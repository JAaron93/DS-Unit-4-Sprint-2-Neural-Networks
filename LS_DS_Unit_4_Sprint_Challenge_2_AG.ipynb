{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "LS_DS_Unit_4_Sprint_Challenge_2_AG.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAaron93/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/LS_DS_Unit_4_Sprint_Challenge_2_AG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nj67V07Z_C0"
      },
      "source": [
        "\n",
        "## Autograded Notebook (Canvas & CodeGrade)\n",
        "\n",
        "This notebook will be automatically graded. It is designed to test your answers and award points for the correct answers. Following the instructions for each Task carefully.\n",
        "Instructions\n",
        "\n",
        "- **Download** this notebook as you would any other ipynb file \n",
        "- **Upload** to Google Colab or work locally (if you have that set-up)\n",
        "- **Delete** `raise NotImplementedError()`\n",
        "\n",
        "- **Write** your code in the `# YOUR CODE HERE` space\n",
        "\n",
        "\n",
        "- **Execute** the Test cells that contain assert statements - these help you check your work (others contain hidden tests that will be checked when you submit through Canvas)\n",
        "\n",
        "- **Save** your notebook when you are finished\n",
        "- **Download** as a ipynb file (if working in Colab)\n",
        "- **Upload** your complete notebook to Canvas (there will be additional instructions in Slack and/or Canvas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shE47BVyZ_C_"
      },
      "source": [
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron (i.e. Neural Network)\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)\n",
        "\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
        "\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a2d017ba3200be3890c0b67eda283c48",
          "grade": false,
          "grade_id": "cell-621a8b86bacf295a",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "lAdp6ZzpZ_DC"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Defining Neural Networks \n",
        "\n",
        "Write *your own* definitions for the following terms:\n",
        "\n",
        "- **Neuron:** A computational simulation of the function of biological neurons. Also referred to as nodes, units, and perceptrons. These units are cast into a wide network of layers that propagate calculated values from one to another in order to strengthen our machines ability to recognize our inputs.\n",
        "\n",
        "- **Input Layer:** The dimensionality of row vectors from our training dataset\n",
        "\n",
        "- **Hidden Layer:** The layer of nodes that compute our propagated inputs, weights and biases. They compose what is commonly referred to as a 'black box.'\n",
        "\n",
        "- **Output Layer:** The output layer is where the the values propagated through our activation function lie. This 'classification layer' is where our neural net makes it's final judgements from the values it's received to solve predictive tasks.\n",
        "\n",
        "- **Activation:** Algorithm that allows the computation of our inputs, weights, and biases to pass on to the output layer or not based on whatever computed value is passed to it. There are different activation functions for different ML problems, whether they might be regression, binary classification, or multi class classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "10aa095d3db59bfe47f9823cfd62f1ef",
          "grade": false,
          "grade_id": "cell-d64f1de9e9458dc7",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "FN1OkktgZ_DG"
      },
      "source": [
        "- `Explain` how Back-propagation works\n",
        "- `Explain` how Gradient Descent works (mention the learning rate)\n",
        "- `Explain` how Back-propagation and Gradient Descent are related\n",
        " \n",
        "\n",
        "Use your own words, but feel free to reference external materials for this question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ceb3f64a4b1b18346decf75c8f5567d2",
          "grade": true,
          "grade_id": "cell-cef20b23d4e0b056",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "PjKMI3tuZ_DH"
      },
      "source": [
        "**Question 1**: Backpropagation is the algorithm responsible for determining how a single training example wants to nudge the weights and biases. This is done for every class in a MCC problem before all of these backpropagated outputs are averaged together to give a final output.\n",
        "\n",
        "The arrows/weights between input values and hidden values and output values can be thought of as the dendrites/axon terminals that connect biological neurons together, where the neurons that tend to fire together streghten our own pattern recognition abilites.\n",
        "\n",
        "So when this theory (Hebbian Theory) is applied to computational neuroscience, the biggest increase to weights, the biggest strengthening of connections happens between neurons/nodes/units/perceptrons that are the most active and the nodes that ought to become more active.\n",
        "\n",
        "Meaning that the nodes that are firing while seeing/training on a 2, get more strongly linked to the nodes that are firing when 'thinking' about a 2 (must be the output nodes).\n",
        "\n",
        "So when weights are adjusted, the nodes that had more positive values, those that had more connections between the neurons trained on identifying a 2 and those that are the output/thinking of a 2 are strengthened! The nodes in that layer that didn't or made weaker connections have their weights weakened!\n",
        "\n",
        "\n",
        "**Question 2**: Gradient Descent basically wants to minimize the amount of error/loss/cost in the model, for the sake of increased accuracy of predictions. So if we imagine a ball on top of a hill, we want it to drop at a certain rate so as to converge on an optimal value at the bottom of the hill. If it drops too fast, it could bounce all over the landscape, never resting at the point we want it to rest at. The rate of descent is analogous to our learning rate.\n",
        "\n",
        "**Question 3**:  During back propagation two different types of parameters are being recursively tuned before they're propagated forward with another derivative calculation that will give a value that our activation function will either take and fire or reject and not fire! From there, gradient descent can use these optimized weighted values to find an optimal loss/error/cost rate.\n",
        "\n",
        "If we imagine a ball at the top of a hill again, these optimized weight values arrived at via recursive tuning from backpropagation, will allow this ball to descend from the hill, not only at an optimal rate/speed, but land at an optimal point at the base of the hill. This optimal point is where our best loss is located. The backpropagation aids gradient descent in finding out exactly where that is!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e040f3ddce6eb34b017f0eb685b202e6",
          "grade": false,
          "grade_id": "cell-e013d19857352d79",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "livhRgG4Z_DJ"
      },
      "source": [
        "Remember our Simple Perceptron Class from Monday. \n",
        "\n",
        "- Describe the process of making a prediction, i.e. how do you go from inputs to outputs?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d746de6391012340f8548821850a621c",
          "grade": true,
          "grade_id": "cell-53c7cc36db9d7983",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "4plBih07Z_DL"
      },
      "source": [
        "The input layers indicate the dimensionality(number of features) of the dataset and propagate them forward to the hidden layer nodes, which is where the activation functions exist, that's where all the weights & biases get computed together by the activation function which outputs values. Those values get propagated to the output layer, which is where loss function is located. Which is where the final prediction is made!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhKi_ulnZ_DN"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## 2. Simple Perceptron\n",
        "\n",
        "In this question, you will build two neural networks using `Keras`. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHJ_oievZ_DR"
      },
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv5RQdhGZ_Df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e15a6772-8a57-41dc-e86b-702943ede222"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jSDRt_dZ_Dg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff1160e-0606-4e9b-f969-f9947667dc43"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMeN8kkxZ_Dh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516d28a2-a5a9-40b6-8873-d6180b7e9f19"
      },
      "source": [
        "2**2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taSZy4XOZ_Di",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d659df9-c6f9-404e-ee78-ae934828508a"
      },
      "source": [
        "4**4"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGJOEuyVZ_Dl"
      },
      "source": [
        "### Simple Perceptron\n",
        "Construct a simple perceptron using Keras. \n",
        "\n",
        "Make sure to include the following in your model:\n",
        "- Add `1 dense layer` with a `single neuron` \n",
        "- Use a `sigmoid activation function`\n",
        "- Set `epochs` to 10 \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data.\n",
        "\n",
        "Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqq-TXdV9XJN"
      },
      "source": [
        "input_dim=X.shape[1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "67e9f7297eb22a79437494d713d74b71",
          "grade": false,
          "grade_id": "cell-427690628f9c900b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "3T-gWroaZ_Dm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b002eed-fc6d-4ad5-84a7-4f986a613f5c"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "model1 = Sequential()\n",
        "\n",
        "# Adding a layer\n",
        "model1.add(Dense(1,\n",
        "                 input_dim=input_dim,\n",
        "                 activation='sigmoid'))\n",
        "\n",
        "# Compiling our model for fitting\n",
        "model1.compile(loss='binary_crossentropy',\n",
        "               optimizer='sgd',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Fitting our compiled model\n",
        "h1 = model1.fit(X,\n",
        "                y,\n",
        "                epochs=10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 1s 2ms/step - loss: 0.7687 - accuracy: 0.5067\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7652 - accuracy: 0.5067\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7615 - accuracy: 0.5067\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7583 - accuracy: 0.5033\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7553 - accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7524 - accuracy: 0.5067\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7492 - accuracy: 0.5033\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7465 - accuracy: 0.5033\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7439 - accuracy: 0.5033\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7411 - accuracy: 0.4933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "36f7f830036d0443ca8e8ba0f17b2a4e",
          "grade": true,
          "grade_id": "cell-bf2ae566afacde8c",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wsBOKQmBZ_Dn"
      },
      "source": [
        "# Visible test\n",
        "assert len(model1.get_config()[\"layers\"]) == 2, \"Make sure you only create 1 Dense layer.\"\n",
        "assert len(h1.epoch) <=10, \"Did you make sure to set epochs to 10 or less?\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pwUFp3TZ_Do",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0187e1c1-689c-46b8-e634-0c467ee7b875"
      },
      "source": [
        "model1.get_config()[\"layers\"]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'class_name': 'InputLayer',\n",
              "  'config': {'batch_input_shape': (None, 2),\n",
              "   'dtype': 'float32',\n",
              "   'name': 'dense_input',\n",
              "   'ragged': False,\n",
              "   'sparse': False}},\n",
              " {'class_name': 'Dense',\n",
              "  'config': {'activation': 'sigmoid',\n",
              "   'activity_regularizer': None,\n",
              "   'batch_input_shape': (None, 2),\n",
              "   'bias_constraint': None,\n",
              "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "   'bias_regularizer': None,\n",
              "   'dtype': 'float32',\n",
              "   'kernel_constraint': None,\n",
              "   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "    'config': {'seed': None}},\n",
              "   'kernel_regularizer': None,\n",
              "   'name': 'dense',\n",
              "   'trainable': True,\n",
              "   'units': 1,\n",
              "   'use_bias': True}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "95d3ee2935a0de64f2a5a22460520e69",
          "grade": true,
          "grade_id": "cell-a957e14380b2f508",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "_Qh-21uZZ_Dp"
      },
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPbVuxOfZ_Dq"
      },
      "source": [
        "### Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron model (also known as a neural network). \n",
        "\n",
        "Your neural network `must` have: \n",
        "- `2` Hidden Layers\n",
        "- Select any number between `5-32` for the number of neurons in each hidden layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the `Callback function` below into your model\n",
        "- Set epochs to `100`\n",
        "- Your model should be called `model2` \n",
        "- Save the results of your fit statement to a variable called `h2`. \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNs5cga1Z_Dr"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        # if model reaches 99% accuracy, training is terminated \n",
        "        acc_threshold = 0.99\n",
        "        if(logs.get('accuracy') > acc_threshold):   \n",
        "            self.model.stop_training = True\n",
        "            self.model.callback_used = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "314337f29c8cd7f38224a31687a86b12",
          "grade": false,
          "grade_id": "cell-77523c4c64743f16",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "FAMbsAXCZ_Ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c13e08-4dda-414e-f246-b3309d64bf03"
      },
      "source": [
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Dense(27,\n",
        "                 activation=\"relu\",\n",
        "                 input_dim=input_dim\n",
        "                 ))\n",
        "\n",
        "model2.add(Dense(32,\n",
        "                 activation=\"relu\"))\n",
        "\n",
        "model2.add(Dense(1,\n",
        "                 activation=\"sigmoid\"\n",
        "                 ))\n",
        "\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "my_callback = myCallback()\n",
        "# Fitting our compiled model\n",
        "h2 = model2.fit(X,\n",
        "                y,\n",
        "                epochs=100,\n",
        "                callbacks=[my_callback])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.7567\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.7867\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.7967\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.8533\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.8800\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.9167\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.9400\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.9533\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.9633\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.9767\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.9767\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.9767\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.9800\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.9767\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.9767\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.9833\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.9833\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.9833\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.9833\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9833\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9833\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9833\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9800\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9833\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9833\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.9833\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.9867\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.9867\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 0.9833\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9867\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9833\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.9867\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9867\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9867\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i5v9VW_rJ6l",
        "outputId": "42599ba5-f75c-4be9-dee7-fc503b546db9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "h2.model.callback_used"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4a5f575f46f151f97f1cebc19a484bae",
          "grade": true,
          "grade_id": "cell-770612ca24334d8a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "vg81TMEQZ_Dt"
      },
      "source": [
        "# Visible test\n",
        "assert len(model2.get_config()[\"layers\"]) == 4, \"You should have 4 layers: Input, hidden 1, hidden 2, output.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][1][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 1, but don't.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][2][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 2, but don't.\"\n",
        "assert h2.params[\"epochs\"] == 100, \"You didn't set epochs to 100.\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3ca73d4d3d17897a570e19a8a97c050f",
          "grade": true,
          "grade_id": "cell-49b1bf7cce22b5b9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "oVxeBJHhZ_Dz"
      },
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2ufX6hsZ_Dz"
      },
      "source": [
        "### Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. \n",
        "\n",
        "Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "You can install this package using the following statement in the terminal\n",
        "\n",
        "```python\n",
        "pip install mlxtend\n",
        "```\n",
        "\n",
        "Or you can install this package using the following statement in your notebook\n",
        "\n",
        "```python\n",
        "!pip install mlxtend\n",
        "```\n",
        "\n",
        "If you choose to install this package from within your notebook, be sure to delete the install statement afterwards so that CodeGrade doesn't try to install it and potentially crash. \n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjLnoU9oGgCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69123725-ef78-4224-e628-2b6cd8dfc7b7"
      },
      "source": [
        "!pip install mlxtend"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.0.0)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.1->mlxtend) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glkXW3uHZ_D1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a68346-bb45-4ca4-accc-a24c2e41bdd3"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((300, 2), (300,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgiUWBS1Z_D2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "1e91013e-3d42-4817-f0f2-e272e992d5eb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "40c30e638b6defe125180b9832a675e2",
          "grade": false,
          "grade_id": "cell-b1bde9222e35b3fc",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "vHNKBDeeZ_D4"
      },
      "source": [
        "1) Why does the Perceptron (`model1`) only achieve about 50% accuracy? \n",
        "\n",
        "2) What is the architectural property of the Multi-Layer Perceptron that allows it to more accurately learn the relationship between X and y? \n",
        "- Hint: recall that each layer represents a vector space and they usually have a different number of dimensions, $\\mathbb{R}^N$.\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e01b50ff508342b905c5a4cdbd7d2dc4",
          "grade": true,
          "grade_id": "cell-302694c508c8da0e",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "t0QIjDw-Z_D5"
      },
      "source": [
        "Question 1: Mine achieves nearly 60%, so I don't know what you mean. Regardless, it's accuracy is still behind the multi-layer perceptron due to it having less nodes to help strengthen its connections between layers and adjust weights via backpropagation.\n",
        "\n",
        "Question 2: Multi Layer Perceptions allow for hyperparameter tuning via adjusting the weights of the nodes that train well on our samples/rows/observations. This can't really be done all that well with just one node. With multiple nodes, which ever nodes that are being trained well on our data will have their weights strengthened while the nodes that aren't will be weakened."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm4XeozBZ_D6"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "- Implement a Multilayer Perceptron architecture of your choosing using the Keras library. \n",
        "- Train your model and report its baseline accuracy. \n",
        "- Then `hyper-parameters tune two parameters each with no more than 2 values each`\n",
        "    - Due to limited computational resources on CodeGrade `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE`\n",
        "- Report your optimized model's accuracy\n",
        "- Use the Heart Disease Dataset provided (binary classification)\n",
        "- Use an appropriate loss function for a binary classification task\n",
        "- Use an appropriate activation function on the final layer of your network.\n",
        "- Train your model using verbose output for ease of grading.\n",
        "- Use GridSearchCV to hyper-parameters tune your model. \n",
        "    - **Use `n_jobs` = 1**\n",
        "- When hyper-parameters tuning, show you work by adding code cells for each new experiment.\n",
        "- Report the accuracy for each combination of hyper-parameters as you test them so that we can easily see which resulted in the highest accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "65nVhDOGZ_D7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "45fcffe9-58ca-4492-f544-8f9a22fd9fd1"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# load data\n",
        "data_path = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>220</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>144</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>136</td>\n",
              "      <td>196</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>169</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>135</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>161</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>318</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>205</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "158   58    1   1       125   220    0  ...      0      0.4      1   4     3       1\n",
              "128   52    0   2       136   196    0  ...      0      0.1      1   0     2       1\n",
              "20    59    1   0       135   234    0  ...      0      0.5      1   0     3       1\n",
              "291   58    1   0       114   318    0  ...      0      4.4      0   3     1       0\n",
              "289   55    0   0       128   205    0  ...      1      2.0      1   1     3       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "22de1dc5d17d7a0bc674d082c33e8b65",
          "grade": false,
          "grade_id": "cell-85dc40f19f5a1d6b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "NZnTOdJRZ_D8"
      },
      "source": [
        "# Create an input matrix named 'X' store it in a 2D numpy array\n",
        "\n",
        "# Create an output vector for the labels named 'Y', store it in 1D numpy array\n",
        "\n",
        "# YOUR CODE HERE\n",
        "target = 'target'\n",
        "Y = df[target]\n",
        "X = df.drop(columns=target)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg07_mltZ_D-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf37bca-8da9-41ad-e894-b43252f6a77e"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPUOr8xAR67B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3465103f-ef50-44f5-ac65-3aa29c1f121e"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVoBtRbbKeD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "029869a9-f511-4bfb-fa26-832ed22ab14a"
      },
      "source": [
        "input_dimensions=X.shape[1]\n",
        "input_dimensions"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_e0McxNMgvg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a2d9fd-8947-4894-f570-2326c220b4b6"
      },
      "source": [
        "number_output_nodes=len(np.unique(y))\n",
        "number_output_nodes"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "825d4f808810a2a8d6301d7453afe478",
          "grade": true,
          "grade_id": "cell-c17c686c974edc2e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1NIVvzGhZ_D_"
      },
      "source": [
        "# Visible Testing\n",
        "assert X.shape[0] == 303, \"Did you drop/lose some rows in X? Did you properly load and split the data?\"\n",
        "assert X.shape[1] == 13, \"Did you drop/lose some columns in X? Did you properly load and split the data?\"\n",
        "assert len(Y)== 303, \"Did you drop/lose some rows in Y? Did you properly load and split the data?\""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH-7_b5WZ_EB"
      },
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1v4NIxnN6-t"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Preprocessing our data via standardization\n",
        "\n",
        "scaler = StandardScaler().fit(X)\n",
        "X_scaled = scaler.transform(X)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYvAdUwKOxRG"
      },
      "source": [
        "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "475835631ff6a34028443dbf604bd922",
          "grade": false,
          "grade_id": "cell-cfc5517cd0b6fa64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "IsFX0ujSZ_EC"
      },
      "source": [
        "# Create a function named 'create_model' that returns a compiled keras model -  required for KerasClassifier\n",
        "# YOUR CODE HERE\n",
        "def create_model(lr=.001, units=27):\n",
        "    \"\"\"\n",
        "    Build and returns a compiled Keras model.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(input_dimensions,\n",
        "                    input_dim=input_dimensions,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.add(Dense(units,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.add(Dense(1,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.compile(optimizer=\"nadam\",\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b906697afb0a3b52cd19e9548eae6a7",
          "grade": true,
          "grade_id": "cell-fac25126eaf1eee4",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dPGDw5uWZ_ED"
      },
      "source": [
        "# Visible Testing\n",
        "assert create_model().__module__ == 'tensorflow.python.keras.engine.sequential', \"create_model should return a keras model that was created using the Sequential class.\""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0412c74b7803790452d4914d99995dd2",
          "grade": false,
          "grade_id": "cell-fbc3d0a07230078c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "cilyfd9eZ_EE"
      },
      "source": [
        "# Pass 'create_model' into KerasClassifier, store KerasClassifier to a variable named 'model'\n",
        "# YOUR CODE HERE\n",
        "model = KerasClassifier(build_fn=create_model)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0442c29a94065e922c5ae929976a52ab",
          "grade": true,
          "grade_id": "cell-464e7506993775f2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7qz2KmuVZ_EG"
      },
      "source": [
        "# Visible Testing\n",
        "assert model.__module__ == 'tensorflow.python.keras.wrappers.scikit_learn', \"model should be a instance of KerasClassifier.\""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f88603ef37a4d3d2ef8699a41ac9a0b2",
          "grade": false,
          "grade_id": "cell-985c0425f3b1304d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "xfB-_SMPZ_EH"
      },
      "source": [
        "# Define the grid search parameters inside a dictionary named 'param_grid' \n",
        "# Use 2 hyper-parameters with 2 possible values for each \n",
        "\n",
        "# YOUR CODE HERE\n",
        "batch_size = [25, 42]\n",
        "epochs = [10, 20]\n",
        "param_grid = dict(batch_size=batch_size,\n",
        "                  epochs=epochs)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a551fd8278b30c1318c036f6ad43b503",
          "grade": true,
          "grade_id": "cell-c765b5db5489d7a2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "MAg09AkmZ_EI"
      },
      "source": [
        "assert len(param_grid.keys()) == 2, \"Did you create a param dict with 2 hyper-parameters as keys?\""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2ea6312f4bc1f42809196b696037dd52",
          "grade": false,
          "grade_id": "cell-7cfb4315eab5031c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "mCM88EcaZ_EI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b460760-2722-484f-d5e2-d372efa0b358"
      },
      "source": [
        "# Create Grid Search object and name it 'gs'\n",
        "# Run Grid Search \n",
        "# YOUR CODE HERE\n",
        "gs = GridSearchCV(estimator=model,\n",
        "                    param_grid=param_grid,\n",
        "                    n_jobs=1,\n",
        "                    verbose=10,\n",
        "                    cv=5)\n",
        "\n",
        "grid_result = gs.fit(X_scaled,\n",
        "                     Y)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7702 - accuracy: 0.5372\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.5372\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7149 - accuracy: 0.5372\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.5372\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.5372\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.5372\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.5372\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.5455\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.5785\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.5992\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.6885\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.689, total=   1.1s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7698 - accuracy: 0.4463\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.4463\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7154 - accuracy: 0.4463\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.4504\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.5413\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.5537\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.5537\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.5537\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.5579\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.5661\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.5246\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.525, total=   1.1s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6947 - accuracy: 0.4628\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.6901\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.5744\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6655 - accuracy: 0.5661\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.5620\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.5661\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.5744\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.6157\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.6446\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.6777\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6230\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.623, total=   1.1s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7579 - accuracy: 0.4444\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7266 - accuracy: 0.4444\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7058 - accuracy: 0.4568\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5062\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.5802\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.5720\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.5844\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.6214\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6523 - accuracy: 0.6132\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.6749\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.6833\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.683, total=   1.1s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7342 - accuracy: 0.5185\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7115 - accuracy: 0.5185\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.5185\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.5226\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.5391\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.6132\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.6955\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.7449\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6444 - accuracy: 0.7531\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7572\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0db6a43cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.7833\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.783, total=   1.4s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6948 - accuracy: 0.4628\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.4793\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.7025\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.7934\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.7727\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.7479\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.7521\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7645\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.7769\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.7893\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.7934\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.7934\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.7893\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7934\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.7975\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.8058\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.8182\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.8264\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.8264\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.8264\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0db582dcb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.8525\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.852, total=   1.6s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    7.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7039 - accuracy: 0.5537\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.5537\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5537\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6738 - accuracy: 0.5537\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.5537\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.5537\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6033\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6240\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.6488\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.7025\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.7231\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.7893\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.7975\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.8058\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.8140\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.8140\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.8182\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.8223\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.8223\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.8264\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.8525\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.852, total=   1.4s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    8.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6841 - accuracy: 0.6364\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.5661\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.5702\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6604 - accuracy: 0.5620\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.5744\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.5868\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6570\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.6983\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.7107\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.7727\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7934\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7934\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7851\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7934\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7975\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7975\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.8017\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.8099\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.8099\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.8223\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7869\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.787, total=   1.4s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   10.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.8385 - accuracy: 0.4444\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7932 - accuracy: 0.4444\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7534 - accuracy: 0.4444\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7207 - accuracy: 0.4444\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.4444\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.5267\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.7613\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.7325\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.6914\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.6914\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6749\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.6914\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.7078\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.7531\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.7407\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.7531\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.7531\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7695\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7984\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.8107\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7833\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.783, total=   1.4s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   11.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.8335 - accuracy: 0.4815\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7901 - accuracy: 0.4815\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.4815\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7289 - accuracy: 0.4815\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7101 - accuracy: 0.4815\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6983 - accuracy: 0.4979\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.5309\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.6584\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.7243\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.7572\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.7654\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.7901\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.8107\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6260 - accuracy: 0.7901\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.7901\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.8066\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.8107\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.8189\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.8189\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.8148\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.8167\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.817, total=   1.4s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.7183 - accuracy: 0.5372\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7087 - accuracy: 0.5372\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7006 - accuracy: 0.5372\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.5372\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.5372\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.5372\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.5372\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.5496\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.5661\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.5744\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6623 - accuracy: 0.6885\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.689, total=   1.0s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.8254 - accuracy: 0.4463\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7958 - accuracy: 0.4463\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7667 - accuracy: 0.4463\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.4463\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7198 - accuracy: 0.4463\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7021 - accuracy: 0.4463\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.4463\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.5207\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.6612\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.7355\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.7869\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.787, total=   1.0s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.7016 - accuracy: 0.5620\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6972 - accuracy: 0.5620\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5620\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5579\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5579\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.5579\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.5620\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.5620\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.5702\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.5620\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.4918\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.492, total=   1.3s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.8397 - accuracy: 0.4444\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8100 - accuracy: 0.4444\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7815 - accuracy: 0.4444\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7561 - accuracy: 0.4444\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.4444\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7176 - accuracy: 0.4444\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7024 - accuracy: 0.4444\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.4444\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6821 - accuracy: 0.4691\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.6091\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6708 - accuracy: 0.7167\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.717, total=   1.1s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.7012 - accuracy: 0.5185\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.6961 - accuracy: 0.5185\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5185\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5185\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6837 - accuracy: 0.5185\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.5226\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.5597\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.6461\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.6379\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.6996\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.8333\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.833, total=   1.1s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.6978 - accuracy: 0.4504\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5289\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5785\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.5950\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.5826\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.5868\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.6198\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.6240\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.6198\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.6240\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6653\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.7273\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.7273\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.7314\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7273\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.7438\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.7479\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.7479\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.7645\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.7727\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5880 - accuracy: 0.8197\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.820, total=   1.2s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.8021 - accuracy: 0.4463\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7796 - accuracy: 0.4463\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7586 - accuracy: 0.4463\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.4463\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7253 - accuracy: 0.4463\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7114 - accuracy: 0.4463\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7016 - accuracy: 0.4463\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4380\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5496\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.6653\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.6983\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.6860\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.6653\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.6281\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.6074\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.6116\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6446\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.6405\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.6612\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.6694\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.6393\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.639, total=   1.2s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.7351 - accuracy: 0.4421\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7223 - accuracy: 0.4421\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7120 - accuracy: 0.4380\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7036 - accuracy: 0.4050\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6969 - accuracy: 0.4256\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5372\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5620\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.5579\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5579\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.5579\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.5579\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.5620\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.5620\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.5620\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.5744\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6033\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.6446\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.6736\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.6860\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.7025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6342 - accuracy: 0.6557\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.656, total=   1.2s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.6981 - accuracy: 0.5556\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6912 - accuracy: 0.5556\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.5556\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.5556\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.5556\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.5556\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.5556\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.5556\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.5556\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.5556\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.5597\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.5926\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6461\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.6955\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.7202\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.7243\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6061 - accuracy: 0.7407\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.7613\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.7654\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.7654\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5960 - accuracy: 0.7333\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.733, total=   2.0s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.6897 - accuracy: 0.5267\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.5226\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.5638\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6783 - accuracy: 0.6132\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.6296\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.6688 - accuracy: 0.6872\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.7037\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.7202\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.7366\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.7449\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.7490\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7984\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.8025\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.8066\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.8107\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 0.7984\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.8107\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.8025\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.8066\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.8066\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.8000\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.800, total=   1.4s\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   25.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 1s 3ms/step - loss: 0.7519 - accuracy: 0.4554\n",
            "Epoch 2/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.7159 - accuracy: 0.4554\n",
            "Epoch 3/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.4554\n",
            "Epoch 4/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6783 - accuracy: 0.6667\n",
            "Epoch 5/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.6931\n",
            "Epoch 6/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6832\n",
            "Epoch 7/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.6304\n",
            "Epoch 8/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7261\n",
            "Epoch 9/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.7558\n",
            "Epoch 10/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.7987\n",
            "Epoch 11/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.7888\n",
            "Epoch 12/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.8053\n",
            "Epoch 13/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.8251\n",
            "Epoch 14/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.8218\n",
            "Epoch 15/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.8251\n",
            "Epoch 16/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.8284\n",
            "Epoch 17/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.8251\n",
            "Epoch 18/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.8284\n",
            "Epoch 19/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.8317\n",
            "Epoch 20/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.8284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLPqySPpZ_EJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd96f32-9d92-4eac-83e0-17aca51dd1ce"
      },
      "source": [
        "# your grid_result object should be able to run in this code \n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8183606624603271 using {'batch_size': 25, 'epochs': 20}\n",
            "Means: 0.6605464458465576, Stdev: 0.08517769431439769 with: {'batch_size': 25, 'epochs': 10}\n",
            "Means: 0.8183606624603271, Stdev: 0.03015253693413842 with: {'batch_size': 25, 'epochs': 20}\n",
            "Means: 0.7034426212310791, Stdev: 0.11749288932586809 with: {'batch_size': 42, 'epochs': 10}\n",
            "Means: 0.7296174883842468, Stdev: 0.07305452507748564 with: {'batch_size': 42, 'epochs': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}