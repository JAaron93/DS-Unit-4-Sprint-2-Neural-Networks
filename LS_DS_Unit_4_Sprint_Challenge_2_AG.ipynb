{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "LS_DS_Unit_4_Sprint_Challenge_2_AG.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAaron93/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/LS_DS_Unit_4_Sprint_Challenge_2_AG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nj67V07Z_C0"
      },
      "source": [
        "\n",
        "## Autograded Notebook (Canvas & CodeGrade)\n",
        "\n",
        "This notebook will be automatically graded. It is designed to test your answers and award points for the correct answers. Following the instructions for each Task carefully.\n",
        "Instructions\n",
        "\n",
        "- **Download** this notebook as you would any other ipynb file \n",
        "- **Upload** to Google Colab or work locally (if you have that set-up)\n",
        "- **Delete** `raise NotImplementedError()`\n",
        "\n",
        "- **Write** your code in the `# YOUR CODE HERE` space\n",
        "\n",
        "\n",
        "- **Execute** the Test cells that contain assert statements - these help you check your work (others contain hidden tests that will be checked when you submit through Canvas)\n",
        "\n",
        "- **Save** your notebook when you are finished\n",
        "- **Download** as a ipynb file (if working in Colab)\n",
        "- **Upload** your complete notebook to Canvas (there will be additional instructions in Slack and/or Canvas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shE47BVyZ_C_"
      },
      "source": [
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron (i.e. Neural Network)\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)\n",
        "\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
        "\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a2d017ba3200be3890c0b67eda283c48",
          "grade": false,
          "grade_id": "cell-621a8b86bacf295a",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "lAdp6ZzpZ_DC"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Defining Neural Networks \n",
        "\n",
        "Write *your own* definitions for the following terms:\n",
        "\n",
        "- **Neuron:** A computational simulation of the function of biological neurons. Also referred to as nodes, units, and perceptrons. These units are cast into a wide network of layers that propagate calculated values from one to another in order to strengthen our machines ability to recognize our inputs.\n",
        "\n",
        "- **Input Layer:** The dimensionality of row vectors from our training dataset\n",
        "\n",
        "- **Hidden Layer:** The layer of nodes that compute our propagated inputs, weights and biases. They compose what is commonly referred to as a 'black box.'\n",
        "\n",
        "- **Output Layer:** The output layer is where the the values propagated through our activation function lie. This 'classification layer' is where our neural net makes it's final judgements from the values it's received to solve predictive tasks.\n",
        "\n",
        "- **Activation:** Algorithm that allows the computation of our inputs, weights, and biases to pass on to the output layer or not based on whatever computed value is passed to it. There are different activation functions for different ML problems, whether they might be regression, binary classification, or multi class classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "10aa095d3db59bfe47f9823cfd62f1ef",
          "grade": false,
          "grade_id": "cell-d64f1de9e9458dc7",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "FN1OkktgZ_DG"
      },
      "source": [
        "- `Explain` how Back-propagation works\n",
        "- `Explain` how Gradient Descent works (mention the learning rate)\n",
        "- `Explain` how Back-propagation and Gradient Descent are related\n",
        " \n",
        "\n",
        "Use your own words, but feel free to reference external materials for this question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ceb3f64a4b1b18346decf75c8f5567d2",
          "grade": true,
          "grade_id": "cell-cef20b23d4e0b056",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "PjKMI3tuZ_DH"
      },
      "source": [
        "**Question 1**: Backpropagation is the algorithm responsible for determining how a single training example wants to nudge the weights and biases. This is done for every class in a MCC problem before all of these backpropagated outputs are averaged together to give a final output.\n",
        "\n",
        "The arrows/weights between input values and hidden values and output values can be thought of as the dendrites/axon terminals that connect biological neurons together, where the neurons that tend to fire together streghten our own pattern recognition abilites.\n",
        "\n",
        "So when this theory (Hebbian Theory) is applied to computational neuroscience, the biggest increase to weights, the biggest strengthening of connections happens between neurons/nodes/units/perceptrons that are the most active and the nodes that ought to become more active.\n",
        "\n",
        "Meaning that the nodes that are firing while seeing/training on a 2, get more strongly linked to the nodes that are firing when 'thinking' about a 2 (must be the output nodes).\n",
        "\n",
        "So when weights are adjusted, the nodes that had more positive values, those that had more connections between the neurons trained on identifying a 2 and those that are the output/thinking of a 2 are strengthened! The nodes in that layer that didn't or made weaker connections have their weights weakened!\n",
        "\n",
        "\n",
        "**Question 2**: Gradient Descent basically wants to minimize the amount of error/loss/cost in the model, for the sake of increased accuracy of predictions. So if we imagine a ball on top of a hill, we want it to drop at a certain rate so as to converge on an optimal value at the bottom of the hill. If it drops too fast, it could bounce all over the landscape, never resting at the point we want it to rest at. The rate of descent is analogous to our learning rate.\n",
        "\n",
        "**Question 3**:  During back propagation two different types of parameters are being recursively tuned before they're propagated forward with another derivative calculation that will give a value that our activation function will either take and fire or reject and not fire! From there, gradient descent can use these optimized weighted values to find an optimal loss/error/cost rate.\n",
        "\n",
        "If we imagine a ball at the top of a hill again, these optimized weight values arrived at via recursive tuning from backpropagation, will allow this ball to descend from the hill, not only at an optimal rate/speed, but land at an optimal point at the base of the hill. This optimal point is where our best loss is located. The backpropagation aids gradient descent in finding out exactly where that is!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e040f3ddce6eb34b017f0eb685b202e6",
          "grade": false,
          "grade_id": "cell-e013d19857352d79",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "livhRgG4Z_DJ"
      },
      "source": [
        "Remember our Simple Perceptron Class from Monday. \n",
        "\n",
        "- Describe the process of making a prediction, i.e. how do you go from inputs to outputs?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d746de6391012340f8548821850a621c",
          "grade": true,
          "grade_id": "cell-53c7cc36db9d7983",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "4plBih07Z_DL"
      },
      "source": [
        "The input layers indicate the dimensionality(number of features) of the dataset and propagate them forward to the hidden layer nodes, which is where the activation functions exist, that's where all the weights & biases get computed together by the activation function which outputs values. Those values get propagated to the output layer, which is where loss function is located. Which is where the final prediction is made!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhKi_ulnZ_DN"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## 2. Simple Perceptron\n",
        "\n",
        "In this question, you will build two neural networks using `Keras`. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHJ_oievZ_DR"
      },
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv5RQdhGZ_Df",
        "outputId": "0d8ec904-d443-4862-f265-c9539092593c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jSDRt_dZ_Dg",
        "outputId": "ae73492b-11c9-4d1e-ba3b-bb9bdb4b6576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMeN8kkxZ_Dh",
        "outputId": "965fe531-a271-455a-9c22-996967963b90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "2**2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taSZy4XOZ_Di",
        "outputId": "5bf0d425-3fec-4456-880a-f49dc8e84f1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "4**4"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGJOEuyVZ_Dl"
      },
      "source": [
        "### Simple Perceptron\n",
        "Construct a simple perceptron using Keras. \n",
        "\n",
        "Make sure to include the following in your model:\n",
        "- Add `1 dense layer` with a `single neuron` \n",
        "- Use a `sigmoid activation function`\n",
        "- Set `epochs` to 10 \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data.\n",
        "\n",
        "Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqq-TXdV9XJN"
      },
      "source": [
        "input_dim=X.shape[1]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "67e9f7297eb22a79437494d713d74b71",
          "grade": false,
          "grade_id": "cell-427690628f9c900b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "3T-gWroaZ_Dm",
        "outputId": "09aa5ba3-b88e-4fa7-920c-7d96d81e556b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "model1 = Sequential()\n",
        "\n",
        "# Adding a layer\n",
        "model1.add(Dense(1,\n",
        "                 input_dim=input_dim,\n",
        "                 activation='sigmoid'))\n",
        "\n",
        "# Compiling our model for fitting\n",
        "model1.compile(loss='binary_crossentropy',\n",
        "               optimizer='sgd',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Fitting our compiled model\n",
        "h1 = model1.fit(X,\n",
        "                y,\n",
        "                epochs=10)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7819 - accuracy: 0.5733\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7785 - accuracy: 0.5733\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7754 - accuracy: 0.5767\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7725 - accuracy: 0.5767\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7697 - accuracy: 0.5767\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7669 - accuracy: 0.5767\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7642 - accuracy: 0.5767\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7617 - accuracy: 0.5767\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7589 - accuracy: 0.5767\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7562 - accuracy: 0.5767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "36f7f830036d0443ca8e8ba0f17b2a4e",
          "grade": true,
          "grade_id": "cell-bf2ae566afacde8c",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wsBOKQmBZ_Dn"
      },
      "source": [
        "# Visible test\n",
        "assert len(model1.get_config()[\"layers\"]) == 2, \"Make sure you only create 1 Dense layer.\"\n",
        "assert len(h1.epoch) <=10, \"Did you make sure to set epochs to 10 or less?\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pwUFp3TZ_Do",
        "outputId": "4bb77637-8fee-4248-c173-ce13dcf30632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model1.get_config()[\"layers\"]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'class_name': 'InputLayer',\n",
              "  'config': {'batch_input_shape': (None, 2),\n",
              "   'dtype': 'float32',\n",
              "   'name': 'dense_1_input',\n",
              "   'ragged': False,\n",
              "   'sparse': False}},\n",
              " {'class_name': 'Dense',\n",
              "  'config': {'activation': 'sigmoid',\n",
              "   'activity_regularizer': None,\n",
              "   'batch_input_shape': (None, 2),\n",
              "   'bias_constraint': None,\n",
              "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "   'bias_regularizer': None,\n",
              "   'dtype': 'float32',\n",
              "   'kernel_constraint': None,\n",
              "   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "    'config': {'seed': None}},\n",
              "   'kernel_regularizer': None,\n",
              "   'name': 'dense_1',\n",
              "   'trainable': True,\n",
              "   'units': 1,\n",
              "   'use_bias': True}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "95d3ee2935a0de64f2a5a22460520e69",
          "grade": true,
          "grade_id": "cell-a957e14380b2f508",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "_Qh-21uZZ_Dp"
      },
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPbVuxOfZ_Dq"
      },
      "source": [
        "### Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron model (also known as a neural network). \n",
        "\n",
        "Your neural network `must` have: \n",
        "- `2` Hidden Layers\n",
        "- Select any number between `5-32` for the number of neurons in each hidden layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the `Callback function` below into your model\n",
        "- Set epochs to `100`\n",
        "- Your model should be called `model2` \n",
        "- Save the results of your fit statement to a variable called `h2`. \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNs5cga1Z_Dr"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        # if model reaches 99% accuracy, training is terminated \n",
        "        acc_threshold = 0.99\n",
        "        if(logs.get('accuracy') > acc_threshold):   \n",
        "            self.model.stop_training = True\n",
        "            self.model.callback_used = True"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "314337f29c8cd7f38224a31687a86b12",
          "grade": false,
          "grade_id": "cell-77523c4c64743f16",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "FAMbsAXCZ_Ds",
        "outputId": "c23624e3-892e-44d8-9627-ecde8c9283b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Dense(27,\n",
        "                 activation=\"sigmoid\",\n",
        "                 input_dim=input_dim\n",
        "                 ))\n",
        "\n",
        "model2.add(Dense(32,\n",
        "                 activation=\"sigmoid\"))\n",
        "\n",
        "model2.add(Dense(1,\n",
        "                 activation=\"sigmoid\"\n",
        "                 ))\n",
        "\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Fitting our compiled model\n",
        "h2 = model2.fit(X,\n",
        "                y,\n",
        "                epochs=100,\n",
        "                callbacks=[myCallback()])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.4900\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5267\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5267\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5267\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5267\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5267\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5433\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5433\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5267\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5267\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5767\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5367\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5333\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5433\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5600\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5533\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5567\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.6000\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.6400\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5767\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5867\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.6467\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.6533\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.6567\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.6367\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.6600\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.6667\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.6533\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.6333\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.6533\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.6667\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.6767\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.6667\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.6800\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.6700\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.6367\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.6067\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.6567\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.6733\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.6867\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.6867\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.6667\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.6833\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.6533\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.6800\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.6833\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.6800\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.6667\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.6700\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.6900\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.6900\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.6800\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.6900\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.6867\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.6800\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.6867\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.6833\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.6800\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.6867\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.6767\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.6933\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.6900\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.6500\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.6300\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.6467\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.6933\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.6933\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.6700\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.6567\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.6800\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.6633\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.6933\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.6867\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6790 - accuracy: 0.6867\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.6800\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.6633\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.6000\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6782 - accuracy: 0.6500\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.6500\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.6900\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.6700\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.6333\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.6567\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.6800\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.6533\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.6600\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.6733\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.6833\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.6767\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.6600\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.6400\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.6733\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.6900\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.6800\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.6800\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6697 - accuracy: 0.6933\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.6900\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.6633\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.6600\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.6700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4a5f575f46f151f97f1cebc19a484bae",
          "grade": true,
          "grade_id": "cell-770612ca24334d8a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "vg81TMEQZ_Dt"
      },
      "source": [
        "# Visible test\n",
        "assert len(model2.get_config()[\"layers\"]) == 4, \"You should have 4 layers: Input, hidden 1, hidden 2, output.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][1][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 1, but don't.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][2][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 2, but don't.\"\n",
        "assert h2.params[\"epochs\"] == 100, \"You didn't set epochs to 100.\""
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3ca73d4d3d17897a570e19a8a97c050f",
          "grade": true,
          "grade_id": "cell-49b1bf7cce22b5b9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "oVxeBJHhZ_Dz"
      },
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2ufX6hsZ_Dz"
      },
      "source": [
        "### Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. \n",
        "\n",
        "Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "You can install this package using the following statement in the terminal\n",
        "\n",
        "```python\n",
        "pip install mlxtend\n",
        "```\n",
        "\n",
        "Or you can install this package using the following statement in your notebook\n",
        "\n",
        "```python\n",
        "!pip install mlxtend\n",
        "```\n",
        "\n",
        "If you choose to install this package from within your notebook, be sure to delete the install statement afterwards so that CodeGrade doesn't try to install it and potentially crash. \n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjLnoU9oGgCX",
        "outputId": "d44fdeab-2c9b-4029-bb29-face6f9f2a1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install mlxtend"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.0.0)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.1->mlxtend) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glkXW3uHZ_D1",
        "outputId": "2c38e20b-84df-4005-c7ad-39d5605df5b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((300, 2), (300,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgiUWBS1Z_D2",
        "outputId": "98cfbf0c-7e81-4d56-9862-c97f9783da79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "40c30e638b6defe125180b9832a675e2",
          "grade": false,
          "grade_id": "cell-b1bde9222e35b3fc",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "vHNKBDeeZ_D4"
      },
      "source": [
        "1) Why does the Perceptron (`model1`) only achieve about 50% accuracy? \n",
        "\n",
        "2) What is the architectural property of the Multi-Layer Perceptron that allows it to more accurately learn the relationship between X and y? \n",
        "- Hint: recall that each layer represents a vector space and they usually have a different number of dimensions, $\\mathbb{R}^N$.\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e01b50ff508342b905c5a4cdbd7d2dc4",
          "grade": true,
          "grade_id": "cell-302694c508c8da0e",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "t0QIjDw-Z_D5"
      },
      "source": [
        "Question 1: Mine achieves nearly 60%, so I don't know what you mean. Regardless, it's accuracy is still behind the multi-layer perceptron due to it having less nodes to help strengthen its connections between layers and adjust weights via backpropagation.\n",
        "\n",
        "Question 2: Multi Layer Perceptions allow for hyperparameter tuning via adjusting the weights of the nodes that train well on our samples/rows/observations. This can't really be done all that well with just one node. With multiple nodes, which ever nodes that are being trained well on our data will have their weights strengthened while the nodes that aren't will be weakened."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm4XeozBZ_D6"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "- Implement a Multilayer Perceptron architecture of your choosing using the Keras library. \n",
        "- Train your model and report its baseline accuracy. \n",
        "- Then `hyper-parameters tune two parameters each with no more than 2 values each`\n",
        "    - Due to limited computational resources on CodeGrade `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE`\n",
        "- Report your optimized model's accuracy\n",
        "- Use the Heart Disease Dataset provided (binary classification)\n",
        "- Use an appropriate loss function for a binary classification task\n",
        "- Use an appropriate activation function on the final layer of your network.\n",
        "- Train your model using verbose output for ease of grading.\n",
        "- Use GridSearchCV to hyper-parameters tune your model. \n",
        "    - **Use `n_jobs` = 1**\n",
        "- When hyper-parameters tuning, show you work by adding code cells for each new experiment.\n",
        "- Report the accuracy for each combination of hyper-parameters as you test them so that we can easily see which resulted in the highest accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "65nVhDOGZ_D7",
        "outputId": "c4244b8c-6c4f-4e4a-ff8d-6e0d7b6ba77e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# load data\n",
        "data_path = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>138</td>\n",
              "      <td>220</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>275</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>139</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>134</td>\n",
              "      <td>271</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>162</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>288</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>140</td>\n",
              "      <td>211</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>165</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "154   39    0   2       138   220    0  ...      0      0.0      1   0     2       1\n",
              "11    48    0   2       130   275    0  ...      0      0.2      2   0     2       1\n",
              "131   49    0   1       134   271    0  ...      0      0.0      1   0     2       1\n",
              "223   56    0   0       200   288    1  ...      1      4.0      0   2     3       0\n",
              "64    58    1   2       140   211    1  ...      0      0.0      2   0     2       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIhBfCArKkX5"
      },
      "source": [
        ""
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTwatRQrM5z_",
        "outputId": "abcad250-063c-4bcb-f7d7-5ee75f29cf30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "154    1\n",
              "11     1\n",
              "131    1\n",
              "223    0\n",
              "64     1\n",
              "      ..\n",
              "300    0\n",
              "178    0\n",
              "168    0\n",
              "138    1\n",
              "169    0\n",
              "Name: target, Length: 303, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2xX6NDjM7Hn",
        "outputId": "a1c3e6af-602f-4663-aff0-cfd21fdd62c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>138</td>\n",
              "      <td>220</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>275</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>139</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>134</td>\n",
              "      <td>271</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>162</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>288</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>140</td>\n",
              "      <td>211</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>165</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>144</td>\n",
              "      <td>193</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>177</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>147</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>201</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>203</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows  13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  ...  exang  oldpeak  slope  ca  thal\n",
              "154   39    0   2       138   220  ...      0      0.0      1   0     2\n",
              "11    48    0   2       130   275  ...      0      0.2      2   0     2\n",
              "131   49    0   1       134   271  ...      0      0.0      1   0     2\n",
              "223   56    0   0       200   288  ...      1      4.0      0   2     3\n",
              "64    58    1   2       140   211  ...      0      0.0      2   0     2\n",
              "..   ...  ...  ..       ...   ...  ...    ...      ...    ...  ..   ...\n",
              "300   68    1   0       144   193  ...      0      3.4      1   2     3\n",
              "178   43    1   0       120   177  ...      1      2.5      1   0     3\n",
              "168   63    1   0       130   254  ...      0      1.4      1   1     3\n",
              "138   57    1   0       110   201  ...      1      1.5      1   0     1\n",
              "169   53    1   0       140   203  ...      1      3.1      0   0     3\n",
              "\n",
              "[303 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "22de1dc5d17d7a0bc674d082c33e8b65",
          "grade": false,
          "grade_id": "cell-85dc40f19f5a1d6b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "NZnTOdJRZ_D8"
      },
      "source": [
        "# Create an input matrix named 'X' store it in a 2D numpy array\n",
        "\n",
        "# Create an output vector for the labels named 'Y', store it in 1D numpy array\n",
        "\n",
        "# YOUR CODE HERE\n",
        "target = 'target'\n",
        "Y = df[target]\n",
        "X = df.drop(columns=target)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg07_mltZ_D-",
        "outputId": "91ed1245-a591-4771-d61d-d7a374ca3a20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPUOr8xAR67B",
        "outputId": "c83c6a67-20c5-41b9-c963-2e04d597813f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVoBtRbbKeD8",
        "outputId": "264530ea-a3d1-4651-b657-05a78806cebe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_dimensions=X.shape[1]\n",
        "input_dimensions"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_e0McxNMgvg",
        "outputId": "932bac95-c449-497a-c515-419e3b2740d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "number_output_nodes=len(np.unique(y))\n",
        "number_output_nodes"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "825d4f808810a2a8d6301d7453afe478",
          "grade": true,
          "grade_id": "cell-c17c686c974edc2e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1NIVvzGhZ_D_"
      },
      "source": [
        "# Visible Testing\n",
        "assert X.shape[0] == 303, \"Did you drop/lose some rows in X? Did you properly load and split the data?\"\n",
        "assert X.shape[1] == 13, \"Did you drop/lose some columns in X? Did you properly load and split the data?\"\n",
        "assert len(Y)== 303, \"Did you drop/lose some rows in Y? Did you properly load and split the data?\""
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH-7_b5WZ_EB"
      },
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1v4NIxnN6-t"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Preprocessing our data via standardization\n",
        "\n",
        "scaler = StandardScaler().fit(X)\n",
        "X = scaler.transform(X)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYvAdUwKOxRG"
      },
      "source": [
        "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "475835631ff6a34028443dbf604bd922",
          "grade": false,
          "grade_id": "cell-cfc5517cd0b6fa64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "IsFX0ujSZ_EC"
      },
      "source": [
        "# Create a function named 'create_model' that returns a compiled keras model -  required for KerasClassifier\n",
        "# YOUR CODE HERE\n",
        "def create_model(lr=.001, units=27):\n",
        "    \"\"\"\n",
        "    Build and returns a compiled Keras model.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(input_dimensions,\n",
        "                    input_dim=input_dimensions,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.add(Dense(units,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.add(Dense(1,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.compile(optimizer=\"adam\",\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b906697afb0a3b52cd19e9548eae6a7",
          "grade": true,
          "grade_id": "cell-fac25126eaf1eee4",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dPGDw5uWZ_ED"
      },
      "source": [
        "# Visible Testing\n",
        "assert create_model().__module__ == 'tensorflow.python.keras.engine.sequential', \"create_model should return a keras model that was created using the Sequential class.\""
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0412c74b7803790452d4914d99995dd2",
          "grade": false,
          "grade_id": "cell-fbc3d0a07230078c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "cilyfd9eZ_EE"
      },
      "source": [
        "# Pass 'create_model' into KerasClassifier, store KerasClassifier to a variable named 'model'\n",
        "# YOUR CODE HERE\n",
        "model = KerasClassifier(build_fn=create_model)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0442c29a94065e922c5ae929976a52ab",
          "grade": true,
          "grade_id": "cell-464e7506993775f2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7qz2KmuVZ_EG"
      },
      "source": [
        "# Visible Testing\n",
        "assert model.__module__ == 'tensorflow.python.keras.wrappers.scikit_learn', \"model should be a instance of KerasClassifier.\""
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f88603ef37a4d3d2ef8699a41ac9a0b2",
          "grade": false,
          "grade_id": "cell-985c0425f3b1304d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "xfB-_SMPZ_EH"
      },
      "source": [
        "# Define the grid search parameters inside a dictionary named 'param_grid' \n",
        "# Use 2 hyper-parameters with 2 possible values for each \n",
        "\n",
        "# YOUR CODE HERE\n",
        "batch_size = [25, 42]\n",
        "epochs = [10, 20]\n",
        "param_grid = dict(batch_size=batch_size,\n",
        "                  epochs=epochs)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a551fd8278b30c1318c036f6ad43b503",
          "grade": true,
          "grade_id": "cell-c765b5db5489d7a2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "MAg09AkmZ_EI"
      },
      "source": [
        "assert len(param_grid.keys()) == 2, \"Did you create a param dict with 2 hyper-parameters as keys?\""
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2ea6312f4bc1f42809196b696037dd52",
          "grade": false,
          "grade_id": "cell-7cfb4315eab5031c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "mCM88EcaZ_EI",
        "outputId": "b1ed9697-d75b-46c8-9ebf-b63422bb2169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create Grid Search object and name it 'gs'\n",
        "# Run Grid Search \n",
        "# YOUR CODE HERE\n",
        "gs = GridSearchCV(estimator=model,\n",
        "                    param_grid=param_grid,\n",
        "                    n_jobs=1,\n",
        "                    verbose=10,\n",
        "                    cv=5)\n",
        "\n",
        "grid_result = gs.fit(X, y)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.4752\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5785\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.6488\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6726 - accuracy: 0.6116\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.6240\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.6281\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6568 - accuracy: 0.6612\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.7066\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.7066\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.7149\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.7705\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.770, total=   0.7s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1353 - accuracy: 0.4587\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0333 - accuracy: 0.4587\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9476 - accuracy: 0.4587\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8759 - accuracy: 0.4587\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8129 - accuracy: 0.4587\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7661 - accuracy: 0.4587\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7266 - accuracy: 0.4587\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.4587\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.4587\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.5413\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.6557\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.656, total=   0.8s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8213 - accuracy: 0.5702\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7734 - accuracy: 0.5702\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7415 - accuracy: 0.5702\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7170 - accuracy: 0.5702\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.5702\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5702\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5702\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.5661\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.5702\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.5785\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.4590\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.459, total=   0.8s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8113 - accuracy: 0.4527\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7568 - accuracy: 0.4527\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7149 - accuracy: 0.4527\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.4527\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6744 - accuracy: 0.6667\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.7860\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6749\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6543\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6416 - accuracy: 0.6543\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.6584\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.6414 - accuracy: 0.6167\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.617, total=   0.7s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    3.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5309\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.5309\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.5391\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.5761\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.6790\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.7119\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.7202\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.7407\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.7860\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.7984\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.8167\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.817, total=   0.8s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5165\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.6364\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.6157\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.5579\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6730 - accuracy: 0.5496\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.6157\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.6777\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6777\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.7438\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6427 - accuracy: 0.7934\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.8058\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.8017\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.7975\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.8017\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.7934\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7934\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7851\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7893\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7934\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7975\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.8525\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.852, total=   1.0s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    4.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7186 - accuracy: 0.5413\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5413\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.5413\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.5413\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6033\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.6818\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.7107\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.7645\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.7893\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.8058\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.8099\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.8058\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.8140\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.8182\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.8140\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.8223\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.8306\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.8471\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.8512\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.8512\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.8197\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.820, total=   1.0s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    5.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.5702\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5702\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5702\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.5702\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6720 - accuracy: 0.5702\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.5702\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.5702\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.5702\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.5785\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.5909\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.6446\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6736\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.7231\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.7314\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.7645\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.7810\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7934\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.8140\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.8223\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.8264\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7541\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.754, total=   1.0s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    6.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.5473\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.5514\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.5514\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.5844\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6049\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6255\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6790\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.6872\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.7366\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.7654\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.7860\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.8107\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.8107\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.8148\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.8148\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.8272\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.8313\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.8148\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.8272\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8230\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.8500\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.850, total=   1.3s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7095 - accuracy: 0.5309\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5309\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5309\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.5432\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.5761\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6461\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6831\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.7449\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.7778\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.7984\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.8189\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.8148\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.8230\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.8272\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.8354\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.8313\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.8313\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.8313\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.8313\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.8230\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.8333\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.833, total=   1.0s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.8209 - accuracy: 0.4669\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7864 - accuracy: 0.4669\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7554 - accuracy: 0.4669\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7326 - accuracy: 0.4669\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7140 - accuracy: 0.4669\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7010 - accuracy: 0.4669\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.4876\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.5372\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.6901\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.7314\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.6230\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.623, total=   0.7s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5579\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5413\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5413\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.5413\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.5413\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.5413\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.5413\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.5413\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.5579\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.5785\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.5902\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.590, total=   0.7s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.5702\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.5702\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.5702\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.5702\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.5702\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.5702\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.5785\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.5826\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.5992\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.6074\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.4918\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.492, total=   0.7s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.5473\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5473\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5473\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6764 - accuracy: 0.5473\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.5556\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6703 - accuracy: 0.5885\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.6173\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.6420\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.6584\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.6872\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.6333\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.633, total=   0.7s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7480 - accuracy: 0.4691\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7280 - accuracy: 0.4691\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7132 - accuracy: 0.4691\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7041 - accuracy: 0.4691\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.4691\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5021\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5309\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5309\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5309\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5309\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6702 - accuracy: 0.6000\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.600, total=   0.8s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7217 - accuracy: 0.4669\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.4669\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.4959\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.6446\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6726 - accuracy: 0.6942\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.6322\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.6364\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6364\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6446\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.6694\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6983\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.7025\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.7066\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.7355\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.7479\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.7686\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.7727\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.7727\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.7810\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.7934\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.8689\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.869, total=   0.9s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8320 - accuracy: 0.4587\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.8021 - accuracy: 0.4587\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7734 - accuracy: 0.4587\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7506 - accuracy: 0.4587\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7296 - accuracy: 0.4587\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.4587\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7069 - accuracy: 0.4587\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.4587\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.4587\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.6240\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.7149\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.6942\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.6694\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.6364\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.6322\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6364\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.6488\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6653\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.6777\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6818\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6470 - accuracy: 0.6557\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.656, total=   0.9s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7551 - accuracy: 0.4298\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7248 - accuracy: 0.4298\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7060 - accuracy: 0.4298\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6912 - accuracy: 0.5289\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5661\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.5702\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.5702\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.5702\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.5702\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.5702\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.5702\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.5702\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.5702\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.5702\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.5785\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.5950\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.6074\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.6322\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6529\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.6694\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.6066\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.607, total=   0.9s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 2ms/step - loss: 0.7092 - accuracy: 0.4280\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.4321\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5802\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5761\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.5514\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.5473\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6710 - accuracy: 0.5473\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.5473\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.5556\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.5679\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6008\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6173\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6626\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.6955\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.7078\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.7202\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.7449\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.7613\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.7819\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.7819\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6010 - accuracy: 0.7333\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.733, total=   1.4s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8067 - accuracy: 0.5309\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7705 - accuracy: 0.5309\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7421 - accuracy: 0.5309\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7198 - accuracy: 0.5309\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.5309\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5309\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5309\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.5309\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.5309\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.5350\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.5802\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.6543\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.6831\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.7160\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.7572\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.7984\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.8066\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.8107\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.8066\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.8148\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6274 - accuracy: 0.7833\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.783, total=   0.9s\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   17.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 2ms/step - loss: 0.7082 - accuracy: 0.5446\n",
            "Epoch 2/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.5446\n",
            "Epoch 3/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.5446\n",
            "Epoch 4/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6667\n",
            "Epoch 5/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6431 - accuracy: 0.7492\n",
            "Epoch 6/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.7789\n",
            "Epoch 7/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.7624\n",
            "Epoch 8/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.7888\n",
            "Epoch 9/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.7855\n",
            "Epoch 10/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.7987\n",
            "Epoch 11/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.8086\n",
            "Epoch 12/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.8086\n",
            "Epoch 13/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.8152\n",
            "Epoch 14/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.8086\n",
            "Epoch 15/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.8152\n",
            "Epoch 16/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.8152\n",
            "Epoch 17/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.8152\n",
            "Epoch 18/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.8185\n",
            "Epoch 19/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8152\n",
            "Epoch 20/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLPqySPpZ_EJ",
        "outputId": "3b40283e-8a09-41ed-f10e-e7d02ce4b049",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# your grid_result object should be able to run in this code \n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8219125628471374 using {'batch_size': 25, 'epochs': 20}\n",
            "Means: 0.6637158393859863, Stdev: 0.1256775221057528 with: {'batch_size': 25, 'epochs': 10}\n",
            "Means: 0.8219125628471374, Stdev: 0.03593385861759365 with: {'batch_size': 25, 'epochs': 20}\n",
            "Means: 0.5876502752304077, Stdev: 0.05035582842744309 with: {'batch_size': 42, 'epochs': 10}\n",
            "Means: 0.7295628428459168, Stdev: 0.0926148744079745 with: {'batch_size': 42, 'epochs': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}