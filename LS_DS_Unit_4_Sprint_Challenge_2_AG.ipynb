{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "LS_DS_Unit_4_Sprint_Challenge_2_AG.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAaron93/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/LS_DS_Unit_4_Sprint_Challenge_2_AG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nj67V07Z_C0"
      },
      "source": [
        "\n",
        "## Autograded Notebook (Canvas & CodeGrade)\n",
        "\n",
        "This notebook will be automatically graded. It is designed to test your answers and award points for the correct answers. Following the instructions for each Task carefully.\n",
        "Instructions\n",
        "\n",
        "- **Download** this notebook as you would any other ipynb file \n",
        "- **Upload** to Google Colab or work locally (if you have that set-up)\n",
        "- **Delete** `raise NotImplementedError()`\n",
        "\n",
        "- **Write** your code in the `# YOUR CODE HERE` space\n",
        "\n",
        "\n",
        "- **Execute** the Test cells that contain assert statements - these help you check your work (others contain hidden tests that will be checked when you submit through Canvas)\n",
        "\n",
        "- **Save** your notebook when you are finished\n",
        "- **Download** as a ipynb file (if working in Colab)\n",
        "- **Upload** your complete notebook to Canvas (there will be additional instructions in Slack and/or Canvas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shE47BVyZ_C_"
      },
      "source": [
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron (i.e. Neural Network)\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)\n",
        "\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
        "\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a2d017ba3200be3890c0b67eda283c48",
          "grade": false,
          "grade_id": "cell-621a8b86bacf295a",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "lAdp6ZzpZ_DC"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Defining Neural Networks \n",
        "\n",
        "Write *your own* definitions for the following terms:\n",
        "\n",
        "- **Neuron:** A computational simulation of the function of biological neurons. Also referred to as nodes, units, and perceptrons. These units are cast into a wide network of layers that propagate calculated values from one to another in order to strengthen our machines ability to recognize our inputs.\n",
        "\n",
        "- **Input Layer:** The dimensionality of row vectors from our training dataset\n",
        "\n",
        "- **Hidden Layer:** The layer of nodes that compute our propagated inputs, weights and biases. They compose what is commonly referred to as a 'black box.'\n",
        "\n",
        "- **Output Layer:** The output layer is where the the values propagated through our activation function lie. This 'classification layer' is where our neural net makes it's final judgements from the values it's received to solve predictive tasks.\n",
        "\n",
        "- **Activation:** Algorithm that allows the computation of our inputs, weights, and biases to pass on to the output layer or not based on whatever computed value is passed to it. There are different activation functions for different ML problems, whether they might be regression, binary classification, or multi class classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "10aa095d3db59bfe47f9823cfd62f1ef",
          "grade": false,
          "grade_id": "cell-d64f1de9e9458dc7",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "FN1OkktgZ_DG"
      },
      "source": [
        "- `Explain` how Back-propagation works\n",
        "- `Explain` how Gradient Descent works (mention the learning rate)\n",
        "- `Explain` how Back-propagation and Gradient Descent are related\n",
        " \n",
        "\n",
        "Use your own words, but feel free to reference external materials for this question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ceb3f64a4b1b18346decf75c8f5567d2",
          "grade": true,
          "grade_id": "cell-cef20b23d4e0b056",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "PjKMI3tuZ_DH"
      },
      "source": [
        "**Question 1**: Backpropagation is the algorithm responsible for determining how a single training example wants to nudge the weights and biases. This is done for every class in a MCC problem before all of these backpropagated outputs are averaged together to give a final output.\n",
        "\n",
        "The arrows/weights between input values and hidden values and output values can be thought of as the dendrites/axon terminals that connect biological neurons together, where the neurons that tend to fire together streghten our own pattern recognition abilites.\n",
        "\n",
        "So when this theory (Hebbian Theory) is applied to computational neuroscience, the biggest increase to weights, the biggest strengthening of connections happens between neurons/nodes/units/perceptrons that are the most active and the nodes that ought to become more active.\n",
        "\n",
        "Meaning that the nodes that are firing while seeing/training on a 2, get more strongly linked to the nodes that are firing when 'thinking' about a 2 (must be the output nodes).\n",
        "\n",
        "So when weights are adjusted, the nodes that had more positive values, those that had more connections between the neurons trained on identifying a 2 and those that are the output/thinking of a 2 are strengthened! The nodes in that layer that didn't or made weaker connections have their weights weakened!\n",
        "\n",
        "\n",
        "**Question 2**: Gradient Descent basically wants to minimize the amount of error/loss/cost in the model, for the sake of increased accuracy of predictions. So if we imagine a ball on top of a hill, we want it to drop at a certain rate so as to converge on an optimal value at the bottom of the hill. If it drops too fast, it could bounce all over the landscape, never resting at the point we want it to rest at. The rate of descent is analogous to our learning rate.\n",
        "\n",
        "**Question 3**:  During back propagation two different types of parameters are being recursively tuned before they're propagated forward with another derivative calculation that will give a value that our activation function will either take and fire or reject and not fire! From there, gradient descent can use these optimized weighted values to find an optimal loss/error/cost rate.\n",
        "\n",
        "If we imagine a ball at the top of a hill again, these optimized weight values arrived at via recursive tuning from backpropagation, will allow this ball to descend from the hill, not only at an optimal rate/speed, but land at an optimal point at the base of the hill. This optimal point is where our best loss is located. The backpropagation aids gradient descent in finding out exactly where that is!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e040f3ddce6eb34b017f0eb685b202e6",
          "grade": false,
          "grade_id": "cell-e013d19857352d79",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "livhRgG4Z_DJ"
      },
      "source": [
        "Remember our Simple Perceptron Class from Monday. \n",
        "\n",
        "- Describe the process of making a prediction, i.e. how do you go from inputs to outputs?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d746de6391012340f8548821850a621c",
          "grade": true,
          "grade_id": "cell-53c7cc36db9d7983",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "4plBih07Z_DL"
      },
      "source": [
        "The input layers indicate the dimensionality(number of features) of the dataset and propagate them forward to the hidden layer nodes, which is where the activation functions exist, that's where all the weights & biases get computed together by the activation function which outputs values. Those values get propagated to the output layer, which is where loss function is located. Which is where the final prediction is made!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhKi_ulnZ_DN"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## 2. Simple Perceptron\n",
        "\n",
        "In this question, you will build two neural networks using `Keras`. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHJ_oievZ_DR"
      },
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv5RQdhGZ_Df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aec7670-f801-4df4-8063-f40e3f193d42"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jSDRt_dZ_Dg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "126a58f3-bd61-410a-a8aa-bc43ace5190d"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMeN8kkxZ_Dh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06438289-ac44-460d-e920-126d94a97286"
      },
      "source": [
        "2**2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taSZy4XOZ_Di",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f97dd8-f2b4-4fef-dd7f-6daef2a363bb"
      },
      "source": [
        "4**4"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGJOEuyVZ_Dl"
      },
      "source": [
        "### Simple Perceptron\n",
        "Construct a simple perceptron using Keras. \n",
        "\n",
        "Make sure to include the following in your model:\n",
        "- Add `1 dense layer` with a `single neuron` \n",
        "- Use a `sigmoid activation function`\n",
        "- Set `epochs` to 10 \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data.\n",
        "\n",
        "Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqq-TXdV9XJN"
      },
      "source": [
        "input_dim=X.shape[1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "67e9f7297eb22a79437494d713d74b71",
          "grade": false,
          "grade_id": "cell-427690628f9c900b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "3T-gWroaZ_Dm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eda7c2a-6f12-4e36-ee18-596f51a122b2"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "model1 = Sequential()\n",
        "\n",
        "# Adding a layer\n",
        "model1.add(Dense(1,\n",
        "                 input_dim=input_dim,\n",
        "                 activation='sigmoid'))\n",
        "\n",
        "# Compiling our model for fitting\n",
        "model1.compile(loss='binary_crossentropy',\n",
        "               optimizer='sgd',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Fitting our compiled model\n",
        "h1 = model1.fit(X,\n",
        "                y,\n",
        "                epochs=10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 1s 2ms/step - loss: 0.9964 - accuracy: 0.4733\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9867 - accuracy: 0.4700\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9775 - accuracy: 0.4733\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9680 - accuracy: 0.4733\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9587 - accuracy: 0.4733\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9503 - accuracy: 0.4733\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9417 - accuracy: 0.4767\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9333 - accuracy: 0.4767\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9245 - accuracy: 0.4767\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9166 - accuracy: 0.4767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "36f7f830036d0443ca8e8ba0f17b2a4e",
          "grade": true,
          "grade_id": "cell-bf2ae566afacde8c",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wsBOKQmBZ_Dn"
      },
      "source": [
        "# Visible test\n",
        "assert len(model1.get_config()[\"layers\"]) == 2, \"Make sure you only create 1 Dense layer.\"\n",
        "assert len(h1.epoch) <=10, \"Did you make sure to set epochs to 10 or less?\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pwUFp3TZ_Do",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb49e46-4024-4918-822b-ff8a1f615721"
      },
      "source": [
        "model1.get_config()[\"layers\"]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'class_name': 'InputLayer',\n",
              "  'config': {'batch_input_shape': (None, 2),\n",
              "   'dtype': 'float32',\n",
              "   'name': 'dense_input',\n",
              "   'ragged': False,\n",
              "   'sparse': False}},\n",
              " {'class_name': 'Dense',\n",
              "  'config': {'activation': 'sigmoid',\n",
              "   'activity_regularizer': None,\n",
              "   'batch_input_shape': (None, 2),\n",
              "   'bias_constraint': None,\n",
              "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "   'bias_regularizer': None,\n",
              "   'dtype': 'float32',\n",
              "   'kernel_constraint': None,\n",
              "   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "    'config': {'seed': None}},\n",
              "   'kernel_regularizer': None,\n",
              "   'name': 'dense',\n",
              "   'trainable': True,\n",
              "   'units': 1,\n",
              "   'use_bias': True}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "95d3ee2935a0de64f2a5a22460520e69",
          "grade": true,
          "grade_id": "cell-a957e14380b2f508",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "_Qh-21uZZ_Dp"
      },
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPbVuxOfZ_Dq"
      },
      "source": [
        "### Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron model (also known as a neural network). \n",
        "\n",
        "Your neural network `must` have: \n",
        "- `2` Hidden Layers\n",
        "- Select any number between `5-32` for the number of neurons in each hidden layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the `Callback function` below into your model\n",
        "- Set epochs to `100`\n",
        "- Your model should be called `model2` \n",
        "- Save the results of your fit statement to a variable called `h2`. \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNs5cga1Z_Dr"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        # if model reaches 99% accuracy, training is terminated \n",
        "        acc_threshold = 0.99\n",
        "        if(logs.get('accuracy') > acc_threshold):   \n",
        "            self.model.stop_training = True\n",
        "            self.model.callback_used = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "314337f29c8cd7f38224a31687a86b12",
          "grade": false,
          "grade_id": "cell-77523c4c64743f16",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "FAMbsAXCZ_Ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e42f2b-bde1-48a3-aa75-841791304151"
      },
      "source": [
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Dense(27,\n",
        "                 activation=\"sigmoid\",\n",
        "                 input_dim=input_dim\n",
        "                 ))\n",
        "\n",
        "model2.add(Dense(32,\n",
        "                 activation=\"sigmoid\"))\n",
        "\n",
        "model2.add(Dense(1,\n",
        "                 activation=\"sigmoid\"\n",
        "                 ))\n",
        "\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "my_callback = myCallback()\n",
        "# Fitting our compiled model\n",
        "h2 = model2.fit(X,\n",
        "                y,\n",
        "                epochs=100,\n",
        "                callbacks=[my_callback])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7335 - accuracy: 0.4733\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.4733\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5200\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5267\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5267\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5267\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5267\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5267\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5667\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5767\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5267\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5267\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5267\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5300\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5367\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5567\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5500\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5533\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5967\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.6567\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.6633\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.6833\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.6900\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.6367\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5633\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.6500\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.6700\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.6633\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.6100\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.6500\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.6833\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.6800\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.6800\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.6767\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.6733\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.6600\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.6667\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.6567\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.6633\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.6900\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.6800\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.6800\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.6900\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.6600\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.6733\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.6267\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.6300\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.6767\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.6867\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.6933\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.6933\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.6933\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.6967\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.6767\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.6767\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.6567\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.6800\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.6767\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.6900\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.6767\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.6767\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.6833\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.6633\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.6533\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.6800\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.6867\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.6867\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.6867\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.6933\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6790 - accuracy: 0.6867\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.6967\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.6867\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.6933\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.6933\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.6967\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.6933\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.6833\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.6733\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.6333\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.6400\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.6600\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.6733\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.6800\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.6767\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.6667\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6710 - accuracy: 0.6800\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.6867\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.6833\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.6400\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.6633\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6697 - accuracy: 0.6833\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.6933\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6900\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.6900\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.6733\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.6567\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.6467\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.6833\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6833\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4a5f575f46f151f97f1cebc19a484bae",
          "grade": true,
          "grade_id": "cell-770612ca24334d8a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "vg81TMEQZ_Dt"
      },
      "source": [
        "# Visible test\n",
        "assert len(model2.get_config()[\"layers\"]) == 4, \"You should have 4 layers: Input, hidden 1, hidden 2, output.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][1][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 1, but don't.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][2][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 2, but don't.\"\n",
        "assert h2.params[\"epochs\"] == 100, \"You didn't set epochs to 100.\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3ca73d4d3d17897a570e19a8a97c050f",
          "grade": true,
          "grade_id": "cell-49b1bf7cce22b5b9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "oVxeBJHhZ_Dz"
      },
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2ufX6hsZ_Dz"
      },
      "source": [
        "### Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. \n",
        "\n",
        "Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "You can install this package using the following statement in the terminal\n",
        "\n",
        "```python\n",
        "pip install mlxtend\n",
        "```\n",
        "\n",
        "Or you can install this package using the following statement in your notebook\n",
        "\n",
        "```python\n",
        "!pip install mlxtend\n",
        "```\n",
        "\n",
        "If you choose to install this package from within your notebook, be sure to delete the install statement afterwards so that CodeGrade doesn't try to install it and potentially crash. \n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjLnoU9oGgCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a30b485-3fc3-4364-ee57-813141552892"
      },
      "source": [
        "!pip install mlxtend"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.1->mlxtend) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glkXW3uHZ_D1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea89695-9a3c-47b8-b1fb-dd6f93a5d6bf"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((300, 2), (300,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgiUWBS1Z_D2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "d7fa5b19-7f2d-46a5-d95d-6c4912ba3cdd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "40c30e638b6defe125180b9832a675e2",
          "grade": false,
          "grade_id": "cell-b1bde9222e35b3fc",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "vHNKBDeeZ_D4"
      },
      "source": [
        "1) Why does the Perceptron (`model1`) only achieve about 50% accuracy? \n",
        "\n",
        "2) What is the architectural property of the Multi-Layer Perceptron that allows it to more accurately learn the relationship between X and y? \n",
        "- Hint: recall that each layer represents a vector space and they usually have a different number of dimensions, $\\mathbb{R}^N$.\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e01b50ff508342b905c5a4cdbd7d2dc4",
          "grade": true,
          "grade_id": "cell-302694c508c8da0e",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "t0QIjDw-Z_D5"
      },
      "source": [
        "Question 1: Mine achieves nearly 60%, so I don't know what you mean. Regardless, it's accuracy is still behind the multi-layer perceptron due to it having less nodes to help strengthen its connections between layers and adjust weights via backpropagation.\n",
        "\n",
        "Question 2: Multi Layer Perceptions allow for hyperparameter tuning via adjusting the weights of the nodes that train well on our samples/rows/observations. This can't really be done all that well with just one node. With multiple nodes, which ever nodes that are being trained well on our data will have their weights strengthened while the nodes that aren't will be weakened."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm4XeozBZ_D6"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "- Implement a Multilayer Perceptron architecture of your choosing using the Keras library. \n",
        "- Train your model and report its baseline accuracy. \n",
        "- Then `hyper-parameters tune two parameters each with no more than 2 values each`\n",
        "    - Due to limited computational resources on CodeGrade `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE`\n",
        "- Report your optimized model's accuracy\n",
        "- Use the Heart Disease Dataset provided (binary classification)\n",
        "- Use an appropriate loss function for a binary classification task\n",
        "- Use an appropriate activation function on the final layer of your network.\n",
        "- Train your model using verbose output for ease of grading.\n",
        "- Use GridSearchCV to hyper-parameters tune your model. \n",
        "    - **Use `n_jobs` = 1**\n",
        "- When hyper-parameters tuning, show you work by adding code cells for each new experiment.\n",
        "- Report the accuracy for each combination of hyper-parameters as you test them so that we can easily see which resulted in the highest accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "65nVhDOGZ_D7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "826453e6-3dd5-4c51-df1b-69b76095544c"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# load data\n",
        "data_path = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>263</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>105</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>211</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>160</td>\n",
              "      <td>228</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>227</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>154</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>234</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>160</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "139   64    1   0       128   263    0  ...      1      0.2      1   1     3       1\n",
              "105   68    0   2       120   211    0  ...      0      1.5      1   0     2       1\n",
              "150   66    1   0       160   228    0  ...      0      2.3      2   0     1       1\n",
              "71    51    1   2        94   227    0  ...      1      0.0      2   1     3       1\n",
              "49    53    0   0       138   234    0  ...      0      0.0      2   0     2       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "22de1dc5d17d7a0bc674d082c33e8b65",
          "grade": false,
          "grade_id": "cell-85dc40f19f5a1d6b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "NZnTOdJRZ_D8"
      },
      "source": [
        "# Create an input matrix named 'X' store it in a 2D numpy array\n",
        "\n",
        "# Create an output vector for the labels named 'Y', store it in 1D numpy array\n",
        "\n",
        "# YOUR CODE HERE\n",
        "target = 'target'\n",
        "Y = df[target]\n",
        "X = df.drop(columns=target)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg07_mltZ_D-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb458cfe-c843-4ae9-f038-4d7ed0352578"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPUOr8xAR67B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e057f5c4-a851-41ab-b5d5-1bc444a6d998"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVoBtRbbKeD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a11ef1-671a-4594-bae2-8b502290ca2e"
      },
      "source": [
        "input_dimensions=X.shape[1]\n",
        "input_dimensions"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_e0McxNMgvg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df600f40-cc09-4cb2-dc20-603025dcb072"
      },
      "source": [
        "number_output_nodes=len(np.unique(y))\n",
        "number_output_nodes"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "825d4f808810a2a8d6301d7453afe478",
          "grade": true,
          "grade_id": "cell-c17c686c974edc2e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1NIVvzGhZ_D_"
      },
      "source": [
        "# Visible Testing\n",
        "assert X.shape[0] == 303, \"Did you drop/lose some rows in X? Did you properly load and split the data?\"\n",
        "assert X.shape[1] == 13, \"Did you drop/lose some columns in X? Did you properly load and split the data?\"\n",
        "assert len(Y)== 303, \"Did you drop/lose some rows in Y? Did you properly load and split the data?\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH-7_b5WZ_EB"
      },
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1v4NIxnN6-t"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Preprocessing our data via standardization\n",
        "\n",
        "scaler = StandardScaler().fit(X)\n",
        "X_scaled = scaler.transform(X)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYvAdUwKOxRG"
      },
      "source": [
        "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "475835631ff6a34028443dbf604bd922",
          "grade": false,
          "grade_id": "cell-cfc5517cd0b6fa64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "IsFX0ujSZ_EC"
      },
      "source": [
        "# Create a function named 'create_model' that returns a compiled keras model -  required for KerasClassifier\n",
        "# YOUR CODE HERE\n",
        "def create_model(lr=.001, units=27):\n",
        "    \"\"\"\n",
        "    Build and returns a compiled Keras model.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(input_dimensions,\n",
        "                    input_dim=input_dimensions,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.add(Dense(units,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.add(Dense(1,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.compile(optimizer=\"nadam\",\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b906697afb0a3b52cd19e9548eae6a7",
          "grade": true,
          "grade_id": "cell-fac25126eaf1eee4",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dPGDw5uWZ_ED"
      },
      "source": [
        "# Visible Testing\n",
        "assert create_model().__module__ == 'tensorflow.python.keras.engine.sequential', \"create_model should return a keras model that was created using the Sequential class.\""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0412c74b7803790452d4914d99995dd2",
          "grade": false,
          "grade_id": "cell-fbc3d0a07230078c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "cilyfd9eZ_EE"
      },
      "source": [
        "# Pass 'create_model' into KerasClassifier, store KerasClassifier to a variable named 'model'\n",
        "# YOUR CODE HERE\n",
        "model = KerasClassifier(build_fn=create_model)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0442c29a94065e922c5ae929976a52ab",
          "grade": true,
          "grade_id": "cell-464e7506993775f2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7qz2KmuVZ_EG"
      },
      "source": [
        "# Visible Testing\n",
        "assert model.__module__ == 'tensorflow.python.keras.wrappers.scikit_learn', \"model should be a instance of KerasClassifier.\""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f88603ef37a4d3d2ef8699a41ac9a0b2",
          "grade": false,
          "grade_id": "cell-985c0425f3b1304d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "xfB-_SMPZ_EH"
      },
      "source": [
        "# Define the grid search parameters inside a dictionary named 'param_grid' \n",
        "# Use 2 hyper-parameters with 2 possible values for each \n",
        "\n",
        "# YOUR CODE HERE\n",
        "batch_size = [25, 42]\n",
        "epochs = [10, 20]\n",
        "param_grid = dict(batch_size=batch_size,\n",
        "                  epochs=epochs)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a551fd8278b30c1318c036f6ad43b503",
          "grade": true,
          "grade_id": "cell-c765b5db5489d7a2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "MAg09AkmZ_EI"
      },
      "source": [
        "assert len(param_grid.keys()) == 2, \"Did you create a param dict with 2 hyper-parameters as keys?\""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2ea6312f4bc1f42809196b696037dd52",
          "grade": false,
          "grade_id": "cell-7cfb4315eab5031c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "mCM88EcaZ_EI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ce45ba7-aef4-416f-d570-89682e9a59e0"
      },
      "source": [
        "# Create Grid Search object and name it 'gs'\n",
        "# Run Grid Search \n",
        "# YOUR CODE HERE\n",
        "gs = GridSearchCV(estimator=model,\n",
        "                    param_grid=param_grid,\n",
        "                    n_jobs=1,\n",
        "                    verbose=10,\n",
        "                    cv=5)\n",
        "\n",
        "grid_result = gs.fit(X_scaled,\n",
        "                     Y)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7845 - accuracy: 0.5372\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7495 - accuracy: 0.5372\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7204 - accuracy: 0.5372\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7005 - accuracy: 0.5372\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.5372\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.5372\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.5372\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.5372\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.5620\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.6405\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.7377\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.738, total=   1.1s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7022 - accuracy: 0.5413\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.5413\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5413\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.5413\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.5455\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.5496\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.5537\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.6198\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.6736\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.6983\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.7541\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.754, total=   1.1s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7086 - accuracy: 0.5537\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.5537\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5537\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.5537\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.5537\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.5537\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.5537\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.5744\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.6364\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.6529\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.6557\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.656, total=   1.1s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7118 - accuracy: 0.4650\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.4650\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.5885\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.6872\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.7078\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.7119\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.6996\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.7366\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.7449\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6312 - accuracy: 0.7654\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7000\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.700, total=   1.1s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6768 - accuracy: 0.5597\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.5556\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.5556\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.5556\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.5597\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.6091\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.6296\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.6667\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.7078\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.7407\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f658e50eef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.8000\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.800, total=   1.4s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.4835\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.5744\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6799 - accuracy: 0.5868\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.5496\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.5372\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.5744\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.5992\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.6612\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.6860\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7107\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.7521\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.7603\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.8058\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.8140\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.8182\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.8140\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.8182\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.8223\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.8223\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.8264\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f658ffad5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7869\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.787, total=   1.6s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    7.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6993 - accuracy: 0.4587\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.5455\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6783 - accuracy: 0.5661\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.5413\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.5537\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.5785\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.5702\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6157\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.7190\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.7562\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6072 - accuracy: 0.7645\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7727\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7975\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.8017\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.8017\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.8099\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.8223\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.8140\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.8182\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.8264\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.8197\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.820, total=   1.4s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    8.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6898 - accuracy: 0.4463\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6738 - accuracy: 0.5950\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.7273\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.7686\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.7479\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7562\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.7727\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.7727\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.7893\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.8099\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.8099\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.8223\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.8306\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.8347\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.8388\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.8388\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.8430\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8471\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.8430\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.8471\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.7869\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.787, total=   1.4s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   10.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6986 - accuracy: 0.4650\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5514\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5967\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.6132\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6502\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.6626\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.7037\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.7037\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.7695\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.7737\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.7942\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.7901\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.8107\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.8272\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.8189\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.8272\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.8272\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.8354\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.8436\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8395\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.8333\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.833, total=   1.4s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   11.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6909 - accuracy: 0.5556\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.5556\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5556\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.5556\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.5556\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.5556\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.5638\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.5761\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.6214\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.6790\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7284\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.7366\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.7613\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7778\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.7778\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.7942\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7942\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.8025\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.8148\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.8189\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.8667\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.867, total=   1.4s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5207\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.5413\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.5413\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.5372\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.5661\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.5702\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.5909\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.6116\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.6488\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.6694\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.7213\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.721, total=   1.0s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.6792 - accuracy: 0.6157\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.5496\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.5744\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.5702\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.6033\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.5909\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6901\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6736\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.7149\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.7397\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.7049\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.705, total=   1.1s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.7255 - accuracy: 0.4463\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7118 - accuracy: 0.4463\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7010 - accuracy: 0.4380\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5124\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.6281\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.5744\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.5620\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.5702\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.5661\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.5661\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.5246\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.525, total=   1.2s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.7002 - accuracy: 0.4650\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4650\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.4979\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.6831\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.7119\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.6831\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.6667\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.6749\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.7037\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.7119\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.7000\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.700, total=   1.1s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.6777 - accuracy: 0.5926\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.5597\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.5638\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.5597\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.5597\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.5638\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.5597\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.5638\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.5885\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.6132\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6167\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.617, total=   1.0s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.6919 - accuracy: 0.5372\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5372\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.5372\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.5372\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6749 - accuracy: 0.5413\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.5702\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.5661\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.5868\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6157\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.6818\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6860\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.6901\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7107\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.7314\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.7397\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.7562\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.7686\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.7975\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.8099\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.8017\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.8361\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.836, total=   1.4s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.7066 - accuracy: 0.4669\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6985 - accuracy: 0.4298\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.4793\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.5537\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.5661\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.5661\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.5661\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.5868\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.5909\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.6446\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.6860\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.7314\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7273\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.7521\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.7810\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.7851\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.7893\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.8058\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.7975\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.8264\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.8361\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.836, total=   1.2s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.8572 - accuracy: 0.4463\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.8232 - accuracy: 0.4463\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7913 - accuracy: 0.4463\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7619 - accuracy: 0.4463\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.4463\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7184 - accuracy: 0.4463\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7015 - accuracy: 0.4463\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.4463\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.5165\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.7355\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.8182\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.7893\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.7190\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.7149\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.6983\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.7025\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.7025\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.7066\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.7190\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.7190\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.7049\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.705, total=   1.2s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.6998 - accuracy: 0.4856\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5103\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5350\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.5679\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.5432\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.5514\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.5432\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.5391\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.5926\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.6461\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.6379\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.6708\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.6955\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.7119\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.7449\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.7613\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.7778\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.7860\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.7942\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.8025\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5868 - accuracy: 0.7833\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.783, total=   1.4s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.8354 - accuracy: 0.4444\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8080 - accuracy: 0.4444\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7825 - accuracy: 0.4444\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7606 - accuracy: 0.4444\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.4444\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7251 - accuracy: 0.4444\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7132 - accuracy: 0.4444\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7032 - accuracy: 0.4444\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.4650\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.5638\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.5802\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6826 - accuracy: 0.5761\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.5556\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6771 - accuracy: 0.5556\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.5556\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.5556\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.5556\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.5556\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.5556\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.5556\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6701 - accuracy: 0.5000\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.500, total=   1.2s\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   24.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 1s 3ms/step - loss: 0.7046 - accuracy: 0.5446\n",
            "Epoch 2/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5446\n",
            "Epoch 3/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.5446\n",
            "Epoch 4/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.5446\n",
            "Epoch 5/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.5446\n",
            "Epoch 6/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.6667\n",
            "Epoch 7/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.7624\n",
            "Epoch 8/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.7393\n",
            "Epoch 9/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.7723\n",
            "Epoch 10/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.7822\n",
            "Epoch 11/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.7987\n",
            "Epoch 12/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.8317\n",
            "Epoch 13/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.8548\n",
            "Epoch 14/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.8581\n",
            "Epoch 15/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.8647\n",
            "Epoch 16/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.8548\n",
            "Epoch 17/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.8449\n",
            "Epoch 18/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.8416\n",
            "Epoch 19/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.8515\n",
            "Epoch 20/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.8515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLPqySPpZ_EJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b7a8bd-8eb5-48f5-c92c-6aec69de197f"
      },
      "source": [
        "# your grid_result object should be able to run in this code \n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8186885237693786 using {'batch_size': 25, 'epochs': 20}\n",
            "Means: 0.7295081973075866, Stdev: 0.048895356139517135 with: {'batch_size': 25, 'epochs': 10}\n",
            "Means: 0.8186885237693786, Stdev: 0.030133819002755743 with: {'batch_size': 25, 'epochs': 20}\n",
            "Means: 0.6534972548484802, Stdev: 0.07399851667335099 with: {'batch_size': 42, 'epochs': 10}\n",
            "Means: 0.7320765137672425, Stdev: 0.12558010364997071 with: {'batch_size': 42, 'epochs': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}