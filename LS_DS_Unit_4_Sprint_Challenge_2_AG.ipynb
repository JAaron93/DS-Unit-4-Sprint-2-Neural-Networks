{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "LS_DS_Unit_4_Sprint_Challenge_2_AG.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAaron93/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/LS_DS_Unit_4_Sprint_Challenge_2_AG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nj67V07Z_C0"
      },
      "source": [
        "\n",
        "## Autograded Notebook (Canvas & CodeGrade)\n",
        "\n",
        "This notebook will be automatically graded. It is designed to test your answers and award points for the correct answers. Following the instructions for each Task carefully.\n",
        "Instructions\n",
        "\n",
        "- **Download** this notebook as you would any other ipynb file \n",
        "- **Upload** to Google Colab or work locally (if you have that set-up)\n",
        "- **Delete** `raise NotImplementedError()`\n",
        "\n",
        "- **Write** your code in the `# YOUR CODE HERE` space\n",
        "\n",
        "\n",
        "- **Execute** the Test cells that contain assert statements - these help you check your work (others contain hidden tests that will be checked when you submit through Canvas)\n",
        "\n",
        "- **Save** your notebook when you are finished\n",
        "- **Download** as a ipynb file (if working in Colab)\n",
        "- **Upload** your complete notebook to Canvas (there will be additional instructions in Slack and/or Canvas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shE47BVyZ_C_"
      },
      "source": [
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron (i.e. Neural Network)\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)\n",
        "\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
        "\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a2d017ba3200be3890c0b67eda283c48",
          "grade": false,
          "grade_id": "cell-621a8b86bacf295a",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "lAdp6ZzpZ_DC"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Defining Neural Networks \n",
        "\n",
        "Write *your own* definitions for the following terms:\n",
        "\n",
        "- **Neuron:** A computational simulation of the function of biological neurons. Also referred to as nodes, units, and perceptrons. These units are cast into a wide network of layers that propagate calculated values from one to another in order to strengthen our machines ability to recognize our inputs.\n",
        "\n",
        "- **Input Layer:** The dimensionality of row vectors from our training dataset\n",
        "\n",
        "- **Hidden Layer:** The layer of nodes that compute our propagated inputs, weights and biases. They compose what is commonly referred to as a 'black box.'\n",
        "\n",
        "- **Output Layer:** The output layer is where the the values propagated through our activation function lie. This 'classification layer' is where our neural net makes it's final judgements from the values it's received to solve predictive tasks.\n",
        "\n",
        "- **Activation:** Algorithm that allows the computation of our inputs, weights, and biases to pass on to the output layer or not based on whatever computed value is passed to it. There are different activation functions for different ML problems, whether they might be regression, binary classification, or multi class classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "10aa095d3db59bfe47f9823cfd62f1ef",
          "grade": false,
          "grade_id": "cell-d64f1de9e9458dc7",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "FN1OkktgZ_DG"
      },
      "source": [
        "- `Explain` how Back-propagation works\n",
        "- `Explain` how Gradient Descent works (mention the learning rate)\n",
        "- `Explain` how Back-propagation and Gradient Descent are related\n",
        " \n",
        "\n",
        "Use your own words, but feel free to reference external materials for this question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ceb3f64a4b1b18346decf75c8f5567d2",
          "grade": true,
          "grade_id": "cell-cef20b23d4e0b056",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "PjKMI3tuZ_DH"
      },
      "source": [
        "**Question 1**: Backpropagation is the algorithm responsible for determining how a single training example wants to nudge the weights and biases. This is done for every class in a MCC problem before all of these backpropagated outputs are averaged together to give a final output.\n",
        "\n",
        "The arrows/weights between input values and hidden values and output values can be thought of as the dendrites/axon terminals that connect biological neurons together, where the neurons that tend to fire together streghten our own pattern recognition abilites.\n",
        "\n",
        "So when this theory (Hebbian Theory) is applied to computational neuroscience, the biggest increase to weights, the biggest strengthening of connections happens between neurons/nodes/units/perceptrons that are the most active and the nodes that ought to become more active.\n",
        "\n",
        "Meaning that the nodes that are firing while seeing/training on a 2, get more strongly linked to the nodes that are firing when 'thinking' about a 2 (must be the output nodes).\n",
        "\n",
        "So when weights are adjusted, the nodes that had more positive values, those that had more connections between the neurons trained on identifying a 2 and those that are the output/thinking of a 2 are strengthened! The nodes in that layer that didn't or made weaker connections have their weights weakened!\n",
        "\n",
        "\n",
        "**Question 2**: Gradient Descent basically wants to minimize the amount of error/loss/cost in the model, for the sake of increased accuracy of predictions. So if we imagine a ball on top of a hill, we want it to drop at a certain rate so as to converge on an optimal value at the bottom of the hill. If it drops too fast, it could bounce all over the landscape, never resting at the point we want it to rest at. The rate of descent is analogous to our learning rate.\n",
        "\n",
        "**Question 3**:  During back propagation two different types of parameters are being recursively tuned before they're propagated forward with another derivative calculation that will give a value that our activation function will either take and fire or reject and not fire! From there, gradient descent can use these optimized weighted values to find an optimal loss/error/cost rate.\n",
        "\n",
        "If we imagine a ball at the top of a hill again, these optimized weight values arrived at via recursive tuning from backpropagation, will allow this ball to descend from the hill, not only at an optimal rate/speed, but land at an optimal point at the base of the hill. This optimal point is where our best loss is located. The backpropagation aids gradient descent in finding out exactly where that is!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e040f3ddce6eb34b017f0eb685b202e6",
          "grade": false,
          "grade_id": "cell-e013d19857352d79",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "livhRgG4Z_DJ"
      },
      "source": [
        "Remember our Simple Perceptron Class from Monday. \n",
        "\n",
        "- Describe the process of making a prediction, i.e. how do you go from inputs to outputs?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d746de6391012340f8548821850a621c",
          "grade": true,
          "grade_id": "cell-53c7cc36db9d7983",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "4plBih07Z_DL"
      },
      "source": [
        "The input layers indicate the dimensionality(number of features) of the dataset and propagate them forward to the hidden layer nodes, which is where the activation functions exist, that's where all the weights & biases get computed together by the activation function which outputs values. Those values get propagated to the output layer, which is where loss function is located. Which is where the final prediction is made!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhKi_ulnZ_DN"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## 2. Simple Perceptron\n",
        "\n",
        "In this question, you will build two neural networks using `Keras`. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHJ_oievZ_DR"
      },
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv5RQdhGZ_Df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "156cd096-910c-4f49-c3b1-82caaf98d4a8"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jSDRt_dZ_Dg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3437ecf3-3f6e-41a5-81fe-0e13b330a67b"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMeN8kkxZ_Dh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d5269a-171c-436f-d20f-82c12c5d6094"
      },
      "source": [
        "2**2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taSZy4XOZ_Di",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eee478d-f1fe-4f7f-9e6c-5f040616d0c8"
      },
      "source": [
        "4**4"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGJOEuyVZ_Dl"
      },
      "source": [
        "### Simple Perceptron\n",
        "Construct a simple perceptron using Keras. \n",
        "\n",
        "Make sure to include the following in your model:\n",
        "- Add `1 dense layer` with a `single neuron` \n",
        "- Use a `sigmoid activation function`\n",
        "- Set `epochs` to 10 \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data.\n",
        "\n",
        "Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqq-TXdV9XJN"
      },
      "source": [
        "input_dim=X.shape[1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "67e9f7297eb22a79437494d713d74b71",
          "grade": false,
          "grade_id": "cell-427690628f9c900b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "3T-gWroaZ_Dm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c38e39d0-6534-4c68-c652-ca4de667bdf5"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "model1 = Sequential()\n",
        "\n",
        "# Adding a layer\n",
        "model1.add(Dense(1,\n",
        "                 input_dim=input_dim,\n",
        "                 activation='sigmoid'))\n",
        "\n",
        "# Compiling our model for fitting\n",
        "model1.compile(loss='binary_crossentropy',\n",
        "               optimizer='sgd',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Fitting our compiled model\n",
        "h1 = model1.fit(X,\n",
        "                y,\n",
        "                epochs=10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 1s 2ms/step - loss: 0.7767 - accuracy: 0.4300\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7731 - accuracy: 0.4367\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7696 - accuracy: 0.4367\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7661 - accuracy: 0.4367\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7626 - accuracy: 0.4400\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7595 - accuracy: 0.4433\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7562 - accuracy: 0.4500\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7531 - accuracy: 0.4533\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7503 - accuracy: 0.4567\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7475 - accuracy: 0.4600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "36f7f830036d0443ca8e8ba0f17b2a4e",
          "grade": true,
          "grade_id": "cell-bf2ae566afacde8c",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wsBOKQmBZ_Dn"
      },
      "source": [
        "# Visible test\n",
        "assert len(model1.get_config()[\"layers\"]) == 2, \"Make sure you only create 1 Dense layer.\"\n",
        "assert len(h1.epoch) <=10, \"Did you make sure to set epochs to 10 or less?\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pwUFp3TZ_Do",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4b61af-f258-40d0-aa69-af6f7545dd11"
      },
      "source": [
        "model1.get_config()[\"layers\"]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'class_name': 'InputLayer',\n",
              "  'config': {'batch_input_shape': (None, 2),\n",
              "   'dtype': 'float32',\n",
              "   'name': 'dense_input',\n",
              "   'ragged': False,\n",
              "   'sparse': False}},\n",
              " {'class_name': 'Dense',\n",
              "  'config': {'activation': 'sigmoid',\n",
              "   'activity_regularizer': None,\n",
              "   'batch_input_shape': (None, 2),\n",
              "   'bias_constraint': None,\n",
              "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "   'bias_regularizer': None,\n",
              "   'dtype': 'float32',\n",
              "   'kernel_constraint': None,\n",
              "   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "    'config': {'seed': None}},\n",
              "   'kernel_regularizer': None,\n",
              "   'name': 'dense',\n",
              "   'trainable': True,\n",
              "   'units': 1,\n",
              "   'use_bias': True}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "95d3ee2935a0de64f2a5a22460520e69",
          "grade": true,
          "grade_id": "cell-a957e14380b2f508",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "_Qh-21uZZ_Dp"
      },
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPbVuxOfZ_Dq"
      },
      "source": [
        "### Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron model (also known as a neural network). \n",
        "\n",
        "Your neural network `must` have: \n",
        "- `2` Hidden Layers\n",
        "- Select any number between `5-32` for the number of neurons in each hidden layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the `Callback function` below into your model\n",
        "- Set epochs to `100`\n",
        "- Your model should be called `model2` \n",
        "- Save the results of your fit statement to a variable called `h2`. \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNs5cga1Z_Dr"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        # if model reaches 99% accuracy, training is terminated \n",
        "        acc_threshold = 0.99\n",
        "        if(logs.get('accuracy') > acc_threshold):   \n",
        "            self.model.stop_training = True\n",
        "            self.model.callback_used = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP3-R-icceOV"
      },
      "source": [
        "callback = myCallback()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "314337f29c8cd7f38224a31687a86b12",
          "grade": false,
          "grade_id": "cell-77523c4c64743f16",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "FAMbsAXCZ_Ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff7aea4-9842-460d-abf0-8c19bf958a18"
      },
      "source": [
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Dense(27,\n",
        "                 activation=\"sigmoid\",\n",
        "                 input_dim=input_dim\n",
        "                 ))\n",
        "\n",
        "model2.add(Dense(32,\n",
        "                 activation=\"sigmoid\"))\n",
        "\n",
        "model2.add(Dense(1,\n",
        "                 activation=\"sigmoid\"\n",
        "                 ))\n",
        "\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Fitting our compiled model\n",
        "h2 = model2.fit(X,\n",
        "                y,\n",
        "                epochs=100,\n",
        "                callbacks=[callback])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7302 - accuracy: 0.4733\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.4733\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5167\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5267\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5267\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5267\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5267\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5267\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5267\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5267\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5267\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5267\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5467\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5367\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5267\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5267\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5267\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5367\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5567\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5333\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5367\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5500\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5533\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5967\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.6267\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.6733\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.6667\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.6100\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5400\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5633\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5367\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5567\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.6300\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.6667\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.6533\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.5700\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5433\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5700\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.6667\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.6633\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.6867\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.6767\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.6300\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.6067\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.6500\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.6600\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.6600\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.6633\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.6767\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.6433\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.6633\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.6900\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.6800\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.6800\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.6833\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.6800\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.6867\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.6833\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.6900\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.6967\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.6933\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.6833\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.6800\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.6933\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.6900\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.6767\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.6833\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.6733\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.6867\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.6833\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.6767\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.6833\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.6800\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.6867\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.6833\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.6933\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.6833\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.6800\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.6833\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.6633\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.6733\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.6767\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.6833\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.6833\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.6833\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.6800\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.6800\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.6767\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.6667\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.6900\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.6900\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.6867\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.6967\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.6900\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.6967\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.6867\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6737 - accuracy: 0.6900\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.6833\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.6967\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.6733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4a5f575f46f151f97f1cebc19a484bae",
          "grade": true,
          "grade_id": "cell-770612ca24334d8a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "vg81TMEQZ_Dt"
      },
      "source": [
        "# Visible test\n",
        "assert len(model2.get_config()[\"layers\"]) == 4, \"You should have 4 layers: Input, hidden 1, hidden 2, output.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][1][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 1, but don't.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][2][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 2, but don't.\"\n",
        "assert h2.params[\"epochs\"] == 100, \"You didn't set epochs to 100.\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3ca73d4d3d17897a570e19a8a97c050f",
          "grade": true,
          "grade_id": "cell-49b1bf7cce22b5b9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "oVxeBJHhZ_Dz"
      },
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2ufX6hsZ_Dz"
      },
      "source": [
        "### Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. \n",
        "\n",
        "Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "You can install this package using the following statement in the terminal\n",
        "\n",
        "```python\n",
        "pip install mlxtend\n",
        "```\n",
        "\n",
        "Or you can install this package using the following statement in your notebook\n",
        "\n",
        "```python\n",
        "!pip install mlxtend\n",
        "```\n",
        "\n",
        "If you choose to install this package from within your notebook, be sure to delete the install statement afterwards so that CodeGrade doesn't try to install it and potentially crash. \n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjLnoU9oGgCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8148ba19-4037-4e22-a489-fedb3a18d540"
      },
      "source": [
        "!pip install mlxtend"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.1->mlxtend) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glkXW3uHZ_D1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b1be86-136c-4dbd-fef1-e5b03ef9827f"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((300, 2), (300,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgiUWBS1Z_D2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "359e40fc-712a-4737-bf63-7ded56a94001"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "40c30e638b6defe125180b9832a675e2",
          "grade": false,
          "grade_id": "cell-b1bde9222e35b3fc",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "vHNKBDeeZ_D4"
      },
      "source": [
        "1) Why does the Perceptron (`model1`) only achieve about 50% accuracy? \n",
        "\n",
        "2) What is the architectural property of the Multi-Layer Perceptron that allows it to more accurately learn the relationship between X and y? \n",
        "- Hint: recall that each layer represents a vector space and they usually have a different number of dimensions, $\\mathbb{R}^N$.\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e01b50ff508342b905c5a4cdbd7d2dc4",
          "grade": true,
          "grade_id": "cell-302694c508c8da0e",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "t0QIjDw-Z_D5"
      },
      "source": [
        "Question 1: Mine achieves nearly 60%, so I don't know what you mean. Regardless, it's accuracy is still behind the multi-layer perceptron due to it having less nodes to help strengthen its connections between layers and adjust weights via backpropagation.\n",
        "\n",
        "Question 2: Multi Layer Perceptions allow for hyperparameter tuning via adjusting the weights of the nodes that train well on our samples/rows/observations. This can't really be done all that well with just one node. With multiple nodes, which ever nodes that are being trained well on our data will have their weights strengthened while the nodes that aren't will be weakened."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm4XeozBZ_D6"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "- Implement a Multilayer Perceptron architecture of your choosing using the Keras library. \n",
        "- Train your model and report its baseline accuracy. \n",
        "- Then `hyper-parameters tune two parameters each with no more than 2 values each`\n",
        "    - Due to limited computational resources on CodeGrade `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE`\n",
        "- Report your optimized model's accuracy\n",
        "- Use the Heart Disease Dataset provided (binary classification)\n",
        "- Use an appropriate loss function for a binary classification task\n",
        "- Use an appropriate activation function on the final layer of your network.\n",
        "- Train your model using verbose output for ease of grading.\n",
        "- Use GridSearchCV to hyper-parameters tune your model. \n",
        "    - **Use `n_jobs` = 1**\n",
        "- When hyper-parameters tuning, show you work by adding code cells for each new experiment.\n",
        "- Report the accuracy for each combination of hyper-parameters as you test them so that we can easily see which resulted in the highest accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "65nVhDOGZ_D7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "120e5832-e114-4c3f-9f79-c27a0a424cee"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# load data\n",
        "data_path = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>253</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>144</td>\n",
              "      <td>1</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>259</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>204</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>256</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>112</td>\n",
              "      <td>230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "186   60    1   0       130   253    0  ...      1      1.4      2   1     3       0\n",
              "256   58    1   0       128   259    0  ...      1      3.0      1   2     3       0\n",
              "281   52    1   0       128   204    1  ...      1      1.0      1   0     0       0\n",
              "219   48    1   0       130   256    1  ...      1      0.0      2   2     3       0\n",
              "261   52    1   0       112   230    0  ...      0      0.0      2   1     2       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "22de1dc5d17d7a0bc674d082c33e8b65",
          "grade": false,
          "grade_id": "cell-85dc40f19f5a1d6b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "NZnTOdJRZ_D8"
      },
      "source": [
        "# Create an input matrix named 'X' store it in a 2D numpy array\n",
        "\n",
        "# Create an output vector for the labels named 'Y', store it in 1D numpy array\n",
        "\n",
        "# YOUR CODE HERE\n",
        "target = 'target'\n",
        "Y = df[target]\n",
        "X = df.drop(columns=target)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg07_mltZ_D-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b3178c8-2e36-4bac-d354-36742726a8bf"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPUOr8xAR67B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc4477b1-5f93-4ca5-fe89-8c7ecd4d340d"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVoBtRbbKeD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd3e08f-63cc-40e5-90b1-9d60f7cf2b91"
      },
      "source": [
        "input_dimensions=X.shape[1]\n",
        "input_dimensions"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_e0McxNMgvg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81910a3e-56c8-4455-ed83-4b749a93190b"
      },
      "source": [
        "number_output_nodes=len(np.unique(y))\n",
        "number_output_nodes"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "825d4f808810a2a8d6301d7453afe478",
          "grade": true,
          "grade_id": "cell-c17c686c974edc2e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1NIVvzGhZ_D_"
      },
      "source": [
        "# Visible Testing\n",
        "assert X.shape[0] == 303, \"Did you drop/lose some rows in X? Did you properly load and split the data?\"\n",
        "assert X.shape[1] == 13, \"Did you drop/lose some columns in X? Did you properly load and split the data?\"\n",
        "assert len(Y)== 303, \"Did you drop/lose some rows in Y? Did you properly load and split the data?\""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH-7_b5WZ_EB"
      },
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1v4NIxnN6-t"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Preprocessing our data via standardization\n",
        "\n",
        "scaler = StandardScaler().fit(X)\n",
        "X = scaler.transform(X)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYvAdUwKOxRG"
      },
      "source": [
        "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "475835631ff6a34028443dbf604bd922",
          "grade": false,
          "grade_id": "cell-cfc5517cd0b6fa64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "IsFX0ujSZ_EC"
      },
      "source": [
        "# Create a function named 'create_model' that returns a compiled keras model -  required for KerasClassifier\n",
        "# YOUR CODE HERE\n",
        "def create_model(lr=.001, units=27):\n",
        "    \"\"\"\n",
        "    Build and returns a compiled Keras model.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(input_dimensions,\n",
        "                    input_dim=input_dimensions,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.add(Dense(units,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.add(Dense(1,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.compile(optimizer=\"nadam\",\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b906697afb0a3b52cd19e9548eae6a7",
          "grade": true,
          "grade_id": "cell-fac25126eaf1eee4",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dPGDw5uWZ_ED"
      },
      "source": [
        "# Visible Testing\n",
        "assert create_model().__module__ == 'tensorflow.python.keras.engine.sequential', \"create_model should return a keras model that was created using the Sequential class.\""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0412c74b7803790452d4914d99995dd2",
          "grade": false,
          "grade_id": "cell-fbc3d0a07230078c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "cilyfd9eZ_EE"
      },
      "source": [
        "# Pass 'create_model' into KerasClassifier, store KerasClassifier to a variable named 'model'\n",
        "# YOUR CODE HERE\n",
        "model = KerasClassifier(build_fn=create_model)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0442c29a94065e922c5ae929976a52ab",
          "grade": true,
          "grade_id": "cell-464e7506993775f2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7qz2KmuVZ_EG"
      },
      "source": [
        "# Visible Testing\n",
        "assert model.__module__ == 'tensorflow.python.keras.wrappers.scikit_learn', \"model should be a instance of KerasClassifier.\""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f88603ef37a4d3d2ef8699a41ac9a0b2",
          "grade": false,
          "grade_id": "cell-985c0425f3b1304d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "xfB-_SMPZ_EH"
      },
      "source": [
        "# Define the grid search parameters inside a dictionary named 'param_grid' \n",
        "# Use 2 hyper-parameters with 2 possible values for each \n",
        "\n",
        "# YOUR CODE HERE\n",
        "batch_size = [25, 42]\n",
        "epochs = [10, 20]\n",
        "param_grid = dict(batch_size=batch_size,\n",
        "                  epochs=epochs)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a551fd8278b30c1318c036f6ad43b503",
          "grade": true,
          "grade_id": "cell-c765b5db5489d7a2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "MAg09AkmZ_EI"
      },
      "source": [
        "assert len(param_grid.keys()) == 2, \"Did you create a param dict with 2 hyper-parameters as keys?\""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2ea6312f4bc1f42809196b696037dd52",
          "grade": false,
          "grade_id": "cell-7cfb4315eab5031c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "mCM88EcaZ_EI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c465eb5-4df2-4566-b7f1-0e69f01f8038"
      },
      "source": [
        "# Create Grid Search object and name it 'gs'\n",
        "# Run Grid Search \n",
        "# YOUR CODE HERE\n",
        "gs = GridSearchCV(estimator=model,\n",
        "                    param_grid=param_grid,\n",
        "                    n_jobs=1,\n",
        "                    verbose=10,\n",
        "                    cv=5)\n",
        "\n",
        "grid_result = gs.fit(X,\n",
        "                     Y,\n",
        "                     callbacks=[myCallback()])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7603 - accuracy: 0.5372\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7276 - accuracy: 0.5372\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7054 - accuracy: 0.5372\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5372\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.5372\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.5413\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.5455\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.6240\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.6570\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.7273\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.7869\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.787, total=   1.1s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6825 - accuracy: 0.5702\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.5702\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.5702\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.5702\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.5744\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.5785\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.6074\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.6405\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.6529\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.7107\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6721\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.672, total=   1.1s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7062 - accuracy: 0.3636\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.5455\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5661\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.5661\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.5661\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.5661\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.5661\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.5661\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.5661\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.5868\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.4918\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.492, total=   1.1s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7527 - accuracy: 0.4691\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7211 - accuracy: 0.4691\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6966 - accuracy: 0.4691\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.4815\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.6955\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.7860\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.7942\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.7778\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7984\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.8066\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.7833\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.783, total=   1.4s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.8040 - accuracy: 0.4815\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7634 - accuracy: 0.4815\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7334 - accuracy: 0.4815\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7113 - accuracy: 0.4815\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6979 - accuracy: 0.4815\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.4815\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.5802\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.6872\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.7490\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6655 - accuracy: 0.7572\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fbc86798830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.8500\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.850, total=   1.1s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7556 - accuracy: 0.5372\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7306 - accuracy: 0.5372\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7110 - accuracy: 0.5372\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.5372\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.5372\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.5372\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.5455\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.5413\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.6074\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.6777\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.7521\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.7603\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.7645\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 0.7727\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.7934\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.8017\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.8017\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.8182\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.8140\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.8223\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fbc95f6a5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.8033\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.803, total=   1.6s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    7.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7356 - accuracy: 0.5702\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7137 - accuracy: 0.5702\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.5702\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5702\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.5702\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.5702\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.5702\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6661 - accuracy: 0.5702\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.5702\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.5702\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.5785\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.6198\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6364\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6736\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.7521\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.7769\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.7975\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.8099\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.8099\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.8099\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7869\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.787, total=   1.4s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    8.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6855 - accuracy: 0.5661\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.5661\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.5661\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.5661\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.5661\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.5661\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.5661\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.5785\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.6281\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6405\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.7149\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.7562\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7727\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.7686\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7851\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7934\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.8058\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.8140\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.8017\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.8058\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7869\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.787, total=   1.4s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   10.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7148 - accuracy: 0.4691\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6976 - accuracy: 0.4691\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.5144\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.7119\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.7531\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.7119\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.7202\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.7366\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.7531\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.7654\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.7737\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.7778\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.7778\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.7901\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.7984\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.7984\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.8025\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.8025\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.8066\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.8066\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.8667\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.867, total=   1.4s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   11.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 4ms/step - loss: 0.8137 - accuracy: 0.4815\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7690 - accuracy: 0.4815\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7321 - accuracy: 0.4815\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7048 - accuracy: 0.4815\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.4815\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6749 - accuracy: 0.5350\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.6667\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.7366\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.7531\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.7737\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.7901\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.7984\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.7942\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.7984\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.8107\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.8148\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.8148\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.8189\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.8230\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.8189\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.8667\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.867, total=   1.4s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.7991 - accuracy: 0.4628\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7753 - accuracy: 0.4628\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7530 - accuracy: 0.4628\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7333 - accuracy: 0.4628\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7169 - accuracy: 0.4628\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7038 - accuracy: 0.4628\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4628\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.4959\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.6074\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.6860\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.7049\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.705, total=   1.0s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 4ms/step - loss: 0.6882 - accuracy: 0.5661\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.5702\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.5702\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.5702\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.5702\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.5702\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.5702\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.5744\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.5744\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.5744\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6767 - accuracy: 0.4590\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.459, total=   1.0s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.7790 - accuracy: 0.4339\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7563 - accuracy: 0.4339\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.4339\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7148 - accuracy: 0.4339\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6984 - accuracy: 0.4339\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.4752\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.7149\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.7190\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.6157\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.5826\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.4754\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.475, total=   1.4s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.7132 - accuracy: 0.4691\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7023 - accuracy: 0.4691\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5144\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.6420\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6826 - accuracy: 0.6008\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.5432\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6749 - accuracy: 0.5597\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.6008\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.6420\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.6584\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6535 - accuracy: 0.7333\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.733, total=   1.0s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 4ms/step - loss: 0.7712 - accuracy: 0.5185\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7485 - accuracy: 0.5185\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7288 - accuracy: 0.5185\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7134 - accuracy: 0.5185\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7026 - accuracy: 0.5185\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5185\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.5185\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.5226\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.5514\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.6337\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6594 - accuracy: 0.7500\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.750, total=   1.1s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.6813 - accuracy: 0.5413\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.5413\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.5413\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.5413\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.5496\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.5661\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.5868\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.6322\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.6529\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.6983\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.7066\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.7397\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.7479\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.7479\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.7645\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.7769\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.7769\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7893\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.8058\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.8140\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.8033\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.803, total=   1.4s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.8510 - accuracy: 0.5702\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8201 - accuracy: 0.5702\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7919 - accuracy: 0.5702\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7663 - accuracy: 0.5702\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7433 - accuracy: 0.5702\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7247 - accuracy: 0.5702\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.7116 - accuracy: 0.5702\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 0.5702\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5702\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.5702\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.5702\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.5702\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.5702\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.5702\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.5702\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.5702\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.5702\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.5785\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.5909\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.5950\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.4754\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.475, total=   1.4s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.7276 - accuracy: 0.4339\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7117 - accuracy: 0.4339\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6968 - accuracy: 0.4339\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.5041\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.7314\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.6942\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.6405\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.5826\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.5744\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.5785\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.5744\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.5702\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.5868\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.6157\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6260 - accuracy: 0.6446\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.6529\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.6777\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.7066\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.7231\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.7314\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.6721\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.672, total=   1.2s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.7722 - accuracy: 0.5309\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7537 - accuracy: 0.5309\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7360 - accuracy: 0.5309\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7207 - accuracy: 0.5309\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7094 - accuracy: 0.5309\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6999 - accuracy: 0.5309\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5309\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.5309\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6826 - accuracy: 0.5309\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.5309\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.5597\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.5885\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.6091\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6749\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.6749\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.7243\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.7284\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.7366\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.7531\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.7654\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6162 - accuracy: 0.7667\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.767, total=   1.6s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 4ms/step - loss: 0.9201 - accuracy: 0.5185\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8865 - accuracy: 0.5185\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8513 - accuracy: 0.5185\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8195 - accuracy: 0.5185\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7911 - accuracy: 0.5185\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7656 - accuracy: 0.5185\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.5185\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7272 - accuracy: 0.5185\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7122 - accuracy: 0.5185\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7007 - accuracy: 0.5185\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.5185\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.5185\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.5185\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.5267\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.5720\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6379\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.6914\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.7325\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.7243\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7531\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6214 - accuracy: 0.8667\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.867, total=   1.2s\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   25.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 1s 3ms/step - loss: 0.7004 - accuracy: 0.5446\n",
            "Epoch 2/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.5446\n",
            "Epoch 3/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.5446\n",
            "Epoch 4/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.5512\n",
            "Epoch 5/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.5842\n",
            "Epoch 6/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.5974\n",
            "Epoch 7/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6667\n",
            "Epoch 8/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.7294\n",
            "Epoch 9/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.7261\n",
            "Epoch 10/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.7327\n",
            "Epoch 11/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.7822\n",
            "Epoch 12/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.7954\n",
            "Epoch 13/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.8020\n",
            "Epoch 14/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.8119\n",
            "Epoch 15/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.8119\n",
            "Epoch 16/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.8086\n",
            "Epoch 17/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.8251\n",
            "Epoch 18/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8416\n",
            "Epoch 19/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.8416\n",
            "Epoch 20/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.8416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLPqySPpZ_EJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "897ef30f-07de-4080-bed3-7647b0c2ffe9"
      },
      "source": [
        "# your grid_result object should be able to run in this code \n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8220765113830566 using {'batch_size': 25, 'epochs': 20}\n",
            "Means: 0.7168306112289429, Stdev: 0.12625347728864925 with: {'batch_size': 25, 'epochs': 10}\n",
            "Means: 0.8220765113830566, Stdev: 0.03689653570925811 with: {'batch_size': 25, 'epochs': 20}\n",
            "Means: 0.6245355188846589, Stdev: 0.1293636002705936 with: {'batch_size': 42, 'epochs': 10}\n",
            "Means: 0.7168305933475494, Stdev: 0.13615416368906247 with: {'batch_size': 42, 'epochs': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}