{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "LS_DS_Unit_4_Sprint_Challenge_2_AG.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAaron93/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/LS_DS_Unit_4_Sprint_Challenge_2_AG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nj67V07Z_C0"
      },
      "source": [
        "\n",
        "## Autograded Notebook (Canvas & CodeGrade)\n",
        "\n",
        "This notebook will be automatically graded. It is designed to test your answers and award points for the correct answers. Following the instructions for each Task carefully.\n",
        "Instructions\n",
        "\n",
        "- **Download** this notebook as you would any other ipynb file \n",
        "- **Upload** to Google Colab or work locally (if you have that set-up)\n",
        "- **Delete** `raise NotImplementedError()`\n",
        "\n",
        "- **Write** your code in the `# YOUR CODE HERE` space\n",
        "\n",
        "\n",
        "- **Execute** the Test cells that contain assert statements - these help you check your work (others contain hidden tests that will be checked when you submit through Canvas)\n",
        "\n",
        "- **Save** your notebook when you are finished\n",
        "- **Download** as a ipynb file (if working in Colab)\n",
        "- **Upload** your complete notebook to Canvas (there will be additional instructions in Slack and/or Canvas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shE47BVyZ_C_"
      },
      "source": [
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron (i.e. Neural Network)\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)\n",
        "\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
        "\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a2d017ba3200be3890c0b67eda283c48",
          "grade": false,
          "grade_id": "cell-621a8b86bacf295a",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "lAdp6ZzpZ_DC"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Defining Neural Networks \n",
        "\n",
        "Write *your own* definitions for the following terms:\n",
        "\n",
        "- **Neuron:** A computational simulation of the function of biological neurons. Also referred to as nodes, units, and perceptrons. These units are cast into a wide network of layers that propagate calculated values from one to another in order to strengthen our machines ability to recognize our inputs.\n",
        "\n",
        "- **Input Layer:** The dimensionality of row vectors from our training dataset\n",
        "\n",
        "- **Hidden Layer:** The layer of nodes that compute our propagated inputs, weights and biases. They compose what is commonly referred to as a 'black box.'\n",
        "\n",
        "- **Output Layer:** The output layer is where the the values propagated through our activation function lie. This 'classification layer' is where our neural net makes it's final judgements from the values it's received to solve predictive tasks.\n",
        "\n",
        "- **Activation:** Algorithm that allows the computation of our inputs, weights, and biases to pass on to the output layer or not based on whatever computed value is passed to it. There are different activation functions for different ML problems, whether they might be regression, binary classification, or multi class classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "10aa095d3db59bfe47f9823cfd62f1ef",
          "grade": false,
          "grade_id": "cell-d64f1de9e9458dc7",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "FN1OkktgZ_DG"
      },
      "source": [
        "- `Explain` how Back-propagation works\n",
        "- `Explain` how Gradient Descent works (mention the learning rate)\n",
        "- `Explain` how Back-propagation and Gradient Descent are related\n",
        " \n",
        "\n",
        "Use your own words, but feel free to reference external materials for this question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ceb3f64a4b1b18346decf75c8f5567d2",
          "grade": true,
          "grade_id": "cell-cef20b23d4e0b056",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "PjKMI3tuZ_DH"
      },
      "source": [
        "**Question 1**: Backpropagation is the algorithm responsible for determining how a single training example wants to nudge the weights and biases. This is done for every class in a MCC problem before all of these backpropagated outputs are averaged together to give a final output.\n",
        "\n",
        "The arrows/weights between input values and hidden values and output values can be thought of as the dendrites/axon terminals that connect biological neurons together, where the neurons that tend to fire together streghten our own pattern recognition abilites.\n",
        "\n",
        "So when this theory (Hebbian Theory) is applied to computational neuroscience, the biggest increase to weights, the biggest strengthening of connections happens between neurons/nodes/units/perceptrons that are the most active and the nodes that ought to become more active.\n",
        "\n",
        "Meaning that the nodes that are firing while seeing/training on a 2, get more strongly linked to the nodes that are firing when 'thinking' about a 2 (must be the output nodes).\n",
        "\n",
        "So when weights are adjusted, the nodes that had more positive values, those that had more connections between the neurons trained on identifying a 2 and those that are the output/thinking of a 2 are strengthened! The nodes in that layer that didn't or made weaker connections have their weights weakened!\n",
        "\n",
        "\n",
        "**Question 2**: Gradient Descent basically wants to minimize the amount of error/loss/cost in the model, for the sake of increased accuracy of predictions. So if we imagine a ball on top of a hill, we want it to drop at a certain rate so as to converge on an optimal value at the bottom of the hill. If it drops too fast, it could bounce all over the landscape, never resting at the point we want it to rest at. The rate of descent is analogous to our learning rate.\n",
        "\n",
        "**Question 3**:  During back propagation two different types of parameters are being recursively tuned before they're propagated forward with another derivative calculation that will give a value that our activation function will either take and fire or reject and not fire! From there, gradient descent can use these optimized weighted values to find an optimal loss/error/cost rate.\n",
        "\n",
        "If we imagine a ball at the top of a hill again, these optimized weight values arrived at via recursive tuning from backpropagation, will allow this ball to descend from the hill, not only at an optimal rate/speed, but land at an optimal point at the base of the hill. This optimal point is where our best loss is located. The backpropagation aids gradient descent in finding out exactly where that is!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e040f3ddce6eb34b017f0eb685b202e6",
          "grade": false,
          "grade_id": "cell-e013d19857352d79",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "livhRgG4Z_DJ"
      },
      "source": [
        "Remember our Simple Perceptron Class from Monday. \n",
        "\n",
        "- Describe the process of making a prediction, i.e. how do you go from inputs to outputs?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d746de6391012340f8548821850a621c",
          "grade": true,
          "grade_id": "cell-53c7cc36db9d7983",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "4plBih07Z_DL"
      },
      "source": [
        "The input layers indicate the dimensionality(number of features) of the dataset and propagate them forward to the hidden layer nodes, which is where the activation functions exist, that's where all the weights & biases get computed together by the activation function which outputs values. Those values get propagated to the output layer, which is where loss function is located. Which is where the final prediction is made!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhKi_ulnZ_DN"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## 2. Simple Perceptron\n",
        "\n",
        "In this question, you will build two neural networks using `Keras`. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHJ_oievZ_DR"
      },
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv5RQdhGZ_Df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16c4b49-23c2-4a88-bbf3-c84c56f70b08"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jSDRt_dZ_Dg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4756463f-a98a-4f1d-bcd3-7017a4b04f9c"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMeN8kkxZ_Dh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb9a99c-7abe-4feb-dd84-56b8b7428622"
      },
      "source": [
        "2**2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taSZy4XOZ_Di",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bee40fc-707b-4d52-82fc-4198c45cca26"
      },
      "source": [
        "4**4"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGJOEuyVZ_Dl"
      },
      "source": [
        "### Simple Perceptron\n",
        "Construct a simple perceptron using Keras. \n",
        "\n",
        "Make sure to include the following in your model:\n",
        "- Add `1 dense layer` with a `single neuron` \n",
        "- Use a `sigmoid activation function`\n",
        "- Set `epochs` to 10 \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data.\n",
        "\n",
        "Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqq-TXdV9XJN"
      },
      "source": [
        "input_dim=X.shape[1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "67e9f7297eb22a79437494d713d74b71",
          "grade": false,
          "grade_id": "cell-427690628f9c900b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "3T-gWroaZ_Dm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa32030-9d70-4195-97b9-3cb8b76c3c46"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "model1 = Sequential()\n",
        "\n",
        "# Adding a layer\n",
        "model1.add(Dense(1,\n",
        "                 input_dim=input_dim,\n",
        "                 activation='sigmoid'))\n",
        "\n",
        "# Compiling our model for fitting\n",
        "model1.compile(loss='binary_crossentropy',\n",
        "               optimizer='sgd',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Fitting our compiled model\n",
        "h1 = model1.fit(X,\n",
        "                y,\n",
        "                epochs=10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 1s 2ms/step - loss: 0.7404 - accuracy: 0.4800\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7377 - accuracy: 0.4833\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7354 - accuracy: 0.4833\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7330 - accuracy: 0.4800\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7306 - accuracy: 0.4733\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7282 - accuracy: 0.4767\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7261 - accuracy: 0.4733\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7240 - accuracy: 0.4733\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7223 - accuracy: 0.4733\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7205 - accuracy: 0.4733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "36f7f830036d0443ca8e8ba0f17b2a4e",
          "grade": true,
          "grade_id": "cell-bf2ae566afacde8c",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wsBOKQmBZ_Dn"
      },
      "source": [
        "# Visible test\n",
        "assert len(model1.get_config()[\"layers\"]) == 2, \"Make sure you only create 1 Dense layer.\"\n",
        "assert len(h1.epoch) <=10, \"Did you make sure to set epochs to 10 or less?\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pwUFp3TZ_Do",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232fe934-5f87-435a-e61a-99fa6101ee1c"
      },
      "source": [
        "model1.get_config()[\"layers\"]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'class_name': 'InputLayer',\n",
              "  'config': {'batch_input_shape': (None, 2),\n",
              "   'dtype': 'float32',\n",
              "   'name': 'dense_input',\n",
              "   'ragged': False,\n",
              "   'sparse': False}},\n",
              " {'class_name': 'Dense',\n",
              "  'config': {'activation': 'sigmoid',\n",
              "   'activity_regularizer': None,\n",
              "   'batch_input_shape': (None, 2),\n",
              "   'bias_constraint': None,\n",
              "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "   'bias_regularizer': None,\n",
              "   'dtype': 'float32',\n",
              "   'kernel_constraint': None,\n",
              "   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "    'config': {'seed': None}},\n",
              "   'kernel_regularizer': None,\n",
              "   'name': 'dense',\n",
              "   'trainable': True,\n",
              "   'units': 1,\n",
              "   'use_bias': True}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "95d3ee2935a0de64f2a5a22460520e69",
          "grade": true,
          "grade_id": "cell-a957e14380b2f508",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "_Qh-21uZZ_Dp"
      },
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPbVuxOfZ_Dq"
      },
      "source": [
        "### Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron model (also known as a neural network). \n",
        "\n",
        "Your neural network `must` have: \n",
        "- `2` Hidden Layers\n",
        "- Select any number between `5-32` for the number of neurons in each hidden layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the `Callback function` below into your model\n",
        "- Set epochs to `100`\n",
        "- Your model should be called `model2` \n",
        "- Save the results of your fit statement to a variable called `h2`. \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNs5cga1Z_Dr"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        # if model reaches 99% accuracy, training is terminated \n",
        "        acc_threshold = 0.99\n",
        "        if(logs.get('accuracy') > acc_threshold):   \n",
        "            self.model.stop_training = True\n",
        "            self.model.callback_used = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "314337f29c8cd7f38224a31687a86b12",
          "grade": false,
          "grade_id": "cell-77523c4c64743f16",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "FAMbsAXCZ_Ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b88f08c7-fdf8-46c8-95d9-551a16545333"
      },
      "source": [
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Dense(27,\n",
        "                 activation=\"sigmoid\",\n",
        "                 input_dim=input_dim\n",
        "                 ))\n",
        "\n",
        "model2.add(Dense(32,\n",
        "                 activation=\"sigmoid\"))\n",
        "\n",
        "model2.add(Dense(1,\n",
        "                 activation=\"sigmoid\"\n",
        "                 ))\n",
        "\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Fitting our compiled model\n",
        "h2 = model2.fit(X,\n",
        "                y,\n",
        "                epochs=100,\n",
        "                callbacks=[myCallback()])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7858 - accuracy: 0.4733\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7244 - accuracy: 0.4733\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.4733\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.4867\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5267\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5267\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5267\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5267\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5267\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5267\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5267\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5267\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5267\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5267\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5267\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5300\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5700\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.6700\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.6767\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.6567\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.6267\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5967\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.6700\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.6567\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.6567\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.6233\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.6233\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.6433\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.6667\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.6833\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.6533\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.6667\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.6900\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.6900\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.6867\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.6867\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.6933\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.6733\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.6700\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.6867\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.6900\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.6800\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.6767\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.6767\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.6900\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.6867\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.6800\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.6867\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.6900\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.6667\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.6767\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.6867\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.6900\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.6867\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.6933\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.6867\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.6733\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.6567\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.6967\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6764 - accuracy: 0.6900\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.6933\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.6800\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.6800\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6746 - accuracy: 0.6700\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.6567\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.6667\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.6533\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.6733\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.6933\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.6933\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6698 - accuracy: 0.6767\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.6833\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.6700\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6668 - accuracy: 0.6767\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.6967\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.6933\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.6967\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.6900\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6900\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6733\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.6767\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6867\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6800\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6767\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6767\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6900\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.6967\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6933\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6900\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6767\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.6733\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6867\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.6933\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.6800\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6933\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6933\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6933\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.6900\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6933\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.6900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4a5f575f46f151f97f1cebc19a484bae",
          "grade": true,
          "grade_id": "cell-770612ca24334d8a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "vg81TMEQZ_Dt"
      },
      "source": [
        "# Visible test\n",
        "assert len(model2.get_config()[\"layers\"]) == 4, \"You should have 4 layers: Input, hidden 1, hidden 2, output.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][1][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 1, but don't.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][2][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 2, but don't.\"\n",
        "assert h2.params[\"epochs\"] == 100, \"You didn't set epochs to 100.\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3ca73d4d3d17897a570e19a8a97c050f",
          "grade": true,
          "grade_id": "cell-49b1bf7cce22b5b9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "oVxeBJHhZ_Dz"
      },
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2ufX6hsZ_Dz"
      },
      "source": [
        "### Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. \n",
        "\n",
        "Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "You can install this package using the following statement in the terminal\n",
        "\n",
        "```python\n",
        "pip install mlxtend\n",
        "```\n",
        "\n",
        "Or you can install this package using the following statement in your notebook\n",
        "\n",
        "```python\n",
        "!pip install mlxtend\n",
        "```\n",
        "\n",
        "If you choose to install this package from within your notebook, be sure to delete the install statement afterwards so that CodeGrade doesn't try to install it and potentially crash. \n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjLnoU9oGgCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc9d164-4d9a-4d36-fa0a-186101f5b4e5"
      },
      "source": [
        "!pip install mlxtend"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.0.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.5.1->mlxtend) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glkXW3uHZ_D1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a282b7c8-397e-4ebf-ab77-a32f0a9a4a48"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((300, 2), (300,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgiUWBS1Z_D2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "edf9a68b-0345-476a-f974-168ec8a6a463"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "40c30e638b6defe125180b9832a675e2",
          "grade": false,
          "grade_id": "cell-b1bde9222e35b3fc",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "vHNKBDeeZ_D4"
      },
      "source": [
        "1) Why does the Perceptron (`model1`) only achieve about 50% accuracy? \n",
        "\n",
        "2) What is the architectural property of the Multi-Layer Perceptron that allows it to more accurately learn the relationship between X and y? \n",
        "- Hint: recall that each layer represents a vector space and they usually have a different number of dimensions, $\\mathbb{R}^N$.\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e01b50ff508342b905c5a4cdbd7d2dc4",
          "grade": true,
          "grade_id": "cell-302694c508c8da0e",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "t0QIjDw-Z_D5"
      },
      "source": [
        "Question 1: Mine achieves nearly 60%, so I don't know what you mean. Regardless, it's accuracy is still behind the multi-layer perceptron due to it having less nodes to help strengthen its connections between layers and adjust weights via backpropagation.\n",
        "\n",
        "Question 2: Multi Layer Perceptions allow for hyperparameter tuning via adjusting the weights of the nodes that train well on our samples/rows/observations. This can't really be done all that well with just one node. With multiple nodes, which ever nodes that are being trained well on our data will have their weights strengthened while the nodes that aren't will be weakened."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm4XeozBZ_D6"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "- Implement a Multilayer Perceptron architecture of your choosing using the Keras library. \n",
        "- Train your model and report its baseline accuracy. \n",
        "- Then `hyper-parameters tune two parameters each with no more than 2 values each`\n",
        "    - Due to limited computational resources on CodeGrade `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE`\n",
        "- Report your optimized model's accuracy\n",
        "- Use the Heart Disease Dataset provided (binary classification)\n",
        "- Use an appropriate loss function for a binary classification task\n",
        "- Use an appropriate activation function on the final layer of your network.\n",
        "- Train your model using verbose output for ease of grading.\n",
        "- Use GridSearchCV to hyper-parameters tune your model. \n",
        "    - **Use `n_jobs` = 1**\n",
        "- When hyper-parameters tuning, show you work by adding code cells for each new experiment.\n",
        "- Report the accuracy for each combination of hyper-parameters as you test them so that we can easily see which resulted in the highest accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "65nVhDOGZ_D7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "510dfd14-1f05-4f3a-9f6d-d9e0bb7d8600"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# load data\n",
        "data_path = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>118</td>\n",
              "      <td>219</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>311</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>294</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>153</td>\n",
              "      <td>0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>165</td>\n",
              "      <td>289</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>124</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>140</td>\n",
              "      <td>211</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>165</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "212   39    1   0       118   219    0  ...      0      1.2      1   0     3       0\n",
              "285   46    1   0       140   311    0  ...      1      1.8      1   2     3       0\n",
              "6     56    0   1       140   294    0  ...      0      1.3      1   0     2       1\n",
              "231   57    1   0       165   289    1  ...      0      1.0      1   3     3       0\n",
              "64    58    1   2       140   211    1  ...      0      0.0      2   0     2       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "22de1dc5d17d7a0bc674d082c33e8b65",
          "grade": false,
          "grade_id": "cell-85dc40f19f5a1d6b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "NZnTOdJRZ_D8"
      },
      "source": [
        "# Create an input matrix named 'X' store it in a 2D numpy array\n",
        "\n",
        "# Create an output vector for the labels named 'Y', store it in 1D numpy array\n",
        "\n",
        "# YOUR CODE HERE\n",
        "target = 'target'\n",
        "Y = df[target]\n",
        "X = df.drop(columns=target)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg07_mltZ_D-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "546e1865-accb-476e-f5a5-143b594fdddf"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPUOr8xAR67B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed3e48a6-5726-43ac-81ec-182be7127373"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVoBtRbbKeD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e9036e5-0197-4869-bbbf-a1fd24d620e9"
      },
      "source": [
        "input_dimensions=X.shape[1]\n",
        "input_dimensions"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_e0McxNMgvg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e22bf19a-e245-4fb8-e329-1996765155d0"
      },
      "source": [
        "number_output_nodes=len(np.unique(y))\n",
        "number_output_nodes"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "825d4f808810a2a8d6301d7453afe478",
          "grade": true,
          "grade_id": "cell-c17c686c974edc2e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1NIVvzGhZ_D_"
      },
      "source": [
        "# Visible Testing\n",
        "assert X.shape[0] == 303, \"Did you drop/lose some rows in X? Did you properly load and split the data?\"\n",
        "assert X.shape[1] == 13, \"Did you drop/lose some columns in X? Did you properly load and split the data?\"\n",
        "assert len(Y)== 303, \"Did you drop/lose some rows in Y? Did you properly load and split the data?\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH-7_b5WZ_EB"
      },
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1v4NIxnN6-t"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Preprocessing our data via standardization\n",
        "\n",
        "scaler = StandardScaler().fit(X)\n",
        "X = scaler.transform(X)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYvAdUwKOxRG"
      },
      "source": [
        "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "475835631ff6a34028443dbf604bd922",
          "grade": false,
          "grade_id": "cell-cfc5517cd0b6fa64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "IsFX0ujSZ_EC"
      },
      "source": [
        "# Create a function named 'create_model' that returns a compiled keras model -  required for KerasClassifier\n",
        "# YOUR CODE HERE\n",
        "def create_model(lr=.001, units=27):\n",
        "    \"\"\"\n",
        "    Build and returns a compiled Keras model.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(input_dimensions,\n",
        "                    input_dim=input_dimensions,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.add(Dense(units,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.add(Dense(1,\n",
        "                    activation=\"sigmoid\"))\n",
        "    \n",
        "    model.compile(optimizer=\"nadam\",\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b906697afb0a3b52cd19e9548eae6a7",
          "grade": true,
          "grade_id": "cell-fac25126eaf1eee4",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dPGDw5uWZ_ED"
      },
      "source": [
        "# Visible Testing\n",
        "assert create_model().__module__ == 'tensorflow.python.keras.engine.sequential', \"create_model should return a keras model that was created using the Sequential class.\""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0412c74b7803790452d4914d99995dd2",
          "grade": false,
          "grade_id": "cell-fbc3d0a07230078c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "cilyfd9eZ_EE"
      },
      "source": [
        "# Pass 'create_model' into KerasClassifier, store KerasClassifier to a variable named 'model'\n",
        "# YOUR CODE HERE\n",
        "model = KerasClassifier(build_fn=create_model)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0442c29a94065e922c5ae929976a52ab",
          "grade": true,
          "grade_id": "cell-464e7506993775f2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7qz2KmuVZ_EG"
      },
      "source": [
        "# Visible Testing\n",
        "assert model.__module__ == 'tensorflow.python.keras.wrappers.scikit_learn', \"model should be a instance of KerasClassifier.\""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f88603ef37a4d3d2ef8699a41ac9a0b2",
          "grade": false,
          "grade_id": "cell-985c0425f3b1304d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "xfB-_SMPZ_EH"
      },
      "source": [
        "# Define the grid search parameters inside a dictionary named 'param_grid' \n",
        "# Use 2 hyper-parameters with 2 possible values for each \n",
        "\n",
        "# YOUR CODE HERE\n",
        "batch_size = [25, 42]\n",
        "epochs = [10, 20]\n",
        "param_grid = dict(batch_size=batch_size,\n",
        "                  epochs=epochs)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a551fd8278b30c1318c036f6ad43b503",
          "grade": true,
          "grade_id": "cell-c765b5db5489d7a2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "MAg09AkmZ_EI"
      },
      "source": [
        "assert len(param_grid.keys()) == 2, \"Did you create a param dict with 2 hyper-parameters as keys?\""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2ea6312f4bc1f42809196b696037dd52",
          "grade": false,
          "grade_id": "cell-7cfb4315eab5031c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "mCM88EcaZ_EI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcdead6d-0225-473e-97a6-663efb3ce9bf"
      },
      "source": [
        "# Create Grid Search object and name it 'gs'\n",
        "# Run Grid Search \n",
        "# YOUR CODE HERE\n",
        "gs = GridSearchCV(estimator=model,\n",
        "                    param_grid=param_grid,\n",
        "                    n_jobs=1,\n",
        "                    verbose=10,\n",
        "                    cv=5)\n",
        "\n",
        "grid_result = gs.fit(X, Y)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6904 - accuracy: 0.5579\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.5579\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.5579\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.5579\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.5579\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.5579\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.5785\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.5992\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.6901\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.7355\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.6721\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.672, total=   1.2s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6809 - accuracy: 0.5455\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.5455\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.5455\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.5455\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.5455\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.6033\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.6612\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.6405\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.6818\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.7107\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.7869\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.787, total=   1.1s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.8077 - accuracy: 0.5413\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7672 - accuracy: 0.5413\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7350 - accuracy: 0.5413\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7108 - accuracy: 0.5413\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5413\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.5413\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.5413\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.5413\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.5455\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.5909\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.5902\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.590, total=   1.1s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7078 - accuracy: 0.5309\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6974 - accuracy: 0.5309\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5309\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6809 - accuracy: 0.5309\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.5309\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.5391\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.6296\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6749\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.6790\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7202\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.7667\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.767, total=   1.1s\n",
            "[CV] batch_size=25, epochs=10 ........................................\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6792 - accuracy: 0.5514\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.5473\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.5473\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.5638\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.5679\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.6626\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.6955\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6259 - accuracy: 0.7160\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.7654\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7819\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6497861dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.7333\n",
            "[CV] ............ batch_size=25, epochs=10, score=0.733, total=   1.1s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6920 - accuracy: 0.5579\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.5579\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.5579\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.5579\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.5661\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6198\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7107\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.7273\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.7479\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.7727\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.7645\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7727\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7975\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.8099\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.8347\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.8264\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.8306\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.8512\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.8512\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.8760\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6521389050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.8361\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.836, total=   1.6s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    7.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6838 - accuracy: 0.6116\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.6942\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.5992\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6322\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.5992\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.6488\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.6405\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6736\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.6983\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.7355\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.7314\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.7397\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.7686\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.8058\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.8017\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.8099\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.8058\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.8058\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.8099\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.8223\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.8197\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.820, total=   1.4s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    8.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.6836 - accuracy: 0.5702\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.6033\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.5992\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.5744\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6074\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.5909\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.6653\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.7231\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.7397\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.7397\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.7810\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.7893\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.8017\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.8182\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.8182\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.8223\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.8140\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.8058\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.8099\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8058\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.8689\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.869, total=   1.4s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   10.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7392 - accuracy: 0.4691\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7165 - accuracy: 0.4691\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7007 - accuracy: 0.4486\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.6049\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.6626\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.6049\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.6173\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.6914\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.7119\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.7119\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.7737\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.7901\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.7942\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.7984\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.8025\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.8025\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.8148\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.8189\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.8189\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.8189\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.8167\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.817, total=   1.4s\n",
            "[CV] batch_size=25, epochs=20 ........................................\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   11.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7709 - accuracy: 0.5473\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.5473\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7168 - accuracy: 0.5473\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6985 - accuracy: 0.5473\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.5473\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.5473\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.5473\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.5473\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.5473\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.5761\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.5885\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6667\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.6872\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.7407\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.7695\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.7942\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.7984\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.8025\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.8230\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.8230\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.7833\n",
            "[CV] ............ batch_size=25, epochs=20, score=0.783, total=   2.0s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.6900 - accuracy: 0.5579\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.5579\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.5579\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.5579\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.5579\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6615 - accuracy: 0.5579\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.5620\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.5661\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.5950\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.6322\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6617 - accuracy: 0.5738\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.574, total=   1.0s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.9758 - accuracy: 0.5455\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.9383 - accuracy: 0.5455\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.9002 - accuracy: 0.5455\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.8628 - accuracy: 0.5455\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8290 - accuracy: 0.5455\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7976 - accuracy: 0.5455\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7704 - accuracy: 0.5455\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7487 - accuracy: 0.5455\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7294 - accuracy: 0.5455\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7137 - accuracy: 0.5455\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7077 - accuracy: 0.5410\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.541, total=   1.0s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.8803 - accuracy: 0.4587\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8507 - accuracy: 0.4587\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8204 - accuracy: 0.4587\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.7917 - accuracy: 0.4587\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7667 - accuracy: 0.4587\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7453 - accuracy: 0.4587\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7275 - accuracy: 0.4587\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7138 - accuracy: 0.4587\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7023 - accuracy: 0.4587\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.4587\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6869 - accuracy: 0.4426\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.443, total=   1.3s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 4ms/step - loss: 0.7317 - accuracy: 0.4691\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7217 - accuracy: 0.4362\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7137 - accuracy: 0.3663\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7062 - accuracy: 0.3333\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.4198\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5021\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5679\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.6091\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.6008\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.7325\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.7500\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.750, total=   1.0s\n",
            "[CV] batch_size=42, epochs=10 ........................................\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 4ms/step - loss: 0.6974 - accuracy: 0.5473\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5473\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5473\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5473\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.5473\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.5473\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.5473\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.5473\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.5432\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.5514\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6595 - accuracy: 0.5667\n",
            "[CV] ............ batch_size=42, epochs=10, score=0.567, total=   1.1s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 1.3376 - accuracy: 0.4421\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.2758 - accuracy: 0.4421\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.2113 - accuracy: 0.4421\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.1457 - accuracy: 0.4421\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.0805 - accuracy: 0.4421\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.0225 - accuracy: 0.4421\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.9673 - accuracy: 0.4421\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.9174 - accuracy: 0.4421\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8729 - accuracy: 0.4421\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8335 - accuracy: 0.4421\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7982 - accuracy: 0.4421\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.7672 - accuracy: 0.4421\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7415 - accuracy: 0.4421\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7183 - accuracy: 0.4421\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.4421\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.4421\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.4628\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.5620\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.6488\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.7190\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6346 - accuracy: 0.7705\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.770, total=   1.3s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.8131 - accuracy: 0.4545\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7879 - accuracy: 0.4545\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7638 - accuracy: 0.4545\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7428 - accuracy: 0.4545\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.7255 - accuracy: 0.4545\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7115 - accuracy: 0.4545\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7009 - accuracy: 0.4545\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5041\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5661\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.6446\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.6116\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.6116\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.5785\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.5785\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.5826\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6116\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.6116\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6157\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.6364\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6736\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6557\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.656, total=   1.2s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.7146 - accuracy: 0.4587\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7053 - accuracy: 0.4587\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6979 - accuracy: 0.4587\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.5041\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6860 - accuracy: 0.6198\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6825 - accuracy: 0.5992\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6793 - accuracy: 0.5579\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6757 - accuracy: 0.5992\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6714 - accuracy: 0.5868\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6683 - accuracy: 0.5579\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.5992\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.6157\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6488\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6488\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.7107\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.7149\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7397\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.7479\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.7603\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.7686\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.7869\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.787, total=   1.4s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.9550 - accuracy: 0.5309\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.9221 - accuracy: 0.5309\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8865 - accuracy: 0.5309\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8515 - accuracy: 0.5309\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.8195 - accuracy: 0.5309\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7919 - accuracy: 0.5309\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7660 - accuracy: 0.5309\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7446 - accuracy: 0.5309\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7255 - accuracy: 0.5309\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.7091 - accuracy: 0.5309\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.5309\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6826 - accuracy: 0.5309\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.5309\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.5309\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.5309\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.5309\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.5309\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.5473\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6132\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.6233 - accuracy: 0.6667\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.7167\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.717, total=   1.5s\n",
            "[CV] batch_size=42, epochs=20 ........................................\n",
            "Epoch 1/20\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 0.6760 - accuracy: 0.5473\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.5473\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.5473\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.5556\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.5761\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.5679\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.6484 - accuracy: 0.6461\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.6749\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7284\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.7366\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.7613\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.7901\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.7819\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.7860\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7984\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.7984\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.8066\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.8025\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.8189\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.8230\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5471 - accuracy: 0.7333\n",
            "[CV] ............ batch_size=42, epochs=20, score=0.733, total=   1.5s\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   25.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 1s 3ms/step - loss: 0.8505 - accuracy: 0.4554\n",
            "Epoch 2/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.7857 - accuracy: 0.4554\n",
            "Epoch 3/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.4554\n",
            "Epoch 4/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.7087 - accuracy: 0.4554\n",
            "Epoch 5/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.5281\n",
            "Epoch 6/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.6403\n",
            "Epoch 7/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.5875\n",
            "Epoch 8/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.5974\n",
            "Epoch 9/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6106\n",
            "Epoch 10/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.6865\n",
            "Epoch 11/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6733\n",
            "Epoch 12/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.7195\n",
            "Epoch 13/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.7591\n",
            "Epoch 14/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.7756\n",
            "Epoch 15/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.7789\n",
            "Epoch 16/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.8020\n",
            "Epoch 17/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.7987\n",
            "Epoch 18/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7921\n",
            "Epoch 19/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.8119\n",
            "Epoch 20/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.8086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLPqySPpZ_EJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b87810-d395-488d-89d3-604e5ac05d97"
      },
      "source": [
        "# your grid_result object should be able to run in this code \n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8249180316925049 using {'batch_size': 25, 'epochs': 20}\n",
            "Means: 0.7098360657691956, Stdev: 0.07136034662442657 with: {'batch_size': 25, 'epochs': 10}\n",
            "Means: 0.8249180316925049, Stdev: 0.0278545853583007 with: {'batch_size': 25, 'epochs': 20}\n",
            "Means: 0.5748087406158447, Stdev: 0.09937461293812365 with: {'batch_size': 42, 'epochs': 10}\n",
            "Means: 0.7326229453086853, Stdev: 0.04592362604875795 with: {'batch_size': 42, 'epochs': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}