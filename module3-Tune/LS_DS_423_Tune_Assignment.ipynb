{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "\n",
    "\n",
    "# Tune Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
    "\n",
    "# Gridsearch Hyperparameters\n",
    "\n",
    "In the guided project, you learned how to use sklearn's GridsearchCV and keras-tuner library to tune the hyperparamters of a neural network model. For your module project you'll continue using these two libraries however we are going to make things a little more interesting for you. \n",
    "\n",
    "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. \n",
    "\n",
    "\n",
    "\n",
    "**Don't forgot to switch to GPU on Colab!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# native python libraries imports \n",
    "import math\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# sklearn imports \n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# keras imports \n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from kerastuner.tuners import RandomSearch, BayesianOptimization, Sklearn\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from keras.activations import relu, sigmoid\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import get_file\n",
    "\n",
    "# required for compatibility between sklearn and keras\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_quickdraw10():\n",
    "    \"\"\"\n",
    "    Fill out this doc string, and comment the code, for practice in writing the kind of code that will get you hired. \n",
    "    \"\"\"\n",
    "    \n",
    "    URL_ = \"https://github.com/LambdaSchool/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/quickdraw10.npz?raw=true\"\n",
    "    \n",
    "    path_to_zip = get_file('./quickdraw10.npz', origin=URL_, extract=False)\n",
    "\n",
    "    data = np.load(path_to_zip)\n",
    "    \n",
    "    # normalize your image data\n",
    "    max_pixel_value = 255\n",
    "    X = data['arr_0']/max_pixel_value\n",
    "    Y = data['arr_1']\n",
    "        \n",
    "    return train_test_split(X, Y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/LambdaSchool/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/quickdraw10.npz?raw=true\n",
      "25427968/25421363 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_quickdraw10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "# Experiment 1\n",
    "\n",
    "## Tune Hyperperameters using Enhanced GridsearchCV \n",
    "\n",
    "We are going to use GridsearchCV again to tune a deep learning model however we are going to add some additional functionality to our gridsearch. Specifically, we are going to automate away the generation of how many nodes to use in a layer and how many layers to use in a model! \n",
    "\n",
    "By the way, yes, there is a function within a function. Try to not let that bother you. An alternative to this would be to create a class. If you're up for the challenge give it a shot. However, consider this a stretch goal that you come back to after you finish going through this assignment. \n",
    "\n",
    "\n",
    "### Objective \n",
    "\n",
    "The objective of this experiment is to show you how to automate the generation of layers and layer nodes for the purposes of gridsearch. Up until now, we've been manually selecting the number of layers and layer nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USXjs7Hk71Hy"
   },
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(n_layers,  first_layer_nodes, last_layer_nodes, act_funct =\"relu\", negative_node_incrementation=True):\n",
    "    \"\"\"\"\n",
    "    Returns a complied keras model \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_layers: int \n",
    "        number of hidden layers in model \n",
    "        To be clear, this excludes the input and output layer.\n",
    "        \n",
    "    first_layer_nodes: int\n",
    "        Number of nodes in the first hidden layer \n",
    "\n",
    "    last_layer_nodes: int\n",
    "        Number of nodes in the last hidden layer (this is the layer just prior to the output layer)\n",
    "        \n",
    "     act_funct: string \n",
    "         Name of activation function to use in hidden layers (this excludes the output layler)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model: keras object \n",
    "    \"\"\"\n",
    "    \n",
    "    def gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation=True):\n",
    "        \"\"\"\n",
    "        Generates and returns the number of nodes in each hidden layer. \n",
    "        To be clear, this excludes the input and output layer. \n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        Number of nodes in each layer is linearly incremented. \n",
    "        For example, gen_layer_nodes(5, 500, 100) will generate [500, 400, 300, 200, 100]\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_layers: int\n",
    "            Number of hidden layers\n",
    "            This values should be 2 or greater \n",
    "\n",
    "        first_layer_nodes: int\n",
    "\n",
    "        last_layer_nodes: int\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        layers: list of ints\n",
    "            Contains number of nodes for each layer \n",
    "        \"\"\"\n",
    "\n",
    "        # throws an error if n_layers is less than 2 \n",
    "        assert n_layers >= 2, \"n_layers must be 2 or greater\"\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # PROTIP: IF YOU WANT THE NODE INCREMENTATION TO BE SPACED DIFFERENTLY\n",
    "        # THEN YOU'LL NEED TO CHANGE THE WAY THAT IT'S CALCULATED - HAVE FUN!\n",
    "        # when set to True number of nodes are decreased for subsequent layers \n",
    "        if negative_node_incrementation:\n",
    "            # subtract this amount from previous layer's nodes in order to increment towards smaller numbers \n",
    "            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
    "            \n",
    "        # when set to False number of nodes are increased for subsequent layers\n",
    "        else:\n",
    "            # add this amount from previous layer's nodes in order to increment towards larger numbers \n",
    "            nodes_increment = (first_layer_nodes - last_layer_nodes)/ (n_layers-1)\n",
    "\n",
    "        nodes = first_layer_nodes\n",
    "\n",
    "        for i in range(1, n_layers+1):\n",
    "\n",
    "            layers.append(math.ceil(nodes))\n",
    "\n",
    "            # increment nodes for next layer \n",
    "            nodes = nodes + nodes_increment\n",
    "\n",
    "        return layers\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n",
    "    \n",
    "    for i in range(1, n_layers):\n",
    "        if i==1:\n",
    "            model.add(Dense(first_layer_nodes, input_dim=X_train.shape[1], activation=act_funct))\n",
    "        else:\n",
    "            model.add(Dense(n_nodes[i-1], activation=act_funct))\n",
    "            \n",
    "            \n",
    "    # output layer \n",
    "    model.add(Dense(10, # 10 unit/neurons in output layer because we have 10 possible labels to predict  \n",
    "                    activation='softmax')) # use softmax for a label set greater than 2            \n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer='adam', # adam is a good default optimizer \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # do not include model.fit() inside the create_model function\n",
    "    # KerasClassifier is expecting a complied model \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore create_model\n",
    "\n",
    "Let's build a few different models in order to understand how the above code works in practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model \n",
    "\n",
    "Use `create_model` to build a model. \n",
    "\n",
    "- Set `n_layers = 10` \n",
    "- Set `first_layer_nodes = 500`\n",
    "- Set `last_layer_nodes = 100`\n",
    "- Set `act_funct = \"relu\"`\n",
    "- Make sure that `negative_node_incrementation = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5dcf5c585f07629a03086cf57ba53615",
     "grade": false,
     "grade_id": "cell-86d63e89a21223de",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# use create_model to create a model \n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = create_model(\n",
    "                     n_layers=10,\n",
    "                     first_layer_nodes=500,\n",
    "                     last_layer_nodes=100,\n",
    "                     act_funct=\"relu\",\n",
    "                     negative_node_incrementation=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 456)               228456    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 412)               188284    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 367)               151571    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 323)               118864    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 278)               90072     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 234)               65286     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 189)               44415     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 145)               27550     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1460      \n",
      "=================================================================\n",
      "Total params: 1,308,458\n",
      "Trainable params: 1,308,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# run model.summary() and make sure that you understand the model architecture that you just built \n",
    "# Notice in the model summary how the number of nodes have been linearly incremented in decreasing values. \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model \n",
    "\n",
    "Use `create_model` to build a model. \n",
    "\n",
    "- Set `n_layers = 10` \n",
    "- Set `first_layer_nodes = 500`\n",
    "- Set `last_layer_nodes = 100`\n",
    "- Set `act_funct = \"relu\"`\n",
    "- Make sure that `negative_node_incrementation = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0722533c325d699f4842e874e43720e",
     "grade": false,
     "grade_id": "cell-99d563a291231a7b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# use create_model to create a model \n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = create_model(\n",
    "                     n_layers=10,\n",
    "                     first_layer_nodes=500,\n",
    "                     last_layer_nodes=100,\n",
    "                     act_funct=\"relu\",\n",
    "                     negative_node_incrementation=False\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 545)               273045    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 589)               321594    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 634)               374060    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 678)               430530    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 723)               490917    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 767)               555308    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 812)               623616    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 856)               695928    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                8570      \n",
      "=================================================================\n",
      "Total params: 4,166,068\n",
      "Trainable params: 4,166,068\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# run model.summary() and make sure that you understand the model architecture that you just built \n",
    "# Notice in the model summary how the number of nodes have been linearly incremented in increasing values.\n",
    "# The output layer must have 10 nodes because there are 10 labels to predict \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 250)               196250    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1000)              251000    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1750)              1751750   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2500)              4377500   \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 3250)              8128250   \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4000)              13004000  \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 4750)              19004750  \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 5500)              26130500  \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 6250)              34381250  \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                62510     \n",
      "=================================================================\n",
      "Total params: 107,287,760\n",
      "Trainable params: 107,287,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# feel free to play around with parameters to gain additional insight as to how the create_model function works \n",
    "model = create_model(\n",
    "                     n_layers=10,\n",
    "                     first_layer_nodes=250,\n",
    "                     last_layer_nodes=7000,\n",
    "                     act_funct=\"softmax\",\n",
    "                     negative_node_incrementation=True\n",
    "                     )\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we've played around a bit with  `create_model` in order to understand how it works, let's build a much simpler model that we'll be running gridsearches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model \n",
    "\n",
    "Use `create_model` to build a model. \n",
    "\n",
    "- Set `n_layers = 2` \n",
    "- Set `first_layer_nodes = 500`\n",
    "- Set `last_layer_nodes = 100`\n",
    "- Set `act_funct = \"relu\"`\n",
    "- Make sure that `negative_node_incrementation = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "606b85d0ba4531836f97caf6850297f8",
     "grade": false,
     "grade_id": "cell-4ca6c5e51302fd10",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# use create_model to create a model \n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = create_model(n_layers=2,\n",
    "                     first_layer_nodes=500,\n",
    "                     last_layer_nodes=100,\n",
    "                     act_funct=\"relu\",\n",
    "                     negative_node_incrementation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 397,510\n",
      "Trainable params: 397,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# run model.summary() and make sure that you understand the model architecture that you just built \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {'n_layers': [2, 3],\n",
    "              'epochs': [3], \n",
    "              \"first_layer_nodes\": [500, 300],\n",
    "              \"last_layer_nodes\": [100, 50]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Epoch 1/3\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 0.7649 - accuracy: 0.7693\n",
      "Epoch 2/3\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 0.4329 - accuracy: 0.8711\n",
      "Epoch 3/3\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 0.3422 - accuracy: 0.8975\n",
      "Best: 0.8685333331425985 using {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 2}\n",
      "Means: 0.8685333331425985, Stdev: 0.0011172982269957467 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 2}\n",
      "Means: 0.8625199993451437, Stdev: 0.0010291597246197368 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 3}\n",
      "Means: 0.86735999584198, Stdev: 0.0024967280237471893 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "Means: 0.8658399979273478, Stdev: 0.004008138164885982 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 3}\n",
      "Means: 0.8585066596666971, Stdev: 0.006130438915743435 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 2}\n",
      "Means: 0.8614266514778137, Stdev: 0.0018705699570771151 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 3}\n",
      "Means: 0.8613866766293844, Stdev: 0.0016525564787808664 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n",
      "Means: 0.8630533417065939, Stdev: 0.0041513314464411664 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n"
     ]
    }
   ],
   "source": [
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_grid, \n",
    "                    n_jobs=-2, \n",
    "                    verbose=1, \n",
    "                    cv=3)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 3,\n",
       " 'first_layer_nodes': 500,\n",
       " 'last_layer_nodes': 100,\n",
       " 'n_layers': 2,\n",
       " 'build_fn': <function __main__.create_model(n_layers, first_layer_nodes, last_layer_nodes, act_funct='relu', negative_node_incrementation=True)>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Experiment 2\n",
    "\n",
    "## Benchmark different Optimization Algorithms \n",
    "\n",
    "In this section, we are going to use the same model and dataset in order to benchmark 3 different gridsearch approaches: \n",
    "\n",
    "- Random Search\n",
    "- Bayesian Optimization. \n",
    "- Brute Force Gridsearch\n",
    "\n",
    "Our goal in this experiment is two-fold. We want to see which appraoch \n",
    "\n",
    "- Scores the highest accuracy\n",
    "- Has the shortest run time \n",
    "\n",
    "We want to see how these 3 gridsearch approaches handle these trade-offs and to give you a sense of those trades offs.\n",
    "\n",
    "### Trade-offs\n",
    "\n",
    "`Brute Force Gridsearch` will train a model on every single unique hyperparameter combination, this guarantees that you'll get the highest possible accuracy from your parameter set but your gridsearch might have a very long run-time. \n",
    "\n",
    "`Random Search` will randomly sample from your parameter set which, depending on how many samples, the run-time might be significantly cut down but you might or might not sample the parameters that correspond to the heightest possible accuracies. \n",
    "\n",
    "`Bayesian Optimization` has a bit of intelligence built into it's search algorithm but you do need to manually select some parameters which greatly influence the model learning outcomes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Build our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because gridsearching can take a lot of time and we are bench marking 3 different approaches\n",
    "# let's build a simple model to minimize run time \n",
    "\n",
    "def build_model(hp):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns a complied keras model ready for keras-tuner gridsearch algorithms \n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # hidden layer\n",
    "    model.add(Dense(units=hp.get('units'),activation=hp.get(\"activation\")))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.get('learning_rate')),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'relu'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build out our hyperparameter dictionary \n",
    "hp = HyperParameters()\n",
    "hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "hp.Choice('learning_rate',values=[1e-1, 1e-2, 1e-3])\n",
    "hp.Choice('activation',values=[\"relu\", \"sigmoid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# Run the Gridsearch Algorithms \n",
    "\n",
    "### Random Search\n",
    "\n",
    "Be sure to check out the [**docs for Keras-Tuner**](https://keras-team.github.io/keras-tuner/documentation/tuners/). Here you can read about the input parameters for the `RandomSearch` tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aaff9aae33845f374e15f2381719d83a",
     "grade": false,
     "grade_id": "cell-8c1dfb9b6d12bea2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# how many unique hyperparameter combinations do we have? \n",
    "# HINT: take the product of the number of possible values for each hyperparameter \n",
    "# save your answer to n_unique_hparam_combos\n",
    "\n",
    "# YOUR CODE HERE\n",
    "n_unique_hparam_combos = len(range(32,512+32, 32)) * 3 *2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9d628451e83431e1b52da10eccf2c00",
     "grade": false,
     "grade_id": "cell-1fa83950bb2d5f92",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# how many of these do we want to randomly sample?\n",
    "# let's pick 25% of n_unique_hparam_combos param combos to sample\n",
    "# save this number to n_param_combos_to_sample\n",
    "\n",
    "# YOUR CODE HERE\n",
    "n_param_combos_to_sample = n_unique_hparam_combos * .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tuner = RandomSearch(\n",
    "            build_model,\n",
    "            objective='val_accuracy',\n",
    "            max_trials=n_param_combos_to_sample, # number of times to sample the parameter set and build a model \n",
    "            seed=1234,\n",
    "            hyperparameters=hp, # pass in our hyperparameter dictionary\n",
    "            directory='./keras-tuner-trial',\n",
    "            project_name='random_search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 Complete [00h 00m 11s]\n",
      "val_accuracy: 0.695360004901886\n",
      "\n",
      "Best val_accuracy So Far: 0.866159975528717\n",
      "Total elapsed time: 00h 04m 49s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# take note of Total elapsed time in print out\n",
    "random_tuner.search(X_train, y_train,\n",
    "                    epochs=3,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./keras-tuner-trial/random_search\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 352\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.866159975528717\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 480\n",
      "learning_rate: 0.001\n",
      "activation: sigmoid\n",
      "Score: 0.8622000217437744\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 384\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.8620399832725525\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 416\n",
      "learning_rate: 0.001\n",
      "activation: sigmoid\n",
      "Score: 0.8594800233840942\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 448\n",
      "learning_rate: 0.001\n",
      "activation: sigmoid\n",
      "Score: 0.8570399880409241\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 288\n",
      "learning_rate: 0.001\n",
      "activation: sigmoid\n",
      "Score: 0.8557999730110168\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 224\n",
      "learning_rate: 0.001\n",
      "activation: sigmoid\n",
      "Score: 0.8515599966049194\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 192\n",
      "learning_rate: 0.01\n",
      "activation: sigmoid\n",
      "Score: 0.8370400071144104\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 160\n",
      "learning_rate: 0.01\n",
      "activation: sigmoid\n",
      "Score: 0.8322799801826477\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 320\n",
      "learning_rate: 0.01\n",
      "activation: sigmoid\n",
      "Score: 0.8311600089073181\n"
     ]
    }
   ],
   "source": [
    "# identify the best score and hyperparamter (should be at the top since scores are ranked)\n",
    "random_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Results\n",
    " \n",
    "Identify and write the the best performing hyperparamter combination and model score. \n",
    "Note that because this is Random Search, multiple runs might have slighly different outcomes. \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f084b5d373f8589a1de8d6d4473b974a",
     "grade": true,
     "grade_id": "cell-5527738b6382c164",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Trial summary\n",
    "---\n",
    "\n",
    "**Hyperparameters:**\n",
    "\n",
    "units: 352\n",
    "\n",
    "learning_rate: 0.001\n",
    "\n",
    "activation: relu\n",
    "\n",
    "Score: 0.866159975528717"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Bayesian Optimization\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/0/02/GpParBayesAnimationSmall.gif)\n",
    "\n",
    "Be sure to check out the [**docs for Keras-Tuner**](https://keras-team.github.io/keras-tuner/documentation/tuners/). Here you can read about the input parameters for the `BayesianOptimization` tuner.\n",
    "\n",
    "Pay special attention to these `BayesianOptimization` parameters: `num_initial_points` and `beta`. \n",
    "\n",
    "`num_initial_points`: \n",
    "\n",
    "Number of randomly selected hyperparameter combinations to try before applying bayesian probability to determine liklihood of which param combo to try next based on expected improvement\n",
    "\n",
    "\n",
    "`beta`: \n",
    "\n",
    "Larger values means more willing to explore new hyperparameter combinations (analogous to searching for the global minimum in Gradient Descent), smaller values means that it is less willing to try new hyperparameter combinations (analogous to getting stuck in a local minimum in Gradient Descent). \n",
    "\n",
    "As a start, error on the side of larger values. What defines a small or large value you ask? That question would pull us into the mathematical intricacies of Bayesian Optimization and Gaussian Processes. For simplicity, notice that the default value is 2.6 and work from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we know that 24 samples is about 25% of 96 possible hyper-parameter combos\n",
    "# because BO isn't random (after num_initial_points number of trails) let's see if 15 max trials gives good results\n",
    "# feel free to play with any of these numbers\n",
    "max_trials=15\n",
    "num_initial_points=5\n",
    "beta=7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./keras-tuner-trial/bayesian_optimization_4/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ./keras-tuner-trial/bayesian_optimization_4/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "bayesian_tuner = BayesianOptimization(\n",
    "                    build_model,\n",
    "                    objective='val_accuracy',\n",
    "                    max_trials=max_trials,\n",
    "                    hyperparameters=hp, # pass in our hyperparameter dictionary\n",
    "                    num_initial_points=num_initial_points, \n",
    "                    beta=beta, \n",
    "                    seed=1234,\n",
    "                    directory='./keras-tuner-trial',\n",
    "                    project_name='bayesian_optimization_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "bayesian_tuner.search(X_train, y_train,\n",
    "               epochs=3,\n",
    "               validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./keras-tuner-trial/bayesian_optimization_4\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 512\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.870639979839325\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 352\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.8697199821472168\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 192\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.8596400022506714\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 320\n",
      "learning_rate: 0.001\n",
      "activation: sigmoid\n",
      "Score: 0.859279990196228\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 480\n",
      "learning_rate: 0.001\n",
      "activation: sigmoid\n",
      "Score: 0.8572400212287903\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 160\n",
      "learning_rate: 0.001\n",
      "activation: sigmoid\n",
      "Score: 0.8492400050163269\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 288\n",
      "learning_rate: 0.01\n",
      "activation: sigmoid\n",
      "Score: 0.8342800140380859\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 384\n",
      "learning_rate: 0.01\n",
      "activation: relu\n",
      "Score: 0.8201599717140198\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 32\n",
      "learning_rate: 0.001\n",
      "activation: relu\n",
      "Score: 0.817799985408783\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 32\n",
      "learning_rate: 0.001\n",
      "activation: sigmoid\n",
      "Score: 0.8065999746322632\n"
     ]
    }
   ],
   "source": [
    "bayesian_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Results\n",
    " \n",
    "Identify and write the the best performing hyperparamter combination and model score. \n",
    "Note that because this is  Bayesian Optimization, multiple runs might have slighly different outcomes. \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1badcdca408cdd49bc2e409dca3bac5a",
     "grade": true,
     "grade_id": "cell-ff95600bf745f40f",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Trial summary\n",
    "---\n",
    "**Hyperparameters:**\n",
    "\n",
    "units: 512\n",
    "\n",
    "learning_rate: 0.001\n",
    "\n",
    "activation: relu\n",
    "\n",
    "Score: 0.870639979839325"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "## Brute Force Gridsearch Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate a Sklearn compatiable parameter dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build out our hyperparameter dictionary\n",
    "hyper_parameters = {\n",
    "    # BUG Fix: cast array as list otherwise GridSearchCV will throw error\n",
    "    \"units\": np.arange(32, 544, 32).tolist(),\n",
    "    \"learning_rate\": [1e-1, 1e-2, 1e-3],\n",
    "    \"activation\":[\"relu\", \"sigmoid\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': [32,\n",
       "  64,\n",
       "  96,\n",
       "  128,\n",
       "  160,\n",
       "  192,\n",
       "  224,\n",
       "  256,\n",
       "  288,\n",
       "  320,\n",
       "  352,\n",
       "  384,\n",
       "  416,\n",
       "  448,\n",
       "  480,\n",
       "  512],\n",
       " 'learning_rate': [0.1, 0.01, 0.001],\n",
       " 'activation': ['relu', 'sigmoid']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Sklearn compatiable model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(units, learning_rate, activation):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns a complie keras model ready for keras-tuner gridsearch algorithms \n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # hidden layer\n",
    "    model.add(Dense(units, activation=activation))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 0.7658 - accuracy: 0.7667\n",
      "Best: 0.8464266657829285 using {'activation': 'relu', 'learning_rate': 0.001, 'units': 480}\n",
      "Means: 0.2100666662057241, Stdev: 0.05747394304161123 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 32}\n",
      "Means: 0.2344800035158793, Stdev: 0.05555053675739537 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 64}\n",
      "Means: 0.3245066702365875, Stdev: 0.013180042849100567 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 96}\n",
      "Means: 0.28329333662986755, Stdev: 0.027131093078496912 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 128}\n",
      "Means: 0.25201333065827686, Stdev: 0.05545650462097443 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 160}\n",
      "Means: 0.2829333295424779, Stdev: 0.05391493862665466 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 192}\n",
      "Means: 0.33401333292325336, Stdev: 0.015976730942275235 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 224}\n",
      "Means: 0.29450665911038715, Stdev: 0.029868877372130672 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 256}\n",
      "Means: 0.3311066726843516, Stdev: 0.02864935742699608 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 288}\n",
      "Means: 0.2595733354489009, Stdev: 0.024871608846024053 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 320}\n",
      "Means: 0.291293332974116, Stdev: 0.050896437392140094 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 352}\n",
      "Means: 0.305293341477712, Stdev: 0.029225712272239083 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 384}\n",
      "Means: 0.2966533303260803, Stdev: 0.027248044231194316 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 416}\n",
      "Means: 0.3224933346112569, Stdev: 0.011853978478051943 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 448}\n",
      "Means: 0.2693066696325938, Stdev: 0.023221749991934288 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 480}\n",
      "Means: 0.2847066620985667, Stdev: 0.03280201873922634 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 512}\n",
      "Means: 0.7816799879074097, Stdev: 0.014720576524988076 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 32}\n",
      "Means: 0.7963066697120667, Stdev: 0.008459939747032949 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 64}\n",
      "Means: 0.805786669254303, Stdev: 0.006045638353630729 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 96}\n",
      "Means: 0.7973200082778931, Stdev: 0.007743087405535064 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 128}\n",
      "Means: 0.8043466806411743, Stdev: 0.006018486269468349 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 160}\n",
      "Means: 0.8030533194541931, Stdev: 0.004449458373143976 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 192}\n",
      "Means: 0.804586668809255, Stdev: 0.006434689287602587 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 224}\n",
      "Means: 0.8021200100580851, Stdev: 0.006409068108015132 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 256}\n",
      "Means: 0.8061733444531759, Stdev: 0.00364920020479532 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 288}\n",
      "Means: 0.8072933355967203, Stdev: 0.007565717263705024 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 320}\n",
      "Means: 0.8041466673215231, Stdev: 0.0051333624797790045 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 352}\n",
      "Means: 0.8037466605504354, Stdev: 0.005604216676484004 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 384}\n",
      "Means: 0.8007599910100301, Stdev: 0.004542907975707696 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 416}\n",
      "Means: 0.8070533474286398, Stdev: 0.00752632234676909 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 448}\n",
      "Means: 0.8041599988937378, Stdev: 0.004284802362890978 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 480}\n",
      "Means: 0.8019999861717224, Stdev: 0.006105834578151118 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 512}\n",
      "Means: 0.7945199807484945, Stdev: 0.002398217621922016 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 32}\n",
      "Means: 0.8076533277829488, Stdev: 0.0030259694474328138 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 64}\n",
      "Means: 0.8146399855613708, Stdev: 0.0023535435482134465 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 96}\n",
      "Means: 0.8265199859937032, Stdev: 0.004050218809697999 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 128}\n",
      "Means: 0.8307066758473715, Stdev: 0.0017282946637354037 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 160}\n",
      "Means: 0.832319994767507, Stdev: 0.004103830145584141 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 192}\n",
      "Means: 0.8365333278973898, Stdev: 0.00364508125995682 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 224}\n",
      "Means: 0.8364000121752421, Stdev: 0.0030268070317372594 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 256}\n",
      "Means: 0.840066651503245, Stdev: 0.0023338135638723127 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 288}\n",
      "Means: 0.8419866760571798, Stdev: 0.0020117785348258894 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 320}\n",
      "Means: 0.8395466605822245, Stdev: 0.001833115053722357 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 352}\n",
      "Means: 0.8375066717465719, Stdev: 0.0024783424208525977 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 384}\n",
      "Means: 0.8431333303451538, Stdev: 0.004033227271778737 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 416}\n",
      "Means: 0.8406400084495544, Stdev: 0.0028244586767943833 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 448}\n",
      "Means: 0.8464266657829285, Stdev: 0.0025977069032503534 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 480}\n",
      "Means: 0.8420666654904684, Stdev: 0.005778696362014978 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 512}\n",
      "Means: 0.6695200006167094, Stdev: 0.005209332420135594 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 32}\n",
      "Means: 0.6547600030899048, Stdev: 0.014253726329842682 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 64}\n",
      "Means: 0.6586800018946329, Stdev: 0.016691183197557864 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 96}\n",
      "Means: 0.6674800117810568, Stdev: 0.021812590370273652 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 128}\n",
      "Means: 0.6710000038146973, Stdev: 0.016626182756828624 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 160}\n",
      "Means: 0.6406400005022684, Stdev: 0.03827987127733773 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 192}\n",
      "Means: 0.6426400144894918, Stdev: 0.04973111238077631 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 224}\n",
      "Means: 0.6543866594632467, Stdev: 0.01446115941493885 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 256}\n",
      "Means: 0.6209333340326945, Stdev: 0.030358603374365273 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 288}\n",
      "Means: 0.6114266514778137, Stdev: 0.01727211599040426 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 320}\n",
      "Means: 0.627293328444163, Stdev: 0.0374221070381326 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 352}\n",
      "Means: 0.6520266731580099, Stdev: 0.03007393153214139 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 384}\n",
      "Means: 0.595906674861908, Stdev: 0.020711916563413316 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 416}\n",
      "Means: 0.6127600073814392, Stdev: 0.021088829170060715 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 448}\n",
      "Means: 0.5946933229764303, Stdev: 0.05973052092956808 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 480}\n",
      "Means: 0.5984533429145813, Stdev: 0.00811622999755178 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 512}\n",
      "Means: 0.7918399969736735, Stdev: 0.006478615908693053 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 32}\n",
      "Means: 0.8082133332888285, Stdev: 0.006402690987398787 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 64}\n",
      "Means: 0.807253340880076, Stdev: 0.0019705489029488788 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 96}\n",
      "Means: 0.8227333426475525, Stdev: 0.0033220610520966042 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 128}\n",
      "Means: 0.8169599771499634, Stdev: 0.0018956817057148604 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 160}\n",
      "Means: 0.8157600164413452, Stdev: 0.00836984523963339 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 192}\n",
      "Means: 0.8198533455530802, Stdev: 0.0017282951235085761 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 224}\n",
      "Means: 0.8283466498057047, Stdev: 0.0005167480114671074 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 256}\n",
      "Means: 0.8146666685740153, Stdev: 0.0036510919854470126 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 288}\n",
      "Means: 0.8200800021489462, Stdev: 0.005223453599172998 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 320}\n",
      "Means: 0.8210799892743429, Stdev: 0.005035549127777313 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 352}\n",
      "Means: 0.8250533143679301, Stdev: 0.0016189965337330841 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 384}\n",
      "Means: 0.8220400015513102, Stdev: 0.002454274501539967 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 416}\n",
      "Means: 0.8184000054995219, Stdev: 0.004464732873552621 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 448}\n",
      "Means: 0.822213331858317, Stdev: 0.0026527536993585475 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 480}\n",
      "Means: 0.8211999932924906, Stdev: 0.002918256861556182 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 512}\n",
      "Means: 0.763919989267985, Stdev: 0.003153836635595078 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 32}\n",
      "Means: 0.7804400126139323, Stdev: 0.0019202637456575626 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 64}\n",
      "Means: 0.7892400225003561, Stdev: 0.0013414490772218637 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 96}\n",
      "Means: 0.7907333374023438, Stdev: 0.00227455899781451 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 128}\n",
      "Means: 0.7963200012842814, Stdev: 0.002343542333197754 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 160}\n",
      "Means: 0.7940933307011923, Stdev: 0.002275528133173231 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 192}\n",
      "Means: 0.7996799945831299, Stdev: 0.0039323477134045074 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 224}\n",
      "Means: 0.8020933270454407, Stdev: 0.0024688615137850025 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 256}\n",
      "Means: 0.80130668481191, Stdev: 0.0023561100394907655 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 288}\n",
      "Means: 0.7989199956258138, Stdev: 0.0020792239320044288 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 320}\n",
      "Means: 0.8028266628583273, Stdev: 0.0035490221369472107 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 352}\n",
      "Means: 0.8055466810862223, Stdev: 0.0016657588797093232 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 384}\n",
      "Means: 0.8019199967384338, Stdev: 0.0022889774382297864 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 416}\n",
      "Means: 0.8027600049972534, Stdev: 0.0011897450522676796 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 448}\n",
      "Means: 0.8050133387247721, Stdev: 0.002547961535465652 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 480}\n",
      "Means: 0.8041066726048788, Stdev: 0.002379547094988955 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 512}\n"
     ]
    }
   ],
   "source": [
    "# save start time \n",
    "start = time()\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=hyper_parameters, \n",
    "                    n_jobs=-2, \n",
    "                    verbose=1, \n",
    "                    cv=3)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# save end time \n",
    "end = time()\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.354429002602895"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total run time \n",
    "total_run_time_in_miniutes = (end - start)/60\n",
    "total_run_time_in_miniutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu', 'learning_rate': 0.001, 'units': 480}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5132 - accuracy: 0.8459\n"
     ]
    }
   ],
   "source": [
    "# because all other optimization approaches are reporting test set score\n",
    "# let's calculate the test set score in this case \n",
    "best_model = grid_result.best_estimator_\n",
    "test_acc = best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8459200263023376"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Results\n",
    " \n",
    "Identify and write the the best performing hyperparamter combination and model score. \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9577db883482c6cded3836e5cfbf5a74",
     "grade": true,
     "grade_id": "cell-eb06d682d2790f6e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Best Score:\n",
    "---\n",
    "0.8459200263023376\n",
    "\n",
    "**activation:** 'relu'\n",
    "\n",
    "**learning_rate:** 0.001\n",
    "\n",
    "**units:** 480"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "The spirit of this experiment is to expose you to the idea of benchmarking and comparing the trade-offs of various gridsearch approaches. \n",
    "\n",
    "Even if we did find a way to pass in the original test set into GridSearchCV, we can see that both Random Search and Bayesian Optimization are arguably better alternatives to a brute force grid search when we consider the trade-offs of run time and locating the best performing model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Stretch Goals\n",
    "\n",
    "- Feel free to run whatever gridserach experiments on whatever models you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jupyter/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:25v8seyl) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 30829<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/jupyter/DS-Unit-4-Sprint-2-Neural-Networks/module3-Tune/wandb/run-20210614_043523-25v8seyl/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/jupyter/DS-Unit-4-Sprint-2-Neural-Networks/module3-Tune/wandb/run-20210614_043523-25v8seyl/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">neat-silence-2</strong>: <a href=\"https://wandb.ai/netrunner/DS-Unit-4-Sprint-2-Neural-Networks-module3-Tune/runs/25v8seyl\" target=\"_blank\">https://wandb.ai/netrunner/DS-Unit-4-Sprint-2-Neural-Networks-module3-Tune/runs/25v8seyl</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:25v8seyl). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.32<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">devout-butterfly-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/netrunner/DS-Unit-4-Sprint-2-Neural-Networks-module3-Tune\" target=\"_blank\">https://wandb.ai/netrunner/DS-Unit-4-Sprint-2-Neural-Networks-module3-Tune</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/netrunner/DS-Unit-4-Sprint-2-Neural-Networks-module3-Tune/runs/3no5rr0i\" target=\"_blank\">https://wandb.ai/netrunner/DS-Unit-4-Sprint-2-Neural-Networks-module3-Tune/runs/3no5rr0i</a><br/>\n",
       "                Run data is saved locally in <code>/home/jupyter/DS-Unit-4-Sprint-2-Neural-Networks/module3-Tune/wandb/run-20210614_043606-3no5rr0i</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'objective'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-dd6459f361d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mnum_initial_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_initial_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     seed=1234)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Log metrics inside your training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for argument 'objective'"
     ]
    }
   ],
   "source": [
    "# this is your open playground - be free to explore as you wish\n",
    "hyperparameter_defaults = hp\n",
    "\n",
    "# Pass your defaults to wandb.init\n",
    "wandb.init(config=hyperparameter_defaults)\n",
    "# Access all hyperparameter values through wandb.config\n",
    "config = wandb.config\n",
    "\n",
    "# Set up your model\n",
    "model = BayesianOptimization(config,\n",
    "                    build_model,\n",
    "                    objective = 'val_accuracy',\n",
    "                    max_trials=max_trials,\n",
    "                    num_initial_points=num_initial_points,\n",
    "                    beta=beta,\n",
    "                    seed=1234)\n",
    "\n",
    "# Log metrics inside your training loop\n",
    "for epoch in range(config[\"epochs\"]):\n",
    "    val_acc, val_loss = model.fit()\n",
    "    metrics = {\"validation_accuracy\": val_acc,\n",
    "               \"validation_loss\": val_loss}\n",
    "    wandb.log(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_433_Tune_Assignment.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "common-cpu.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "nteract": {
   "version": "0.22.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0090d85d70604fe3968ef1d1f5ff63a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "182023e5b24946b2a6003e1079bda35f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "199e741fea5c4930aa1e99bac40095bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1d2fa7b2d4074cf19296a07fc47b344c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_4d0a0937991c4ba4a35b21a5cbfb9aa7",
       "max": 1,
       "style": "IPY_MODEL_81bee63ee5ff44c6ac4e7ff5c80368fa"
      }
     },
     "2ba02faa4a8a41ee85b65c849787227a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_928dc02d4e9d43a1a80d55f87122bf5d",
       "style": "IPY_MODEL_7bcb51ac1f1d45c888413f5a908c5cf4",
       "value": " 0.02MB of 0.02MB uploaded (0.00MB deduped)\r"
      }
     },
     "363d1d0dcfe54c1aa1b22391e3e3cd2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "36f3a55b91354acab1457ef30b27839d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "43d60bfe254f4f868f1f7c3d845a0782": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "445094ec6b764e8db54d72677f9d6cbe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_acf19a8821a3457ab733be48c65b1b7d",
       "style": "IPY_MODEL_f050d4df71e5439a8710f299f78f701a",
       "value": " 0.02MB of 0.02MB uploaded (0.00MB deduped)\r"
      }
     },
     "470b2a6a6cc44aeaa60eb23b159b6c58": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4d0a0937991c4ba4a35b21a5cbfb9aa7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4f8aad3734974b70beff3a8233c6a158": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_182023e5b24946b2a6003e1079bda35f",
       "style": "IPY_MODEL_54d025b39cb242f1ba4b46ceded464da"
      }
     },
     "54d025b39cb242f1ba4b46ceded464da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5a59699b428b4b1983233815a234436d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "640c1d448abe443cbe0b1fca5433048d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6e2698c8037f49468d6427f39c31edf5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4f8aad3734974b70beff3a8233c6a158",
        "IPY_MODEL_1d2fa7b2d4074cf19296a07fc47b344c"
       ],
       "layout": "IPY_MODEL_5a59699b428b4b1983233815a234436d"
      }
     },
     "7905e5337fe64326915e4cda84b5f954": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7bcb51ac1f1d45c888413f5a908c5cf4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "81bee63ee5ff44c6ac4e7ff5c80368fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "928dc02d4e9d43a1a80d55f87122bf5d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a927398c0ce4440083177d78f5d4c978": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_36f3a55b91354acab1457ef30b27839d",
       "style": "IPY_MODEL_640c1d448abe443cbe0b1fca5433048d",
       "value": " 0.02MB of 0.02MB uploaded (0.00MB deduped)\r"
      }
     },
     "acf19a8821a3457ab733be48c65b1b7d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ad20458eeeb04b62845040ee024315d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b705349d7e9742c09aa7e3326806ff28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_43d60bfe254f4f868f1f7c3d845a0782",
       "max": 1,
       "style": "IPY_MODEL_ad20458eeeb04b62845040ee024315d0",
       "value": 1
      }
     },
     "df0f299621634ed3a782ed7900d9c189": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_470b2a6a6cc44aeaa60eb23b159b6c58",
       "max": 1,
       "style": "IPY_MODEL_7905e5337fe64326915e4cda84b5f954",
       "value": 1
      }
     },
     "e5859c17c8e849798f3616ecbeface29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_199e741fea5c4930aa1e99bac40095bc",
       "max": 1,
       "style": "IPY_MODEL_f3f2a04bb43f4fc29238c3edc267e34a",
       "value": 1
      }
     },
     "e5e7662eb85e4008aaf2870fd67a3e09": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f050d4df71e5439a8710f299f78f701a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f3f2a04bb43f4fc29238c3edc267e34a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
