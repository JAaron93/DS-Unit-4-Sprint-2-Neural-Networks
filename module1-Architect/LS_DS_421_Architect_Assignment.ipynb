{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ObyHCH8HvHSf",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# *Data Science Unit 4 Sprint 2 Assignment 1*\n",
    "\n",
    "Use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. \n",
    "\n",
    "### Objective\n",
    "\n",
    "- Build a baseline classification model then run a few experiments with different optimizers and learning rates. \n",
    "- Don't forgot to [**switch to GPU on if you're running your notebook on Colab!**](https://colab.research.google.com/notebooks/gpu.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-Tc3ovEyQ9b"
   },
   "source": [
    "## Load Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CkU0pAYCvU8o"
   },
   "outputs": [],
   "source": [
    "# imports in first cell \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# use Sequential to build out your model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Dense layer is used for Fully Connected Forward Feeding networks\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CkU0pAYCvU8o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 784)\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "# load in data set\n",
    "data = np.load('../quickdraw10.npz')\n",
    "X = data['arr_0']\n",
    "y = data['arr_1']\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8qsDqdqvHDd"
   },
   "outputs": [],
   "source": [
    "class_names = ['apple',\n",
    "               'anvil',\n",
    "               'airplane',\n",
    "               'banana',\n",
    "               'The Eiffel Tower',\n",
    "               'The Mona Lisa',\n",
    "               'The Great Wall of China',\n",
    "               'alarm clock',\n",
    "               'ant',\n",
    "               'asparagus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Owbm1EbxvA5A"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# these are your 10 unique images\n",
    "plt.figure(figsize = (10, 5))\n",
    "start = 0\n",
    "\n",
    "for num, name in enumerate(class_names):\n",
    "    plt.subplot(2, 5, num+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X[start].reshape(28, 28), cmap=plt.cm.binary)\n",
    "    plt.xlabel(name)\n",
    "    start += 10000\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say hello to the Quickdraw dataset. \n",
    "\n",
    "You'll be using this dataset a lot this week as an alternative to the mnist which we'll be using in the guided projects. The nice thing about this dataset is that it's simple, which allows us to focus on our model, it's various components, and gradually coming to a better understand of how to build neural networks without worrying about cleaning and preping our image data too much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c97_M1WNvTNY"
   },
   "outputs": [],
   "source": [
    "# always a good idea to shuffle your dataset \n",
    "X, y = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jb70CbLVyK65"
   },
   "source": [
    "-----\n",
    "\n",
    "## Build Your Baseline Model\n",
    "\n",
    "Make sure that you\n",
    "\n",
    "- **Determine** the dimensionality of your input data by investigating **X**\n",
    "- **Normalize** your input data to values between 0 and 1 \n",
    "- **Determine** the number of neurons in your output layer by investigating **Y**\n",
    "- **Select** `sparse_categorical_crossentropy` as your loss function.\n",
    "- **Select** `sgd` as your optimizer.\n",
    "- **Add** 3 hidden layers to your model with the following number of nodes\n",
    "    - h1 has 500 nodes\n",
    "    - h2 has 250 nodes\n",
    "    - h3 has 100 nodes\n",
    "    \n",
    "- **Set** epochs to 20 \n",
    "- **Use** the `validation_split` command to automatically create a training / validation dataset from within the model, so you don't have to do it yourself.\n",
    "    -  Specify a percentage such as .2 in your fit statement.\n",
    " \n",
    " \n",
    "Not sure what the various parameters are for or what what values to assign to them?\n",
    "\n",
    "- Reference the guided project notebook for Sprint 2 Module 1\n",
    "- Reference the [**Keras documentation**](https://keras.io/api/)\n",
    "- Google other examples\n",
    "- Discuss your results with classmates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_output_models = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   1,  51,  44,  99,   4,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   5, 123, 221, 255, 255, 255,\n",
       "       184, 153, 133,  18,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 104, 255, 225, 152,\n",
       "       142, 237, 255, 255, 255,  57,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 177, 255,\n",
       "       254,  79,  20, 186, 255, 255, 242,  44,   8,  76,  10, 104,  63,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7, 170,\n",
       "       255, 255, 255, 240, 255, 251, 255, 255, 233,  53, 158, 255, 225,\n",
       "       255, 245, 114, 119, 119,  37,   0,   0,   0,   0,   0,   0,  24,\n",
       "       207, 255, 255, 255, 199, 252, 255, 255, 255, 255, 236,  71, 255,\n",
       "       251, 255, 150, 240, 255, 255, 255, 136,   0,   0,   0,   0,   0,\n",
       "        47, 231, 255, 255, 255, 144,   2,  79, 201, 254, 210, 106, 117,\n",
       "       142, 241, 134, 255, 148,   8,  30, 224, 234,  46,   0,   0,   0,\n",
       "         0,  59, 250, 255, 255, 254, 122,   0,   0,   0,   0,  28,  32,\n",
       "         0,   0, 177, 244, 239, 226,  30,   0,  85, 255, 203, 133,  79,\n",
       "         0,   0,   0,  86, 255, 255, 246,  56,   0,   0,   0,   0,   0,\n",
       "         0,   0,  18, 135, 250, 255, 255, 252, 127,  45,  15, 158, 214,\n",
       "       255, 255,  23,   0,   0,   0, 125, 240,  67,   0,   0,   0,   0,\n",
       "         0,   0,  12, 123, 239, 255, 255, 255, 249, 251, 255, 146,   0,\n",
       "        75, 221, 254, 153,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   1, 106, 233, 255, 255, 253, 175,  66,  32, 233, 212,\n",
       "        29, 176, 255, 255, 176, 102,  14,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  20, 180, 255, 255, 239, 140,  33,   0,   9, 210,\n",
       "       234,  33,  49, 240, 255, 255, 255, 255, 102,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  60, 227, 255, 219, 106,  12,   0,   0,   0,\n",
       "        82, 255,  71,   0,   0,   0,   8, 144, 254, 200,  12,   0,   0,\n",
       "         0,   0,   0,   0,   1, 111, 250, 250, 136,   7,   0,   0,   0,\n",
       "         0,   0, 125, 255, 255, 255, 252, 238, 244, 253, 136,   6,   0,\n",
       "         0,   0,   0,   0,   0,   0, 124, 255, 187,  37,   0,   0,   0,\n",
       "         0,   0,   0,   0,  11, 109, 119, 119, 132, 196, 225,  64,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  40,  80,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   4,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler - Recentering data around 0\n",
    "# Normalization - way of reseting data by compressing them into a certain range\n",
    "\n",
    "# Many different ways to scale our data\n",
    "# Specifically we're doing it through normalization. Scaling between values of 0 & 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00392157, 0.2       , 0.17254902, 0.38823529,\n",
       "       0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01960784, 0.48235294, 0.86666667,\n",
       "       1.        , 1.        , 1.        , 0.72156863, 0.6       ,\n",
       "       0.52156863, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.40784314, 1.        , 0.88235294, 0.59607843, 0.55686275,\n",
       "       0.92941176, 1.        , 1.        , 1.        , 0.22352941,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.69411765, 1.        ,\n",
       "       0.99607843, 0.30980392, 0.07843137, 0.72941176, 1.        ,\n",
       "       1.        , 0.94901961, 0.17254902, 0.03137255, 0.29803922,\n",
       "       0.03921569, 0.40784314, 0.24705882, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.02745098,\n",
       "       0.66666667, 1.        , 1.        , 1.        , 0.94117647,\n",
       "       1.        , 0.98431373, 1.        , 1.        , 0.91372549,\n",
       "       0.20784314, 0.61960784, 1.        , 0.88235294, 1.        ,\n",
       "       0.96078431, 0.44705882, 0.46666667, 0.46666667, 0.14509804,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09411765, 0.81176471, 1.        , 1.        ,\n",
       "       1.        , 0.78039216, 0.98823529, 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.9254902 , 0.27843137, 1.        ,\n",
       "       0.98431373, 1.        , 0.58823529, 0.94117647, 1.        ,\n",
       "       1.        , 1.        , 0.53333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18431373, 0.90588235,\n",
       "       1.        , 1.        , 1.        , 0.56470588, 0.00784314,\n",
       "       0.30980392, 0.78823529, 0.99607843, 0.82352941, 0.41568627,\n",
       "       0.45882353, 0.55686275, 0.94509804, 0.5254902 , 1.        ,\n",
       "       0.58039216, 0.03137255, 0.11764706, 0.87843137, 0.91764706,\n",
       "       0.18039216, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.23137255, 0.98039216, 1.        , 1.        , 0.99607843,\n",
       "       0.47843137, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.10980392, 0.1254902 , 0.        , 0.        , 0.69411765,\n",
       "       0.95686275, 0.9372549 , 0.88627451, 0.11764706, 0.        ,\n",
       "       0.33333333, 1.        , 0.79607843, 0.52156863, 0.30980392,\n",
       "       0.        , 0.        , 0.        , 0.3372549 , 1.        ,\n",
       "       1.        , 0.96470588, 0.21960784, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07058824, 0.52941176, 0.98039216, 1.        , 1.        ,\n",
       "       0.98823529, 0.49803922, 0.17647059, 0.05882353, 0.61960784,\n",
       "       0.83921569, 1.        , 1.        , 0.09019608, 0.        ,\n",
       "       0.        , 0.        , 0.49019608, 0.94117647, 0.2627451 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.04705882, 0.48235294, 0.9372549 , 1.        ,\n",
       "       1.        , 1.        , 0.97647059, 0.98431373, 1.        ,\n",
       "       0.57254902, 0.        , 0.29411765, 0.86666667, 0.99607843,\n",
       "       0.6       , 0.00784314, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00392157, 0.41568627, 0.91372549,\n",
       "       1.        , 1.        , 0.99215686, 0.68627451, 0.25882353,\n",
       "       0.1254902 , 0.91372549, 0.83137255, 0.11372549, 0.69019608,\n",
       "       1.        , 1.        , 0.69019608, 0.4       , 0.05490196,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.07843137,\n",
       "       0.70588235, 1.        , 1.        , 0.9372549 , 0.54901961,\n",
       "       0.12941176, 0.        , 0.03529412, 0.82352941, 0.91764706,\n",
       "       0.12941176, 0.19215686, 0.94117647, 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.4       , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.23529412, 0.89019608, 1.        , 0.85882353,\n",
       "       0.41568627, 0.04705882, 0.        , 0.        , 0.        ,\n",
       "       0.32156863, 1.        , 0.27843137, 0.        , 0.        ,\n",
       "       0.        , 0.03137255, 0.56470588, 0.99607843, 0.78431373,\n",
       "       0.04705882, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00392157, 0.43529412, 0.98039216,\n",
       "       0.98039216, 0.53333333, 0.02745098, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.49019608, 1.        ,\n",
       "       1.        , 1.        , 0.98823529, 0.93333333, 0.95686275,\n",
       "       0.99215686, 0.53333333, 0.02352941, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.48627451, 1.        , 0.73333333, 0.14509804, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.04313725, 0.42745098, 0.46666667, 0.46666667,\n",
       "       0.51764706, 0.76862745, 0.88235294, 0.25098039, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.15686275, 0.31372549,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
       "       0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is normalization\n",
    "X[1]/X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output_nodes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef20dd34df6998e0a50e394d59d58659",
     "grade": false,
     "grade_id": "cell-907b9348d7a2ebb3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get dim of image row vectors and save to imput_dim\n",
    "imput_dim = X.shape[1]\n",
    "\n",
    "# get number of unique labels and save to n_output_nodels\n",
    "n_output_nodels = np.unique(y)\n",
    "\n",
    "# normalize image data to values between 0 and 1 (by dividing by max pixel value)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 784)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a check on your data prep \n",
    "assert  X_scaled.max(), \"Max pixel value should be 1.0, make sure you normalize your data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "zHWblzsMyNkU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0ba174cb72f491f73c3aa7df8ae7ac4",
     "grade": false,
     "grade_id": "cell-b7c96fc46d86725f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# instantiate a sequential object and call it model, then add layers to your model\n",
    "model = Sequential()\n",
    "# Adding h1 layer\n",
    "model.add(Dense(500,\n",
    "                input_dim=imput_dim,\n",
    "                activation='sigmoid'\n",
    "                ))\n",
    "\n",
    "# Adding h2 layer\n",
    "model.add(Dense(250,\n",
    "                activation='sigmoid'))\n",
    "\n",
    "# Adding h3 layer\n",
    "model.add(Dense(100,\n",
    "                activation='sigmoid'))\n",
    "\n",
    "# Adding output layer\n",
    "model.add(Dense(50,\n",
    "                activation='softmax'))\n",
    "\n",
    "# add a compile layer but don't fit your model yet\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# number of epochs\n",
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a check on your model architecture \n",
    "n_layers = len(model.get_config()[\"layers\"])\n",
    "assert n_layers == 5, \"You should have 5 layers: input, h1, h2, h3, and output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               25100     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 50)                5050      \n",
      "=================================================================\n",
      "Total params: 547,900\n",
      "Trainable params: 547,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check out your model summary \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHWblzsMyNkU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 2.2549 - accuracy: 0.2096 - val_loss: 8.4496 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 1.5617 - accuracy: 0.5494 - val_loss: 9.2445 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.9841 - accuracy: 0.7118 - val_loss: 9.7960 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.7841 - accuracy: 0.7607 - val_loss: 10.0490 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 0.7068 - accuracy: 0.7877 - val_loss: 10.1839 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.6523 - accuracy: 0.8070 - val_loss: 10.2903 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.6259 - accuracy: 0.8136 - val_loss: 10.4844 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.5917 - accuracy: 0.8251 - val_loss: 10.5767 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.5793 - accuracy: 0.8278 - val_loss: 10.6286 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.5661 - accuracy: 0.8313 - val_loss: 10.7148 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.5528 - accuracy: 0.8379 - val_loss: 10.8093 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.5412 - accuracy: 0.8386 - val_loss: 10.8708 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.5288 - accuracy: 0.8427 - val_loss: 10.8958 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.5177 - accuracy: 0.8444 - val_loss: 10.9247 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.5158 - accuracy: 0.8462 - val_loss: 11.0292 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.4980 - accuracy: 0.8516 - val_loss: 11.0194 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.4929 - accuracy: 0.8534 - val_loss: 11.0409 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.4836 - accuracy: 0.8558 - val_loss: 11.0926 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.4772 - accuracy: 0.8566 - val_loss: 11.1884 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.4605 - accuracy: 0.8629 - val_loss: 11.1629 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# fit your model and save training resuts to history\n",
    "history = model.fit(X_scaled, y,\n",
    "                    epochs=epochs,\n",
    "                    # test set will be generated within the model\n",
    "                    validation_split=0.2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 3826), started 0:04:05 ago. (Use '!kill 3826' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d66f3103bb9a6c90\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d66f3103bb9a6c90\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0QJURWh-9uv"
   },
   "source": [
    "----\n",
    "### Visualize the results\n",
    "\n",
    "- Move results in `history` in a dataframe \n",
    "- Use [**Seaborn**](https://seaborn.pydata.org/generated/seaborn.lineplot.html) to create lineplots for both loss and accuracy by epoch. \n",
    "- Analyze the results and write a couple of obsverations. \n",
    "\n",
    "At what point should we have stopped training the model and why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "ijAlzfYKAFaY",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ef8cde40701c2ef57cf853b19455125",
     "grade": false,
     "grade_id": "cell-16e647cfc3291a01",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.037219</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>8.449553</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.388261</td>\n",
       "      <td>0.594975</td>\n",
       "      <td>9.244497</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.917654</td>\n",
       "      <td>0.725812</td>\n",
       "      <td>9.795975</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.762180</td>\n",
       "      <td>0.768075</td>\n",
       "      <td>10.048980</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.692422</td>\n",
       "      <td>0.793063</td>\n",
       "      <td>10.183853</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.646253</td>\n",
       "      <td>0.808613</td>\n",
       "      <td>10.290261</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.615438</td>\n",
       "      <td>0.817450</td>\n",
       "      <td>10.484416</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.593021</td>\n",
       "      <td>0.824800</td>\n",
       "      <td>10.576744</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.575608</td>\n",
       "      <td>0.829425</td>\n",
       "      <td>10.628552</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.560454</td>\n",
       "      <td>0.833475</td>\n",
       "      <td>10.714847</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.547641</td>\n",
       "      <td>0.837475</td>\n",
       "      <td>10.809252</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.535957</td>\n",
       "      <td>0.839763</td>\n",
       "      <td>10.870763</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.525530</td>\n",
       "      <td>0.843538</td>\n",
       "      <td>10.895780</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.515347</td>\n",
       "      <td>0.846250</td>\n",
       "      <td>10.924678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.506013</td>\n",
       "      <td>0.848962</td>\n",
       "      <td>11.029162</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.497160</td>\n",
       "      <td>0.851462</td>\n",
       "      <td>11.019354</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.488389</td>\n",
       "      <td>0.854587</td>\n",
       "      <td>11.040949</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.480470</td>\n",
       "      <td>0.856575</td>\n",
       "      <td>11.092576</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.472396</td>\n",
       "      <td>0.858863</td>\n",
       "      <td>11.188374</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.464857</td>\n",
       "      <td>0.861888</td>\n",
       "      <td>11.162892</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy   val_loss  val_accuracy\n",
       "0   2.037219  0.317000   8.449553           0.0\n",
       "1   1.388261  0.594975   9.244497           0.0\n",
       "2   0.917654  0.725812   9.795975           0.0\n",
       "3   0.762180  0.768075  10.048980           0.0\n",
       "4   0.692422  0.793063  10.183853           0.0\n",
       "5   0.646253  0.808613  10.290261           0.0\n",
       "6   0.615438  0.817450  10.484416           0.0\n",
       "7   0.593021  0.824800  10.576744           0.0\n",
       "8   0.575608  0.829425  10.628552           0.0\n",
       "9   0.560454  0.833475  10.714847           0.0\n",
       "10  0.547641  0.837475  10.809252           0.0\n",
       "11  0.535957  0.839763  10.870763           0.0\n",
       "12  0.525530  0.843538  10.895780           0.0\n",
       "13  0.515347  0.846250  10.924678           0.0\n",
       "14  0.506013  0.848962  11.029162           0.0\n",
       "15  0.497160  0.851462  11.019354           0.0\n",
       "16  0.488389  0.854587  11.040949           0.0\n",
       "17  0.480470  0.856575  11.092576           0.0\n",
       "18  0.472396  0.858863  11.188374           0.0\n",
       "19  0.464857  0.861888  11.162892           0.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a check on our model training\n",
    "assert df.shape[0] == 20, \"df should have the training results from 20 epochs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "ijAlzfYKAFaY",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "424d241660318a72ecda935be10485d7",
     "grade": false,
     "grade_id": "cell-96dba18873c4cffc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use the plotting method in your dataframe to plot the modeling results\n",
    "\n",
    "# YOUR CODE HERE\n",
    "import seaborn as sns\n",
    "\n",
    "epochs = [i for i in range(len(df['loss']))]\n",
    "sns.lineplot(epochs, df['loss'], label=\"train\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations \n",
    "\n",
    "Based on the plot of the training and validation loss answer the following questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Was our model able to learn over the course of the 20 epochs? Why or why not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7713eb32ad3a910a58dfdb9494a9db3",
     "grade": true,
     "grade_id": "cell-820990a8232a858a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is our model overfitting? Why or why not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d30c64465cd35081d70578c20ecf96d",
     "grade": true,
     "grade_id": "cell-33868e7ef6e401b5",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Could the model score benefit from additional epochs? Why or why not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0fc2208e2c78461578fc7a05224066b8",
     "grade": true,
     "grade_id": "cell-5c883f0a3161e469",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MAhBrcE4yOZe"
   },
   "source": [
    "-----\n",
    "## Change Optimizers\n",
    "\n",
    "Let's compare model performance between difference optimizers. \n",
    "- Build a new model, identical as the last one but using `adam` for the optimizer. \n",
    "- Visualize the training results just as we did for the last model. \n",
    "- Save modeling results to adam_history so we don't erase the results from the previous model run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "jIW_spOZ0cxy",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d30d8c6f4521861a77c9ef04dbde904",
     "grade": false,
     "grade_id": "cell-56663c8a5e75b71f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 0.7903 - accuracy: 0.7689 - val_loss: 11.6737 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.3372 - accuracy: 0.8988 - val_loss: 12.6175 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.2572 - accuracy: 0.9228 - val_loss: 13.4305 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.2022 - accuracy: 0.9396 - val_loss: 14.6862 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.1631 - accuracy: 0.9522 - val_loss: 15.9496 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.1281 - accuracy: 0.9618 - val_loss: 17.3534 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.1017 - accuracy: 0.9698 - val_loss: 17.9582 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.0824 - accuracy: 0.9755 - val_loss: 18.6899 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0714 - accuracy: 0.9787 - val_loss: 19.7312 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.0607 - accuracy: 0.9820 - val_loss: 20.2227 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0534 - accuracy: 0.9836 - val_loss: 20.2678 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0505 - accuracy: 0.9847 - val_loss: 20.4990 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0436 - accuracy: 0.9867 - val_loss: 21.3020 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.0379 - accuracy: 0.9881 - val_loss: 20.9270 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0357 - accuracy: 0.9895 - val_loss: 20.3617 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0315 - accuracy: 0.9900 - val_loss: 21.3523 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0338 - accuracy: 0.9892 - val_loss: 21.2311 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 21.0439 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: 22.2052 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0280 - accuracy: 0.9907 - val_loss: 21.8965 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# train same model as above but use sgd if you used adam previously ( or use adam if you used sgd previously)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# instantiate a sequential object and call it model, then add layers to your model\n",
    "model = Sequential()\n",
    "# Adding h1 layer\n",
    "model.add(Dense(500,\n",
    "                input_dim=imput_dim,\n",
    "                activation='sigmoid'\n",
    "                ))\n",
    "\n",
    "# Adding h2 layer\n",
    "model.add(Dense(250,\n",
    "                activation='sigmoid'))\n",
    "\n",
    "# Adding h3 layer\n",
    "model.add(Dense(100,\n",
    "                activation='sigmoid'))\n",
    "\n",
    "# Adding output layer\n",
    "model.add(Dense(50,\n",
    "                activation='softmax'))\n",
    "\n",
    "# add a compile layer but don't fit your model yet\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# number of epochs\n",
    "epochs=20\n",
    "\n",
    "# fit your model and save training resuts to history\n",
    "adam_history = model.fit(X_scaled, y,\n",
    "                    epochs=epochs,\n",
    "                    # test set will be generated within the model\n",
    "                    validation_split=0.2\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a check that we're using the correct optimizer in this model\n",
    "opt_name = model.optimizer.get_config()[\"name\"]\n",
    "assert opt_name == \"Adam\", \"you need to use adam for the optimizer in this model.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a4c01aa7dbcc832d75b05bffaeaacc8",
     "grade": false,
     "grade_id": "cell-20118d1646215346",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "df_adam = pd.DataFrame(adam_history.history)\n",
    "\n",
    "epochs = [i for i in range(len(df_adam['loss']))]\n",
    "sns.lineplot(epochs, df_adam['loss'], label=\"train\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations \n",
    "\n",
    "This plot should look very different from the previous plot. Based on the plot of the training and validation loss answer the following questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is our model overfitting? Why or why not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa4141497af675d227aa510feb8db732",
     "grade": true,
     "grade_id": "cell-7e524ccac970c33e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Could our model's performance improve by training on more than 20 epochs? Why or why not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae03b8b897eb5d052590574ab3bba839",
     "grade": true,
     "grade_id": "cell-456c40e885652955",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assuming that you want to stick to this model architecture, what can you do to avoid overfitting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f5a9393314231d3ce253363c1df1223",
     "grade": true,
     "grade_id": "cell-74d7def19c66702b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# Conclusion \n",
    "\n",
    "What you have observed by comparing the two models that are identitical, except for the optimizer, is that the choice of the optimizer can have a very big influence in the training outcome of ML models in general and in a neural networks in particuar. \n",
    "\n",
    "You might not actually know \n",
    "\n",
    "- why changing the optimizer from Stocastic Gradient Descent over to Adam made a difference.\n",
    "- how Gradient Desecent works \n",
    "- or that Adam is known as Adaptive Gradient Descent (i.e. is it a different version of ordinary Gradient Descent). \n",
    "\n",
    "But that's ok - tomorrow's lesson will be a deep dive into Gradient Descent. You'll learn the theory of Gradient Descent, we'll code up Gradient Descent from scratch, and we'll talk about how Adam is different from ordinary Gradient Descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Preparation for Tomorrow \n",
    "\n",
    "In Preparation for tomorrow, you might need to watch a few videos. I say might because you may or may not already be comfortable with multi-variate calculus. \n",
    "\n",
    "### Theory of Calculus \n",
    "The theory of Gradient Descent rest on [**the derivative from Calculus**](https://www.youtube.com/watch?v=WUvTyaaNkzM). If you've never taken a Calculus course before, or are a bit rusty, definitely watch this video in preparation for tomorrow's lesson. The take away here is to conceptually understand the derivative, you won't be asked to actually calculate any derivatives by hand. \n",
    "\n",
    "### The Gradient - a multi-dimensional derivative\n",
    "Once you've watched the previous video, you are now set up to  understand how to conceptualize a derivative in an N-dimensional space (where N is any number ranging from 2, 3, 4, ..., all the way to a very large number of dimensions N ) [**This video visually explains the multi-dimensional derivative called the Gradient visually**](https://www.youtube.com/watch?v=GkB4vW16QHI) - and that's the take away. This point of this video is to help you understand the Gradient visually using 3D surfaces. You should also know that the Gradient is made of up partial derivatives, more on this tomorrow. \n",
    "\n",
    "### Contour Maps \n",
    "It is very common to visual 3D surfaces as 2D contour maps - and we'll be making a lot of use of contour maps to understand Gradient Descent. Watch this video in order to [**understand the relationship between 3D surfaces and 2D contour maps**](https://www.youtube.com/watch?v=acdX4YamDtU)\n",
    "\n",
    "### The Calculus of Backpropagation \n",
    "\n",
    "Unlike standard Sklearn ML models, neural networks use not just Gradient Descent but also something called Backpropagatin in order to learn from the data. [**In order to understand how backpropagation works, you need to understand the Chain Rule in Calculus**](https://www.youtube.com/watch?v=acdX4YamDtU). The take away here is to understand how a partial derivative can be decomposed into a product of multiple derivatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# Stretch Goals\n",
    "\n",
    "### This section is optional!\n",
    "\n",
    "Only after you've completed the above work and watched the recommended videos, are you then encouraged to experiment with building a few more models and analyze their results. \n",
    "\n",
    "Here are some suggestions to help you get started. \n",
    "\n",
    "- Train the same model using the Sigmoid activation fucntion and the Relu activation function and note the difference in their learning outcomes.  [**Keras docs on activation fucntions**](https://keras.io/api/layers/activations/). We'll cover the Relu activation function in Sprint 2 Module 3.\n",
    "- Train the same model using Normalized and non-Normalized data and note the difference in their learning outcomes. \n",
    "\n",
    "\n",
    "The objective here is to give you an oppertunity to get more practice with the Keras API (i.e. building models) and running a couple of experiments to help set you up for future lessons. In order words, we'll be discussing different activation functions and the affect of Normalized data on model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_432_TensorFlow_Assignment",
   "provenance": []
  },
  "environment": {
   "name": "common-cpu.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
